{"meta":{"title":"Vianlex's Wiki","subtitle":"个人知识记录","description":"好记性，不如烂笔头。","author":"Vianlex","url":"http://example.com","root":"/"},"pages":[{"title":"首页","date":"2022-04-27T16:00:00.000Z","updated":"2023-05-31T13:39:26.130Z","comments":true,"path":"index.html","permalink":"http://example.com/index.html","excerpt":"","text":"Wecome to Vianlex Blog学习笔记和工作遇到的一些问题记录"},{"title":"关于我","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"长恨此身非我有，何时忘却营营。——苏轼《临江仙·夜归临皋》"},{"title":"分类目录","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标签列表","date":"2023-05-31T13:39:26.130Z","updated":"2023-05-31T13:39:26.130Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"index","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/index/","link":"","permalink":"http://example.com/wiki/index/","excerpt":"","text":"GitHub Pages + GitHub Action + Hexo 搭建自动部署的静态网站GitHub Pages 搭建静态网站1、静态网站的 github 仓库名称必须满足格式：用户名称.github.io，静态网站的访问地址即是仓库的名称，如下图，创建的仓库静态网页 github 仓库名为 vialex.github.io, 则要访问该仓库的静态网页，配置后浏览器访问 vianlex.github.io 即可。 2、创建一个 ph-pages 分支， 并在仓库的 settings 中指定静态网站使用 ph-pages 分支，main 分支存放搭建 hexo 网站的源码，ph-pages 存放 hexo 编译后的静态网页源码，设置好后，浏览器访问 vianlex.github.io 会默认访问 pg-pages 分支下的 index.html 文件，静态网站使用分支设置如下图： 3、vianlex.github.io 静态网站使用仓库的 main 分支存放 hexo 源码，pg-pages 分支存放 hexo 编译后静态文件，另一种方式也可以使用一个仓库存放 hexo 源码，一个仓库存放 hexo 编译后的静态文件。 手动使用 hexo deploy 部署静态网站使用 hexo deploy 部署静态网站，其实就是把我们搭建 hexo 网站编译，并将编译后的静态网站源码推送到 pg-pages 分支, 使用 hexo deploy 部署必须安装 hexo-deployer-git 插件和修改 _config.yml 中 deploy 参数。 1、安装 hexo-deployer-git 插件 1npm install hexo-deployer-git --save 2、修改 _config.yml 配置文件以下配置的作用：是使用 hexo deploy 编译 hexo 源码后，将生成的静态网页，推送到指定的仓库和分支，推送的仓库类型可以是 git、gitlab 或者其他 1234deploy: type: git repo: git@github.com:vianlex/vianlex.github.io.git # 指定我们静态网站部署 github 仓库 branch: gh-pages # 因为上面我们上面设置 vianlex.github.io 静态网站指定的分支是 ph-pages，所以要将编译后的静态网站源码推动到该分支 GitHub Actions 自动部署静态网站自动部署静态网站也需要跟手动部署一样，安装好 hexo-deployer-git 插件和配置好 _config.yml 中 deploy 参数，自动部署其实就是利用 Github 提供的 Github Action 代替我们的手动执行 hexo deploy，要想使用 Github Actions 流水线要做的几个部署如下。 1、生成部署密钥命令如下： 密钥可以使用自己以前生成过的访问 github 或者访问其他应用的 ssh 密钥，不过为安全最好是单独生成新的密钥 12345 ssh-keygen -t rsa -f github-deploy-key-t 指定密钥的类型，可以省略-f 指定密钥文件名称 2、 在仓库的 settings 配置刚才生成的密钥，公钥和私钥的配置是为 GitHub Actions 流水线编译部署能将 hexo 源码编译的静态网站源码推送到仓库的 ph-pages 分支2.1、设置访问仓库的公钥，如下图：2.2、设置访问仓库需要的私钥，如下图： 3、在仓库根目录下创建 .github&#x2F;workflows 目录，并目录创建一个 yml 类型的文件，文件名称随意取，然后文件内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 指定 GitHub Actions 流水线的名称，即在仓库的 GitHub Actions 流水线列表中的显示的名字name: auto-deploy-hexo-cion: # 设置 Github Actions 流水线的触发方式，使用 git push 的时候触发 push: branches: # 指定触发的分支，main 分支 git push 的时候触发流水线 - main # 指定环境变量，方便引用，用到的时候使用 $&#123;&#123; env.GIT_USER&#125;&#125; 引用即可env: GIT_USER: vianlex GIT_EMAIL: zhouykwork@outlook.com DEPLOY_REPO: vianlex/vianlex.github.io DEPLOY_BRANCH: mainjobs: build: strategy: # 指定 node 和 os 版本 矩阵指定多版本 matrix: os: [ubuntu-latest] node_version: [12.x] # $&#123;&#123;matrix.node_version&#125;&#125; 即使是引用上面定义的版本 name: Build on node $&#123;&#123; matrix.node_version &#125;&#125; and $&#123;&#123; matrix.os &#125;&#125; runs-on: $&#123;&#123; matrix.os &#125;&#125; # 流水线执行的步骤 steps: # 第一步，指定拉取hexo 源码仓库分支，repository 和 ref 使用变量引用上面配置的仓库和分支 - name: Checkout deploy repo uses: actions/checkout@v2 with: repository: $&#123;&#123; env.DEPLOY_REPO &#125;&#125; ref: $&#123;&#123; env.DEPLOY_BRANCH &#125;&#125; # 第二步，指定使用的 node 版本 - name: Use Node.js $&#123;&#123; matrix.node_version &#125;&#125; uses: actions/setup-node@v1 with: node-version: $&#123;&#123; matrix.node_version &#125;&#125; # 第三步，设置运行环境的系统变量，并配置访问仓库的密钥，因为流水线编译 hexo 要将编译后的源码推送到仓库的 ph-pages 分支 - name: Configuration environment env: # $&#123;&#123;secrets.HEXO_DEPLOY_PRI&#125;&#125; 表示引用的是仓库配置 settings-&gt;secrets 中的标题名称是 HEXO_DEPLOY_PRI 的私钥 HEXO_DEPLOY_PRI: $&#123;&#123;secrets.HEXO_DEPLOY_PRI&#125;&#125; run: | sudo timedatectl set-timezone &quot;Asia/Shanghai&quot; # 在流水线的主机的用户目录下创建 .ssh 目录，并将我们在仓库设置的私钥复制到其中 mkdir -p ~/.ssh/ echo &quot;$HEXO_DEPLOY_PRI&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt; ~/.ssh/known_hosts # 配置访问仓库的用户名和邮箱 git config --global user.name $GIT_USER git config --global user.email $GIT_EMAIL # 第四步，安装 hexo 依赖 - name: Install dependencies run: | npm install hexo-cli -g npm install # 第五步，运行 hexo 部署命令 - name: Hexo deploy run: | hexo clean hexo d 4、配置好后，每次 main 分支 git push 的时候 GitHub Actions 都会触发上面配置的流水线，流水线执行状态，如下图可查看： 参考链接1、https://lujiahao0708.github.io/p/df27ccfb.html2、https://dslwind.github.io/2021-04-20-github-action-hexo","categories":[],"tags":[]},{"title":"Node 环境配置说明","slug":"NodeJs/Node 环境配置记录","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/NodeJs/Node 环境配置记录/","link":"","permalink":"http://example.com/wiki/NodeJs/Node%20%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"npm config 命令说明使用 npm help config 可以查看 npm 配置帮助文档 12345678// 查看全局或者用户级别的配置文件路径npm config get [ globalconfig | userconfig]// 编辑配置全局或者用户级别的配置文件npm config edit [userconfig | globalconfig]// 显示当前环境的配置属性npm config list 或者 npm config ls npm install -g [cli package]安装全局 CLI 命令包，是需要将 node_global 添加到环境变量中, 才能直接在终端中使用 npm 配置文件说明使用 npm set(修改用户级别配置的命令) 和 npm golabl set(修改全局配置的命令) 命令修改配置文件，都会直接写入对应的级别的配置文件中，所以也可以直接修改配置文件也是一样的效果，npm 配置的查找顺序如下： 项目的配置文件(&#x2F;path&#x2F;to&#x2F;user&#x2F;project&#x2F;.npmrc)用户的配置文件($HOME&#x2F;.npmrc)全局配置文件($PREFIX&#x2F;etc&#x2F;npmrc)npm 内置配置文件(&#x2F;path&#x2F;to&#x2F;npm&#x2F;npmrc)","categories":[{"name":"NodeJs","slug":"NodeJs","permalink":"http://example.com/categories/NodeJs/"}],"tags":[]},{"title":"使用出现问题记录","slug":"PowerDesigner/使用问题记录","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/PowerDesigner/使用问题记录/","link":"","permalink":"http://example.com/wiki/PowerDesigner/%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"提示 the object has no symbol在 Workspace 中找到应对 PDM 或者 CDM 的 PhysicalDiagram 然后右键选择 show symbols 再选择要显示的对象即可。","categories":[{"name":"PowerDesigner","slug":"PowerDesigner","permalink":"http://example.com/categories/PowerDesigner/"}],"tags":[]},{"title":"SQL 逆向导入生成 PDM","slug":"PowerDesigner/逆向导入问题记录","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/PowerDesigner/逆向导入问题记录/","link":"","permalink":"http://example.com/wiki/PowerDesigner/%E9%80%86%E5%90%91%E5%AF%BC%E5%85%A5%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"逆向导入 MySQL 表结构例子第一步 第二步、DBMS 需要选择 MySql 第三步、选择要导入的建表 SQL 脚本 查看 Colums 没有 comment 注释列的话，可以 CTRL+U 选择显示 comment 即可 SQL 逆向导入生成 PDM 没有导入 COMMENT 注释问题解决的方式是，把建表语句中字段设置的默认值和字符集全去掉，只保留字段的类型和注释，如下： 1234567CREATE TABLE `user` ( `id` VARCHAR(50) COMMENT &#x27;用户 ID&#x27;, `username` VARCHAR(50) COMMENT &#x27;用户名&#x27;, PRIMARY KEY (`id`) USING BTREE) COLLATE=&#x27;utf8mb4_0900_ai_ci&#x27; ENGINE=InnoDB COMMENT &#x27;用户表&#x27;; 将生成的 PDM 转 CDM菜单栏上选择 Tools 然后选择 Generate conceptual Data Model 即可","categories":[{"name":"PowerDesigner","slug":"PowerDesigner","permalink":"http://example.com/categories/PowerDesigner/"}],"tags":[]},{"title":"Redis 缓存穿透、缓存击穿、缓存雪崩","slug":"Redis/Redis 缓存穿透、击穿、雪崩","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/Redis/Redis 缓存穿透、击穿、雪崩/","link":"","permalink":"http://example.com/wiki/Redis/Redis%20%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E9%9B%AA%E5%B4%A9/","excerpt":"","text":"使用缓存的目的时为提高响应的效率和并发量，以及减少数据库的压力，如果缓存出现穿透、击穿、雪崩，就是失去了使用缓存的目录和意义，没有了缓存流量直通数据库，数据库压力增大，可能会就会导致系统崩溃。 缓存穿透穿透说明缓存穿透是要查询的数据在缓存中查询不到，在数据库中也查询不到，因为数据库中没有，每次查询之后都无法写入缓存，就导致每次查询数据都是直接查询数据库，当高并发或人为恶意查询数据，就会造成数据库的压力剧增、或者崩溃。 穿透出现场景1、原有的数据在缓存中和数据库中已经删除，前端仍然有关联的数据查询，未去掉。2、人为的利用不存在的 key 恶意尝试请求，攻击系统。 穿透的处理方案1、查询到空值时也将缓存设置默认值或者空，有效期设置短一些如3分钟，同时数据库写入数据时，必须更新缓存。2、校验数据的有效性，防止恶意的 key 请求。3、黑名单限制，防止恶意请求。4、使用布隆过滤器，数据库写入数据时，先使用布隆过滤器标记，查询缓存没有数据时，查询布隆过滤器判断是否存在数据，不存在直接返回，存在在查询数据库。 缓存雪崩雪崩说明在使用缓存时，通常会对缓存设置过期时间，一方面目的是保持缓存与数据库数据的一致性，另一方面是减少冷缓存占用过多的内存空间。一个时刻出现大规模的缓存失效的情况或者 Redis 服务崩溃的情况下，大量的请求全部转发到数据库，从而导致数据库压力骤增，甚至宕机。从而形成一系列的连锁反应，造成系统崩溃等情况，就是缓存雪崩。 雪崩出现场景1、大量热点 key 同时失效。2、redis 集群彻底崩溃。 雪崩的处理方案1、在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。2、使用熔断机制。当流量到达一定的阈值时，就直接返回系统拥挤之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。3、提高数据库的容灾能力，可以使用分库分表，读写分离的策略。4、为了防止 Redis 宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。 缓存击穿击穿说明缓存雪崩有点类似，缓存雪崩是大规模的 key 失效，而缓存击穿是一个热点的 Key，有大并发集中对该 key 进行访问，因为没有缓存，一瞬间的大量并发请求直接打到数据库。 击穿的处理方案1、如果业务允许的话，对于热点的key可以设置永不过期的key。2、使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，同时也会来的一个问题使用锁导致性能变差。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[]},{"title":"Awk 基础用法","slug":"Shell/Awk  基础用法","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/Shell/Awk  基础用法/","link":"","permalink":"http://example.com/wiki/Shell/Awk%20%20%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/","excerpt":"","text":"","categories":[{"name":"Shell","slug":"Shell","permalink":"http://example.com/categories/Shell/"}],"tags":[]},{"title":"Sed 基础用法","slug":"Shell/Sed 基础用法","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/Shell/Sed 基础用法/","link":"","permalink":"http://example.com/wiki/Shell/Sed%20%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/","excerpt":"","text":"","categories":[{"name":"Shell","slug":"Shell","permalink":"http://example.com/categories/Shell/"}],"tags":[]},{"title":"SpringBoot 属性配置","slug":"SpringBoot/SpringBoot 属性配置","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/SpringBoot/SpringBoot 属性配置/","link":"","permalink":"http://example.com/wiki/SpringBoot/SpringBoot%20%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE/","excerpt":"","text":"配置读取SpringBoot 属性配置支持 properties 文件、YAML文件、环境变量和命令行参数。 Spring Boot 提供的 SpringApplication 类会搜索并加载配置文件来获取配置属性值。SpringBoot 启动运行 SpringApplication 类的 run 方法时，会以下位置搜索配置文件： 当前目录的 ／config 子目录 当前目录 classpath 中的 &#x2F;config 包 classpath 配置的访问 通过 @ConfigurationProperties 绑定到 Bean 对象 在 Bean 对象中通过 @Value 注解引用 通过 Spring 提供的 Environment 类访问","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/categories/SpringBoot/"}],"tags":[]},{"title":"Dom4j 入门笔记","slug":"Xml/Dom4j 入门笔记","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/Xml/Dom4j 入门笔记/","link":"","permalink":"http://example.com/wiki/Xml/Dom4j%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Maven 引入依赖包12345678910111213141516171819&lt;!-- https://mvnrepository.com/artifact/org.dom4j/dom4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- xpath --&gt;&lt;dependency&gt; &lt;groupId&gt;jaxen&lt;/groupId&gt; &lt;artifactId&gt;jaxen&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;5.8.1&lt;/version&gt;&lt;/dependency&gt; 创建 XML12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.github.vianlex.xml.dom4j;import java.net.URL;import java.util.Iterator;import java.util.List;import org.dom4j.Attribute;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.DocumentHelper;import org.dom4j.Element;import org.dom4j.Node;import org.dom4j.io.OutputFormat;import org.dom4j.io.SAXReader;import org.dom4j.io.XMLWriter;import org.junit.jupiter.api.Test;public class Dom4jTest &#123; /** * 构建 xml * &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; * &lt;beans&gt; * &lt;bean id=&quot;userService&quot; class=&quot;com.github.vianlex.service.impl.UserServiceImpl&quot;&gt; * &lt;property name=&quot;userDao&quot; ref=&quot;userDao&quot;/&gt; * &lt;/bean&gt; * &lt;bean id=&quot;roleService&quot; class=&quot;com.github.vianlex.service.impl.RoleServiceImpl&quot;&gt; * &lt;property name=&quot;roleDao&quot; ref=&quot;roleDao&quot;&gt;&lt;/property&gt; * &lt;/bean&gt; * &lt;bean id=&quot;roleDao&quot; class=&quot;com.github.vianlex.dao.RoleDao&quot;&gt;&lt;/bean&gt; * &lt;bean id=&quot;userDao&quot; class=&quot;com.github.vianlex.dao.UserDao&quot;&gt;&lt;/bean&gt; * &lt;beans&gt; * */ @Test public void createXml() &#123; Document document = DocumentHelper.createDocument(); // 创建 &lt;beans&gt; 标签 Element root = document.addElement(&quot;beans&quot;); // 创建 &lt;beans&gt; 的子标签 &lt;bean&gt; Element userServiceBean = root.addElement(&quot;bean&quot;).addAttribute(&quot;id&quot;, &quot;userService&quot;).addAttribute(&quot;class&quot;, &quot;com.github.vianlex.service.impl.UserServiceImpl&quot;); // 创建 &lt;bean&gt; 的子标签 &lt;property&gt; userServiceBean.addElement(&quot;property&quot;).addAttribute(&quot;name&quot;, &quot;userDao&quot;).addAttribute(&quot;ref&quot;, &quot;userDao&quot;); Element roleServiceBean = root.addElement(&quot;bean&quot;).addAttribute(&quot;id&quot;, &quot;roleService&quot;).addAttribute(&quot;class&quot;, &quot;com.github.vianlex.service.impl.RoleServiceImpl&quot;); roleServiceBean.addElement(&quot;property&quot;).addAttribute(&quot;name&quot;, &quot;roleDao&quot;).addAttribute(&quot;ref&quot;, &quot;roleDao&quot;); Element userDao = root.addElement(&quot;bean&quot;).addAttribute(&quot;id&quot;, &quot;roleDao&quot;).addAttribute(&quot;class&quot;, &quot;com.github.vianlex.dao.RoleDao&quot;); Element roleDao = root.addElement(&quot;bean&quot;).addAttribute(&quot;id&quot;, &quot;userDao&quot;).addAttribute(&quot;class&quot;, &quot;com.github.vianlex.dao.UserDao&quot;); System.out.println(document.asXML()); System.out.println(&quot; ============================================== &quot;); // 美化打印 xml try &#123; OutputFormat format = OutputFormat.createPrettyPrint(); XMLWriter writer = new XMLWriter(System.out, format); writer.write(document); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; System.out.println(&quot; ============================================== &quot;); // 紧凑型打印 xml try &#123; // Compact format to System.out OutputFormat format = OutputFormat.createCompactFormat(); XMLWriter writer = new XMLWriter(System.out, format); writer.write(document); writer.close(); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125;&#125; 将文本 xml 写文件123FileWriter out = new FileWriter(&quot;foo.xml&quot;);document.write(out);out.close(); 解析 XML 解析文本 xml 1234567891011@Testpublic void getDocumentByText() &#123; String xml = &quot;&lt;beans&gt;&lt;bean id=\\&quot;userService\\&quot; class=\\&quot;com.github.vianlex.service.impl.UserServiceImpl\\&quot;&gt;&lt;property name=\\&quot;userDao\\&quot; ref=\\&quot;userDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleService\\&quot; class=\\&quot;com.github.vianlex.service.impl.RoleServiceImpl\\&quot;&gt;&lt;property name=\\&quot;roleDao\\&quot; ref=\\&quot;roleDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleDao\\&quot; class=\\&quot;com.github.vianlex.dao.RoleDao\\&quot;/&gt;&lt;bean id=\\&quot;userDao\\&quot; class=\\&quot;com.github.vianlex.dao.UserDao\\&quot;/&gt;&lt;/beans&gt;&quot;; try &#123; Document document = DocumentHelper.parseText(xml); System.out.println(document.asXML()); &#125; catch (DocumentException e) &#123; throw new RuntimeException(&quot;解析文本 xml 出错&quot;, e); &#125;&#125; 解析文件中的 xml 123456789101112@Testpublic void getDocumentByXmlFile() &#123; String fileName = &quot;spring-context.xml&quot;; SAXReader saxReader = new SAXReader(); try &#123; Document document = saxReader.read(this.getClass().getResourceAsStream(fileName)); System.out.println(document.asXML()); &#125; catch (DocumentException e) &#123; throw new RuntimeException(&quot;解析 xml 文件出错&quot;, e); &#125;&#125; 解析 document123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 迭代方式解析 document */@Testpublic void parseDocumentByIter() throws Exception&#123; String xml = &quot;&lt;beans id=\\&quot;helloRoot\\&quot;&gt;&lt;bean id=\\&quot;userService\\&quot; class=\\&quot;com.github.vianlex.service.impl.UserServiceImpl\\&quot;&gt;&lt;property name=\\&quot;userDao\\&quot; ref=\\&quot;userDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleService\\&quot; class=\\&quot;com.github.vianlex.service.impl.RoleServiceImpl\\&quot;&gt;&lt;property name=\\&quot;roleDao\\&quot; ref=\\&quot;roleDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleDao\\&quot; class=\\&quot;com.github.vianlex.dao.RoleDao\\&quot;/&gt;&lt;bean id=\\&quot;userDao\\&quot; class=\\&quot;com.github.vianlex.dao.UserDao\\&quot;/&gt;&lt;/beans&gt;&quot;; Document document = DocumentHelper.parseText(xml); // root elements Element root = document.getRootElement(); // iterate through child elements of root for (Iterator&lt;Element&gt; it = root.elementIterator(); it.hasNext();) &#123; Element element = it.next(); System.out.println(&quot;元素标签名：&quot;+element.getName()+&quot;，标签属性：(id = &#x27;&quot;+element.attributeValue(&quot;id&quot;) +&quot;&#x27;, class=&#x27;&quot;+element.attributeValue(&quot;class&quot;)+&quot;&#x27;)&quot; ); &#125; System.out.println(&quot; ================================================= &quot;); // iterate through child elements of root with element name &quot;bean&quot; for (Iterator&lt;Element&gt; it = root.elementIterator(&quot;bean&quot;); it.hasNext();) &#123; Element element = it.next(); System.out.println(&quot;元素标签名：&quot;+element.getName()+&quot;，标签属性：(id = &#x27;&quot;+element.attributeValue(&quot;id&quot;) +&quot;&#x27;, class=&#x27;&quot;+element.attributeValue(&quot;class&quot;)+&quot;&#x27;)&quot; ); &#125; System.out.println(&quot; ====================================== &quot;); // iterate through attributes of root for (Iterator&lt;Attribute&gt; it = root.attributeIterator(); it.hasNext();) &#123; Attribute attribute = it.next(); System.out.println(attribute.getName() + &quot; = &quot; + attribute.getValue()); &#125;&#125;/** * xpath 方式解析 document * @throws Exception */@Testpublic void parseDocumentByXpath() throws Exception &#123; String xml = &quot;&lt;beans&gt;&lt;bean id=\\&quot;userService\\&quot; class=\\&quot;com.github.vianlex.service.impl.UserServiceImpl\\&quot;&gt;&lt;property name=\\&quot;userDao\\&quot; ref=\\&quot;userDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleService\\&quot; class=\\&quot;com.github.vianlex.service.impl.RoleServiceImpl\\&quot;&gt;&lt;property name=\\&quot;roleDao\\&quot; ref=\\&quot;roleDao\\&quot;/&gt;&lt;/bean&gt;&lt;bean id=\\&quot;roleDao\\&quot; class=\\&quot;com.github.vianlex.dao.RoleDao\\&quot;/&gt;&lt;bean id=\\&quot;userDao\\&quot; class=\\&quot;com.github.vianlex.dao.UserDao\\&quot;/&gt;&lt;/beans&gt;&quot;; Document document = DocumentHelper.parseText(xml); // 查找 &lt;bean&gt; 元素 List&lt;Node&gt; beanNodeList = document.selectNodes(&quot;//bean&quot;); for (Node node : beanNodeList) &#123; Element element = (Element) node; System.out.println(element.getName()+ &quot;, &quot; + element.attributeValue(&quot;id&quot;) + element.attributeValue(&quot;class&quot;)); &#125; // 查找 &lt;property&gt; 元素 List&lt;Node&gt; propertyNodeList = document.selectNodes(&quot;//property&quot;); for (Node node : propertyNodeList) &#123; Element element = (Element) node; System.out.println(element.getName()+ &quot;, &quot; + element.attributeValue(&quot;name&quot;) + element.attributeValue(&quot;ref&quot;)); &#125;&#125; 参考链接 https://dom4j.github.io/#top","categories":[{"name":"Xml","slug":"Xml","permalink":"http://example.com/categories/Xml/"}],"tags":[]},{"title":"XPath 笔记","slug":"Xml/XPath 笔记","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/Xml/XPath 笔记/","link":"","permalink":"http://example.com/wiki/Xml/XPath%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"XPath 节点术语在 XPath 中，有七种类型的节点：元素、属性、文本、命名空间、处理指令、注释以及文档（根）节点。XML 文档是被作为节点树来对待的。树的根被称为文档节点或者根节点。 节点关系 父（Parent）， 每个元素以及属性都有一个父节点。 子（Children）, 元素节点可有零个、一个或多个子节点。 同胞（Sibling），拥有相同的父的节点。 先辈（Ancestor），某节点的父节点、及父父节点，等等。 后代（Descendant），某个节点的子节点，及子子节点，等等。 XPath 语法示例语法 XML 实例文档，如下： 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;bookstore&gt; &lt;book&gt; &lt;title lang=&quot;eng&quot;&gt;Harry Potter&lt;/title&gt; &lt;price&gt;29.99&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;title lang=&quot;eng&quot;&gt;Learning XML&lt;/title&gt; &lt;price&gt;39.95&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; 选取节点 表达式 描述 nodename 选取此节点的所有子节点。 &#x2F; 表示文档树的起始 &#x2F;&#x2F; 匹配文档中的任何节点，而不考虑它们的位置。 . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 使用例子： 123456789101112131415# 获取文档中的 bookstore 节点/bookstore# 获取文档 bookstore 节点下的 book 节点/bookstore/book# 获取文档中的所有 book 节点//book# 获取文档中的所有 title 节点 //title# 获取名为 lang 的所有属性//@lang 谓语选择谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中使用。 &#x2F;bookstore&#x2F;book[1] 选取属于 bookstore 子元素的第一个 book 元素。 &#x2F;bookstore&#x2F;book[last()] 选取属于 bookstore 子元素的最后一个 book 元素。 &#x2F;bookstore&#x2F;book[last()-1] 选取属于 bookstore 子元素的倒数第二个 book 元素。 &#x2F;bookstore&#x2F;book[position()&lt;3] 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。 &#x2F;&#x2F;title[@lang] 选取所有拥有名为 lang 的属性的 title 元素。 &#x2F;&#x2F;title[@lang&#x3D;’eng’] 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。 &#x2F;bookstore&#x2F;book[price&gt;35.00] 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 &#x2F;bookstore&#x2F;book[price&gt;35.00]&#x2F;title 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 选取未知节点XPath 通配符可用来选取未知的 XML 元素。 通配符 描述 * 匹配任何元素节点。如 &#x2F;&#x2F;book&#x2F;*，选取 book 节点下面的所有节点，如 //*，选择文档中的所有元素。 @* 匹配任何属性节点。如 &#x2F;&#x2F;title[@*] 选取所有带有属性的 title 元素 node() 匹配任何类型的节点。如 &#x2F;bookstore&#x2F;node() 选取 bookstore 节点下的任何节点 选取若干路径通过在路径表达式中使用“|”运算符，您可以选取若干个路径。 路径表达式 结果 &#x2F;&#x2F;book&#x2F;title &#x2F;&#x2F;book&#x2F;price 选取 book 元素的所有 title 和 price 元素。 &#x2F;&#x2F;title &#x2F;&#x2F;price 选取文档中的所有 title 和 price 元素。 &#x2F;bookstore&#x2F;book&#x2F;title &#x2F;&#x2F;price 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 XPath 轴轴可定义相对于当前节点的节点集。 轴名称 结果 ancestor 选取当前节点的所有先辈（父、祖父等）。 ancestor-or-self 选取当前节点的所有先辈（父、祖父等）以及当前节点本身。 attribute 选取当前节点的所有属性。 child 选取当前节点的所有子元素。 descendant 选取当前节点的所有后代元素（子、孙等）。 descendant-or-self 选取当前节点的所有后代元素（子、孙等）以及当前节点本身。 following 选取文档中当前节点的结束标签之后的所有节点。 namespace 选取当前节点的所有命名空间节点。 parent 选取当前节点的父节点。 preceding 选取文档中当前节点的开始标签之前的所有节点。 preceding-sibling 选取当前节点之前的所有同级节点。 self 选取当前节点。 参考链接 https://www.w3school.com.cn/xpath/index.asp 在线测试地址","categories":[{"name":"Xml","slug":"Xml","permalink":"http://example.com/categories/Xml/"}],"tags":[]},{"title":"软件名称记录","slug":"other/软件名称记录","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/other/软件名称记录/","link":"","permalink":"http://example.com/wiki/other/%E8%BD%AF%E4%BB%B6%E5%90%8D%E7%A7%B0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"1、常见软件名后缀 CE、EE、CS 的说明 1234docker-ce 表示的是 docker 社区版(Community Edition)docker-ee 表示的是 docker 企业版(Enterprise Edition)docker-cs 表示的是 docker 自定义版(Custom Support)","categories":[{"name":"other","slug":"other","permalink":"http://example.com/categories/other/"}],"tags":[]},{"title":"网络设备入门笔记","slug":"计算机网络/网络设备入门笔记","date":"2023-05-31T13:39:26.114Z","updated":"2023-05-31T13:39:26.114Z","comments":true,"path":"wiki/计算机网络/网络设备入门笔记/","link":"","permalink":"http://example.com/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"交换机交换机的作用是通过网线将多台计算机形成一个局域网， 交换机是在集线器的基础上优化而来，集线器的工作原理是把接收到的数据包通过广播的方式发送给插入集线器的所有计算机，在整个局域网中的所有计算机都会接收到这个数据包，并且判断数据包是否发送给自己的，如果是就接收，不是就丢掉。当局域网很小的时候，用集线器问题不大，但是当局域网的设备比较多的时候，每个计算机发的包都广播给集线器的所有端口，网络线路就会很频繁，形成网络风暴，性能就不好了。集线器是无脑的广播数据包，而交换机则更加智能化，交换机传输数据包会直接传输到指定的端口上去，不会每次都广播给所有端口。交换机里面保存了一张 MAC 的地址表，记录计算机(或者其他设备)的 MAC 地址以及其插入交换机的端口位置，当交换机接受到数据包时，会根据数据包中的 MAC 地址在地址表中找到对应的端口，然后将数据包该端口转发到对应的计算中，所有就不需要将数据包广播给所有端口了。如果地址表中没有对应的记录，则将数据包广播到除了源端口之外的所有端口，然后把响应的端口写到地址表中。如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。 路由器路由器就是用来连接两个或多个不同的局域网的。路由器是基于网络层设计的，提供了路由与转发两种重要的机制，每个路由器中都有一个路由表和转发表，路由表用来决策路由，转发表用来转发分组。路由器收到一个数据包后，会检查其目的 IP 地址，然后查找路由表。查找到匹配的路由表项之后，路由器会根据该表项所指示的出接口信息和下一跳信息将数据包转发出去。 交换机和路由器的区别 交换机工作于数据链路层，能识别 MAC 地址，根据 MAC 地址转发链路层数据帧，路由器位于网络层，能识别 IP 地址，根据 IP 地址转发分组； 交换机用于连接局域网，数据包在局域网内网的数据转发，路由器用于连接局域网和外网，数据包可以在不同局域网转发。 NAT 网络NAT 英文全称 Network Address Translation，中文翻译为网络地址转换，它是一种把内部私有网络地址转换成上一级对外输出的网络IP地址。虚拟系统借助 NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。 虚拟网络虚拟网桥(Bridge)虚拟网桥可以看作是一个虚拟的交换机，可以配置 MAC 和 IP 地址，可以使用 veth-pair 虚拟设备(相当于网线)或者虚拟网卡 tun&#x2F;tap 将不同的虚拟机连接到虚拟交换机组成一个虚拟的局域网(VLAN)。如果把网桥、虚拟机网段设置跟宿主机的同一个网段，则虚拟局域网跟宿主机局域网属于平行关系，那么在网络上可以把虚拟机看成一台真正的主机，如果网桥配置的网关跟宿主机不一样，则虚拟局域网跟宿主机的局域网属于两个隔开的网络，如果虚拟机想要通过宿主机访问外网，则需要宿主机开启 开启 IP forward 功能并配置 NAT 地址转换，才能连接到外网。Linux 可以使用 brcti 命令可以操作虚拟的网络。 虚拟 NAT虚拟 NAT 会在宿主机中虚拟出一块网卡来，使得宿主机成为双网卡主机，虚拟网卡带有 NAT 功能，使得虚拟局域网内的虚拟机在对外访问时，使用的则是宿主机的IP地址，这样从外部网络来看，只能看到宿主机，完全看不到新建的虚拟局域网。虚拟 NAT 的缺点是虚拟机可以 ping 通宿主机，但是宿主机 ping 不通虚拟机。 Host-only在 Host-Only 模式下，虚拟网络是一个全封闭的网络，只能能够与宿主机通信。 Host-Only 网络和 NAT 网络很相似，不同的地方就是 Host-Only 网络没有 NAT 服务，所以虚拟网络不能连接到通过宿主机连到外网，Host-Only 的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。 参考链接1、https://blog.csdn.net/qq_21187515/article/details/119375576","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"Excel 设置行高和换行问题","slug":"Apache POI/Excel 设置行高和换行问题","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Apache POI/Excel 设置行高和换行问题/","link":"","permalink":"http://example.com/wiki/Apache%20POI/Excel%20%E8%AE%BE%E7%BD%AE%E8%A1%8C%E9%AB%98%E5%92%8C%E6%8D%A2%E8%A1%8C%E9%97%AE%E9%A2%98/","excerpt":"","text":"Excel 单元格设置强制换行，使用符号 \\r\\n 可以强制换行1234567891011121314151617181920212223242526//单元格数据String data = &quot;假如生活欺骗了你，不要悲伤，不要心急！忧郁的日子里需要镇静，相信吧，快乐的日子将会来临。&quot;// 创建行Row row = sheet.createRow(0);// 设置默认的行高row.setHeight(10);// 创建样式HSSFCellStyle style = workbook.createCellStyle();style.setWrapText(true);// 创建单元格Cell cell = row.createCell(0);cell.setCellStyle(style);//设置默认的列宽sheet.setDefaultColumnWidth(20);// 强制实现换行 dataStringBuilder sbData = new StringBuilder(data)int length = sbData.length();int rowHeightLine = 1; for(int i = width - 1; i &lt; length; i = i + width + 1 ) &#123; System.out.println(&quot;换行符位置：&quot; + i); sbData.insert(i, &quot;\\r\\n&quot;); rowHeightLine++;&#125;row.setHeight(row.getHeight() * rowHeightLine)cell.setCellValue(sbData.toString()); 参考链接https://stackoverflow.com/questions/19145628/auto-size-height-for-rows-in-apache-poi#","categories":[{"name":"Apache POI","slug":"Apache-POI","permalink":"http://example.com/categories/Apache-POI/"}],"tags":[]},{"title":"Docker Swarm 笔记","slug":"Docker/Docker Swarm 笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/Docker Swarm 笔记/","link":"","permalink":"http://example.com/wiki/Docker/Docker%20Swarm%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Swarm 介绍Swarm 是多个以 Swarm Mode 运行的 Docker 主机组成的集群，Swarm 集群中的 Docker 主机可以充当管理节点（Manager）、工作节点（Worker）或者两者都可以。 管理节点：主要负责整个集群的管理工作包括集群配置、服务管理等所有跟集群有关的工作。 工作节点：主要负责执行运行服务的任务。 Swarm 基本概念Swarm 集群管理涉及的抽象对象有三个分别是 Node、Task、Service。 节点(node)：Swarm 的管理节点(manager)和工作节点(worker)的统称。 任务(Task)： Task 是 Swarm 中的最小的调度单位，一个运行的容器就是一个 Task。 服务(Service)：Service 是由一组 Task 组成构成。可以把 Task 看作是 k8s 的 Pod，Service 相当于 K8s 的 Deployment 等工作负载。Service 又分为以下两种： replicated services 按照一定规则在各个工作节点上运行指定个数的任务。 global services 每个工作节点上都会运行 Service 中的任务。 负载均衡(Load balancing)：Swarm 通过 ingress 负载均衡暴露 Service 外部访问。如果你没有定义端口，则 Swarm 会默认暴露 30000-32767 范围内的一个端口。当有请求访问服务时，Swarm 通过内部的负载均衡将请求分发到相应的 Task 中。 注意：当你通过 Docker Swarm 创建一个 service 时，你定义了它的理想状态（副本数、网络、存储资源、对外暴露的端口等）。Docker会维持它的状态，例如，如果一个 worker node 不可用了，Docker Swarm 会调度不可用 node 上的 task 到其他 nodes 上。运行在容器中的一个 task，是 swarm service 的一部分，且通过 swarm manager 进行管理和调度，和独立的容器是截然不同的。Swarm service 相比单容器的一个最大优势就是，你能够修改一个服务的配置：包括网络、数据卷，不需要手工重启服务。Docker 将会更新配置，把过期配置的 task 停掉，重新创建一个新配置的容器。 Swarm 节点管理 查看节点信息1docker node ls 获取添加工作节点或者管理节点的 token1234# 获取加入工作节点的 token docker swarm join-token worker# 管理节点 docker swarm join-token manager 节点脱离 swarm 集群12# -- force 表示强制离开集群docker swarm leave [--force] 删除集群某个节点1docker node remove &lt;节点名称|节点ID&gt; 部署服务通过 docker service create命令可以快速部署服务，该命令语法格式为：docker service create &lt;--name 服务名字&gt; &lt;--replicas task副本数&gt; &lt;image&gt; [容器运行后要执行的命令]，常用可选参数如下： –name 指定服务的名字 –replicas 指定 Task 的副本数量 -w, –workdir 指定容器的工作目录 env 指定环境变量，如 -env JAVA_OPS=&quot;&quot; –mount 容器目录挂载到主机目录，如：--mount host/xxx/xxx:container/xxx/xxx 或者 --mount type=bind,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt; ，推荐使用第二种新语法，比较明了 -p, –publish port 指定端口，如：-p host-port:container-port 或者 --publish published=&lt;host-port&gt;,target=&lt;container-port&gt;，推荐使用第二种新语法，比较明了 –update-delay 设置滚动更新延迟时间，即为多个副本任务的更新间隔时间 –update-parallelism 每次并发更新的任务数量 –mode 指定服务的运行模式可选值有：replicated(按一定规则调度 task 到合适的 node), global(每个工作节点都运行一个 task), replicated-job, global-job 创建服务 1234# 创一个名 test-swarm 的服务，运行2个副本任务容器docker service create --name test-swarm -p 2000:80 --replicas 2 nginx:latest endpoint_mode=dnsrr 查看正在运行的 services，使用如下命令 1docker service ls 查看 service 信息，使用命令 docker service inspect --pretty &lt;服务名&gt; 12# 查看名为 test-swarm 的 service 详细信息docker service inspect --pretty test-swarm 使用命令docker service ps &lt;服务名&gt;查看服务 Task 的运行信息 12# 查看 test-swarm 服务中 task 的运行情况 docker service ps test-swarm 使用命令docker service update &lt;选项参数&gt; &lt;服务名&gt;，具体支持哪些配置的更新改动可以使用帮助命令查看 docker serivce update --help 12345# 新增 3000:80 端口映射docker service update --publish-add 3000:80# 删除端口映射docker service update --publish-rm 3000:80 扩容增加任务副本数量 1234# 将 test-swarm 服务的任务副本数量修改为 3docker service scale test-swarm=3# 等同以上命令docker service update --replicas 3 test-swarm 删除服务，使用命令 docker service rm &lt;服务名&gt; 12# 删除 test-swarm 服务docker service rm test-swarm 查看服务的日志，使用命令 docker service logs [OPTIONS] &lt;SERVICE|TASK&gt; 12# 查看服务 test-swarm 的日志docker service logs -f --tail=200 test-swarm 部署多个服务批量部署多个服务需要使用 docker stack 命令和 docker-compose.yaml 配置文件，docker stack 是 docker serice 在基础上封装了一层，一个 stack 管理着多个 serivces，docker stack 常用命令如下： docker stack deploy 部署或者更新 stack docker stack ls 查看已部署的 stack 列表 docker stack ps 查看 stack 部署的服务下的任务列表 docker stack rm 删除一个 stack docker stack services 查看 stack 部署的所有服务 定义 stack 使用的 docker-compose 文件，配置说明 12345678910111213141516171819202122version: &#x27;3.7&#x27;services: my-web: image: nginx:latest ports: - target: 80 # 容器端口 published: 8080 # 主机端口 protocol: tcp # 可选值 tcp、udp mode: ingress # 可选值 host、ingress 默认 ingress # 注意如果没有配置 deploy 属性的话，ports 属性中 mode 配置的 ingress 模式是不起作用的，会模式为 host 模式 deploy: mode: replicated # 可选值 replicated 和 global 默认值 replicated replicas: 2 # 配置服务副本数量 endpoint_mode: vip # 配置服务发现模式，可选值 vip 和 dnsrr, 默认值 vip # 配置重启策略 restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s 使用 docker stack deploy 命令部署服务，命令语法 docker stack deploy [OPTIONS] STACK(表示 stack 名)，常用选项如下： –compose-file , -c 指定 docker-compose 配置文件12# 通过 docker-compose 配置文件部署一个名为 mystack 的 stack，部署后生成的服务名格式为：stack 名 + docker-compose 文件配置的服务名，即 mystack_my-webdocker stack -c docker-compose.yml mystack 服务发现和负载均衡Service 相当于它的所有 Task 的一个反向代理，Service 的服务发现和负载均衡是利用 Linux 内核的 iptables 和 IPVS 的功能来实现。Docker Swarm 提供了两种不同机制的服务发现，分别是： VIP(Virtual IP)：Swarm 创建应用服务时，会创建一个应用服务的虚拟 IP，Docker 内嵌的 DNS 服务会维护该虚拟 IP 和应用服务名记录，同时在每个应用服务容器内创建一个 ingress_sbox 网络命令空间，然后利用 Linux 内核的 iptables 和 IPVS 在 ingress_sbox 网络命名空间通过 VIP 转发请求到服务容器的 IP，从而实现负载均衡。 DRR(DNS round-robin)：通过 Docker 引擎提供的内嵌 DNS 服务，维护服务名对应 task 容器的 IP 地址列表，当前请求访问服务时，Docker DNS 解析服务名，获取服务所有任务容器的 IP 地址列表，然后将请求转发到其中任意一个(一般默认是第一)，从而实现负载均衡。 Docker Swarm 通过 ingress overlay 网络实现了网格路由(routing mesh)功能。在 Swarm 集群中所有的工作节点(worker)和管理节点(manager)都会参与到网格路由中。当部署的服务通过 --publish 暴露端口时，由于所有的节点都在网格路由(routing mesh)中，所以全部的节点都会是监听--publish暴露的端口，因此访问集群中的任何节点都可以访问到服务。 如果不想每个节点都监听服务暴露的端口，则需要将暴露的模式指定为 host 模式，来禁用路由网格，如 --publish published=8080,target=80,mode=host 。 路由网格模式只支持 VIP 的服务发现模式，如果使用 DRR 模式是不起作用的。可以通过 --endpoint_mode: vip | drr 指定服务选择那种服务发现，默认是 vip 管理节点和工作节点的心跳12# 修改检测心跳1分钟docker swarm update --dispatcher-heartbeat 60s 参考链接 https://docs.docker.com/engine/swarm/swarm-tutorial/ https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/ https://docs.docker.com/engine/swarm/networking/","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Docker 入门笔记","slug":"Docker/Docker 入门笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/Docker 入门笔记/","link":"","permalink":"http://example.com/wiki/Docker/Docker%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"2. Docker 网络原理Docker 服务进程启动时，默认会创建一个 docker0 虚拟网桥，也就是虚拟交换机，docker0 的默认 IP 地址为172.17.0.1，子网掩码为255.255.0.0。在 Linux 系统中可以使用命令 brctl show 可以查看虚拟网桥，如果命令不存在，需要安装 bridge-utils 软件。 2.1 Docker 网络模式Docker 默认支持4种网络工作模式，如下： Host 模式：容器内部网络空间共享主机的空间，效果类似直接在宿主机上启动一个进程，端口信息和宿主机共用； Container 模式：启动时使用参数 -net &#x3D; container:[名称|id] 指定当前启动容器与 -net 指定的已存在的容器共享网络，使用其网络命名空间。 None 模式：该模式关闭了容器的网络功能，但是还会保留网络命名空间，只是不创建虚拟网卡和相关网络配置。 Bridge 模式：该模式是 Docker 默认网络模式，容器启动时会将容器连接到一个 docker0 虚拟网桥，通过 docker0 网桥以及宿主机 Iptables nat 表配置与宿主机通信。 2.1.1 Container 模式2.1.2 Bridge 模式Bridge 网桥是虚拟交换机，工作于数据链路层，主要的功能是根据 MAC 地址将数据包转发到网桥的不同端口上。Docker 网桥模式的示意图如下： Docker 创建启动一个容器的时候，会在宿主机中创建一对虚拟接口&#x2F;网卡 Veth Pair，虚拟端口的一端桥接到 docker0 网桥，在宿主机中使用 ifconfig | grep veth 可以查看到，其命名的方式前缀固定 Veth 后缀随机，如 veth080517f，虚拟端口的另一端连接到新启动的容器内部网络中，因为容器内跟宿主机的网络命名空间是隔离的，所其名字会被命名给 eth0，然后从网桥的可用地址段中获取一个空闲地址分配给容器的 eth0。 参考链接1、https://blog.csdn.net/m0_49654228/article/details/117446963","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Docker 常用命令","slug":"Docker/Docker 常用命令","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/Docker 常用命令/","link":"","permalink":"http://example.com/wiki/Docker/Docker%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"docker 镜像查看、删除等相关命令1. docker images 命令查看本地镜像仓库中的镜像docker images 语法格式 docker images [OPTIONS] [REPOSITORY[:TAG]]，可选参数如下： docker images -a 列出本地所有的镜像 docker images -f 过滤查询镜像 docker images -q 列出显示镜像 ID1234567891011121314151617181920212223242526272829303132333435363738# 查看所有镜像docker images # 根据 &lt;REPOSITORY&gt;[:TAG] 显式的过滤查看镜像，注意当使用 * 模糊匹配时，无法匹配 / 符号，如匹配 vianlex/nginx:dev-latest 镜像，支持以下方式匹配docker images vianlex/nginxdocker images vianlex/nginx:dev-latestdocker images &quot;*/nginx*&quot;docker images &quot;*/nginx:dev-*&quot;# 只是查看镜像的 iddocker images -q# 匹配标签(tag)为&lt;none&gt;的镜像docker images -f=&quot;dangling=true&quot;# 根据 reference=&lt;REPOSITORY&gt;[:TAG] 模糊匹配镜像，注意匹配时，reference=&lt;REPOSITORY&gt;[:TAG] 中的 / 符号不能无法使用 * 模糊匹配，如匹配镜像 vianlex/nginx:dev-latestdocker images -f=&quot;reference=*/nginx&quot; 或者 docker images -f &quot;reference=*/nginx&quot;docker images -f=reference=&quot;*/nginx&quot; 或者 docker images -f reference=&quot;*/nginx&quot; #或者docker images -f=&quot;reference=*/nginx:dev-*&quot;docker images -f=reference=&quot;*/nginx:dev-*&quot;# 根据 before 或者 since 过滤镜像，格式为 before=&lt;REPOSITORY&gt;[:TAG] 或者 before=image-iddocker images -f before=&quot;eb4d124f64cd&quot; # 根据镜像 ID 查找创建时间大的镜像docker images -f since=&quot;vianlex/nginx:dev-latest&quot; # 根据镜像名称查找创建时间小的镜像# 根据 label=&lt;key&gt; 或者 label=&lt;key&gt;=&lt;value&gt; 过滤镜像，label 是在 dockerfile 中定义的，可以使用 docker inpsect 命令可以查看镜像的 labelsdocker images -f=&quot;label=version&quot;#或者docker images -f=&quot;label=version=v1&quot;# 格式镜像列表的输出格式docker images --format &quot;&#123;&#123;.Repository&#125;&#125; -- &#123;&#123;.ID&#125;&#125; -- &#123;&#123;.Size&#125;&#125;&quot;# 或者docker images --format &quot;&#123;&#123;.Repository&#125;&#125; &#123;&#123;.ID&#125;&#125; &#123;&#123;.Size&#125;&#125; &#123;&#123;.di&#125;&#125;&quot;# 或者 docker images --fotmat &quot;&#123;&#123;.ID&#125;&#125;&quot; 2. docker rmi 命令删除 docker 镜像docker rmi 命令语法格式：docker rmi [ repository:tag | imageId ] ，可选参数 -f 指定强制删除 123456789101112# 根据镜像仓库加标签删除 docker rmi nginx:latest# 根据镜像 ID 删除docker rmi 43154ddb57a8# 根据镜像 id 批量删除 docker images -q | xargs docker rmi # 或docker rmi $(docker images -q)# 删除 tag 是 none 的所有镜像docker rmi $(docker images -f &quot;dangling=true&quot; -q) docker 操作容器的常用命令1. docker run 命令用于创建并启动 Docker 容器，常用参数如下： -d, –detach&#x3D;false 指定容器以后台进程的方式运行 -i, –interactive&#x3D;false 以交互模式运行容器，通常与 -t 同时使用 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用 –name&#x3D;”myNginx” 指定容器名字，方便管理 –dns 8.8.8.8 指定容器使用的 DNS 服务器，默认和宿主一致 –dns-search&#x3D; example.com 指定容器的 dns 搜索域名，会写入到容器的 &#x2F;etc&#x2F;resolv.conf 文件 -h “linux-hostname” 指定容器的 hostname -w, –workdir&#x3D;”&#x2F;opt” 指定容器的工作目录 -e username&#x3D;centeos, –env&#x3D;[] 设置容器的环境变量 –env-file&#x3D;[] 从指定文件读入环境变量 -v, –volume&#x3D;[] 给容器挂载存储卷，挂载到容器的某个目录。 –dns&#x3D;[] 指定容器的 dns 服务器。 -P 随机端口映射，容器内部端口随机映射到主机的端口 -p 指定端口映射，格式为：主机(宿主)端口:容器端口 –entrypoint&#x3D;”” 覆盖 image 的入口点。 –env-file&#x3D;[] 指定环境变量文件，文件格式为每行一个环境变量。 –expose&#x3D;[] 指定容器暴露的端口，即修改镜像的暴露端口。 –link&#x3D;[] 指定容器间的关联，使用其他容器的 IP、env 等信息。 -net&#x3D;”bridge” 指定容器网络配置 –privileged&#x3D;false 指定容器是否为特权容器，特权容器拥有所有的 capabilities。 –restart&#x3D;”no” 指定容器停止后的重启策略: –rm&#x3D;false 指定容器停止后自动删除容器(不支持以 docker run -d 启动的容器)。12#创建并启动 nginx 容器docker run -p 81:80 -v /data:/usr/share/nginx/html --name mynginx -d nginx:latest 2. docker ps 查看容器常用的可选参数 -q, –quiet 只显示容器的 ID –format 格式化输出结果 -f, –filter 过滤显示结果，使用 key&#x3D;value 的方式过滤，如-f name=myNginx，可选的过值对如下： id 根据容器的 id 过滤 name 根据容器名称过滤 ancestor 根据镜像信息过滤，如 -f ancestor &lt;image-name&gt;[:&lt;tag&gt;] | &lt;image id&gt; status 根据状态进行过滤，可选值有 created, restarting, running, removing, paused, exited, or dead publish or expose 根据端口过滤，如 -f publish &lt;port&gt;[/&lt;proto&gt;] 或者 -f expose &lt;startport-endport&gt;/[&lt;proto&gt;] before or since 根据创建时间或者容器名的前后过滤 label 根据标签过滤1234567891011docker ps --filter &quot;label=color&quot;docker ps --filter &quot;name=xxxxx&quot;docker ps --filter status=runningdocker ps --filter ancestor=nginx:latest# 显示创建比容器 9c3527ed70ce 早的所有容器 docker ps -f before=9c3527ed70ce 2. docker stop 停止正在运行的容易docker stop 语法格式 docker stop [--time , -t] container [container...] 停止一个或者多个正在运行的容器，可选参数 -t 指定运行命令多少秒后停止容器 12345# 根据容器 id 停止容器docker stop 9c3527ed70ce# 根据条件过滤停止容器docker stop $(docker ps -q -f name=myNginx) 3. docker start 启动容器12# 根据容器名称或者id启动容器docker start [container-name|container-id] 4. docker restart 者重启容器可选参数 --time, -t 指定多少秒后停止并重启容器 1234# 根据容器 id 重启容器docker restart 9c3527ed70cedocker restart $(docker ps -q -f name=myNginx) 5. docker rm 删除容器可以删除一个或者多个容器，可参数 -f 强制删除 12# 删除容器，docker rm [container-name|container-id] 6. docker logs 查看容器运行日志1234567891011#查看实时的日志：sudo docker logs -f --tail 100 container_id 或者 container_name#查看指定时间后的日志，只显示最后100行：docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 container_id#查看最近30分钟的日志:docker logs --since 30m container_id#查看某时间段日志：docker logs -t --since=&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; container_id 7. docker exec 命令在宿主机运行容器中的命令，使用例子如下： 12345678# 进入容器的终端命令行docker exec -it [container_id | container_name] [/bin/sh | /bin/bash] # 查看容器的文件内容docker exec [container_id | container_name] cat /logs/ils.2020-08-19.log # 运行容器的命令docker exec -it [container_id | container_name] nginx -s reload 8. docker cp 命令将容器中的文件复制到宿主机中或者将宿主机的文件复制容器中 12345# 将容器文件复制到宿主机中docker cp [container_id | container_name]:/xxx/xxx /home/xxxxxx# 将宿主机文件复制到容器中docker cp /home/xxxxxx [container_id | container_name]:/xxx/xxx 归档镜像导入导出1. docker save 命令将 Docker 镜像保存成 tar 包docker save 命令语法 docker save [ -o | --output | &gt; ] filename.tar [ reposity:tag | imageId ] 1234#第一种方式docker save -o flannel.tar rancher/mirrored-flannelcni-flannel:v0.20.0#第二种方式docker save -o &gt; flannel-cni-plugin.tar fcecffc7ad4a 2. docker load 命令将镜像归档文件导入镜像仓库docker load 命令语法 docker load [ --input | &lt; ] filename.tar 12345# 第一种方式docker load --input filename.tar# 第二种方式docker load &lt; filename.tar 参考连接 https://docs.docker.com/engine/reference/commandline/images/","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Docker 权限配置","slug":"Docker/Docker 权限配置","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/Docker 权限配置/","link":"","permalink":"http://example.com/wiki/Docker/Docker%20%E6%9D%83%E9%99%90%E9%85%8D%E7%BD%AE/","excerpt":"","text":"新增 docker 用户组查看 docker 用户组是否存在 1sudo cat /etc/group | grep docker docker 用户组不存在则新建一个 1234# 创建用户组sudo groupadd docker# 给用户组设置权限sudo a+rw /var/run/docker.sock 将当前用户添加 docker 用户组1sudo gpasswd -a $&#123;USER&#125; docker 临时切换到 docker 组12newgrp docker 重启 docker 服务12sudo service docker restart","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Dockerfile 使用说明","slug":"Docker/Dockerfile 使用说明","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/Dockerfile 使用说明/","link":"","permalink":"http://example.com/wiki/Docker/Dockerfile%20%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","excerpt":"","text":"docker 构建忽略文件 .dockerignore，指定构建上下文中可以复制哪些文件, 文件格式如下12345678# * 表示忽略全部文件* # ! 表示可以排除哪些文件，不需要忽略 !package.json!nuxt.config.js !.nuxt !static COPY 命令无法复制文件夹，则可以利用 .dockerignore 来实现复制文件夹123456# 比如想将 static 文件夹和其目录下的文件都复制到 /path 下，是无法实现的，COPY 只会将 static 目录中的文件复制到 /path 下，static 文件夹本身无法复制COPY static /path/# 这种方式可以复制文件夹，如将当前构建上下文中的文件，全部复制到 /path 目录下，COPY 命令会根据 .dockerignore 文件判断哪些文件可以复制，哪些文件不能复制COPY . /path/","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Docker 安装笔记","slug":"Docker/docker 安装笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/docker 安装笔记/","link":"","permalink":"http://example.com/wiki/Docker/docker%20%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/","excerpt":"","text":"使用 YUM 命令安装 安装 docker 依赖软件1yum install -y yum-utils device-mapper-persistent-data lvm2 添加 docker 软件源1234# 查看是否 docker 软件源文件, 不存在，则用 wget 下载ls -il /etc/yum.repos.d/docker-ce.repo # 下载 docker 软件源文件，并保存到 /etc/yum.repos.d/docker-ce.repowget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo 安装 docker 1234# 查看可安装的版本 yum --showduplicates list docker-ce# 安装指定的版本yum -y install docker-ce-19.03.13-3.el8 设置 docker 开机自启,并启动 docker1systemctl enable docker &amp;&amp; systemctl start docker 查看 docker 版本，如果显示成功，表示安装成功1docker --version CentOS8 使用 dnf 安装最新版 安装 Docker 存储驱动的依赖包，使用的 dnf 命令，centos8 开始使用dnf替代yum管理软件1dnf install -y device-mapper-persistent-data lvm2 添加 Docker 软件源1dnf config-manager --add-repo=https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 查看已添加的 Docker 软件源, 如果命令结果有返回 docker-ce.x86_64 说明添加成功1dnf list docker-ce 开始安装 Docker1dnf install -y docker-ce --nobest docker 启动相关命令12345678910#重新加载配置文件systemctl daemon-reload #运行Docker守护进程systemctl start docker #停止Docker守护进程systemctl stop docker #重启Docker守护进程systemctl restart docker #设置Docker开机自启动 systemctl enable docker 手动离线安装 根据需要下载指定的 docker 安装包1https://download.docker.com/linux/static/stable/x86_64/docker-19.03.10.tgz 解压 docker 安装包1tar -xvf docker-19.03.10.tgz 将解压出来的 docker 目录复制或者移动到 &#x2F;usr&#x2F;bin 目录中1mv docker /usr/bin/ 创建 docker.service 文件，并将文件复制到目录 /etc/systemd/system/ 中，并添加可执行权限 chmod +x /etc/systemd/system/docker.service，目的是使用 systemd 管理和控制 docker ，以守护进程的方式运行，方便设置开机自启。docker.service 的文件内容，如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comBindsTo=containerd.serviceAfter=network-online.target firewalld.service containerd.serviceWants=network-online.targetRequires=docker.socket[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemdExecReload=/bin/kill -s HUP $MAINPIDTimeoutSec=0RestartSec=2Restart=always# Note that StartLimit* options were moved from &quot;Service&quot; to &quot;Unit&quot; in systemd 229.# Both the old, and new location are accepted by systemd 229 and up, so using the old location# to make them work for either version of systemd.StartLimitBurst=3# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make# this option work for either version of systemd.StartLimitInterval=60s# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Comment TasksMax if your systemd version does not support it.# Only systemd 226 and above support this option.TasksMax=infinity# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process[Install]WantedBy=multi-user.target 设置开机自启和启动 docker 1systemctl enable docker &amp;&amp; systemctl start docker 卸载，直接删除 docker.service 文件和复制到 &#x2F;usr&#x2F;bin 中的 docker 目录即可","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Docker-compose 学习记录","slug":"Docker/docker-compose 学习记录","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Docker/docker-compose 学习记录/","link":"","permalink":"http://example.com/wiki/Docker/docker-compose%20%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"docker-compose 介绍docker-compose 是用来定义和管理多容器运行的 docker 应用程序，通过 YAML 配置文件和简单的 Docker-Compose 命令就可以管理和控制 docker 容器的生命周期和日志，其可以看作是 docker 容器自动化管理工具。 docker-compose 是以 project 和 service 的概念去管理 docker 容器的，每一个容器是一个 service，每一个或者多个 docker-compose 配置文件所在的目录是一个 project, project 的名称默认是配置文件的上层目录名。 注意 docker-compose 管理的是 service, 所以 dokcer-compose 命令是以 service 维度去操作管理 docker 容器的。 docker-compose 常用命令的简单介绍docker-compose 命令运行时，会默认读取当前目录的 docker-compose 配置文件，如果 docker-compose 命令运行所在目录不存在 docker-compose 文件，则需要要使用 -f 指定 docker-compose 配置文件或者指定使用 -p 指定 project 的名称。 docker-compse 命令详细用法使用 --help 方式查看，如果查看 docker-compose ps 的详细用法，运行 docker-compose ps --help 命令即可。以下是 docker-compose 部分命令解释说明。 docker-compose pull根据 docker-compose 配置文件拉取镜像 1234567# 默认拉取 docker-compose 配置文件所有 service 的镜像docker-compose pull # 根据服务名称拉取单个或者多个服务的镜像docker-compose pull [service-name]docker-compose pull [service-name1] [serivce-name2] docker-compose create创建或者重建运行中容器，命令执行成功后，容器的状态都是 Created 状态，表示只是创建了容器，并未运行容器，所以要注意重建运行中的容器后，容器的状态将由 Running 状态变成 Created 服务无法在使用，必须要 docker-compose start 启动容器后才可以。 1234567# 根据 docker-compose 配置文件中的镜像创建容器或者重建运行中的容器，容器的状态会变成 Created 状态docker-compose create # 根据一个或者多个服务名称创建或者重建运行中的容器docker-compose create [service-name]docker-compose create [service-name1] [service-name2] docker-compose start启动 Created 状态的容器，命令执行成功后，容器状态变成 Running 状态 1234567# 根据 docker-compose 配置文件启动所有 Created 状态的容器docker-compose start # 根据一个或者多个服务名启动 Created 状态的容器docker-compose start [service-name1] docker-compose start [service-name1] [service-name2] docker-compose run创建容器并启动容器，等价于运行 docker-compose create 和 docker-compose start 命令 12# 以后台守护进程的方式创建和运行 docker-compose 配置文件中的镜像容器docker-compose up -d dockerc-compose down停止和删除 docker-compose 配置文件中的所有容器和网络 1docker-compose down docker-compose logs查看容器日志 12# 根据服务名查看容器的日志docker-compose logs &lt;service-name&gt; -f --tail=200 docker-compose exec运行容器中的命令或者进入容器内容 123456789# 根据服务名进入容器内部docker-compose exec -it &lt;service-name&gt; &lt;/bin/sh | /bash&gt;# 根据服务名运行容器中的命令docker-compose exec -it &lt;service-name&gt; ls -ildocker-compose exec -it &lt;service-name&gt; env # 查看环境变量docker-compose exec -it &lt;service-name&gt; nginx -t # 运行 nginx 配置文件验证命令 docker-compose cp将容器的文件或者文件夹复制到宿主机中 12345# 将宿主机中的 /home/sysadmin/data/hello.txt 文件复制到容器的 /data 目录下docker-compose cp /home/sysadmin/data/hello.txt &lt;serivce-name&gt;:/data# 将容器中的 /data/hello.txt 文件复制到宿主机的 /home/sysadmin/data 目录下docker-compose cp &lt;serivce-name&gt;:/data/hello.txt /home/sysadmin/data","categories":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"}],"tags":[]},{"title":"Go 基础语法","slug":"Golang/Go 基础语法","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Golang/Go 基础语法/","link":"","permalink":"http://example.com/wiki/Golang/Go%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","excerpt":"","text":"","categories":[{"name":"Golang","slug":"Golang","permalink":"http://example.com/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"http://example.com/tags/go/"}]},{"title":"Class 对象和 Tpye 对象知识笔记","slug":"Java 知识点/Class对象和Tpye对象","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/Class对象和Tpye对象/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/Class%E5%AF%B9%E8%B1%A1%E5%92%8CTpye%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"类对象 常见的类对象如下： class：外部类、成员类（成员内部类、静态内部类）、局部内部类、匿名类 interface：接口 []：数组 enum：枚举类 annotation：注解类@interface primitive：基础（原始）数据类型 void 空类 测试例子说明 1234567891011121314151617181920212223@Testpublic void test() &#123; // 外部类类对象 System.out.println(Object.class); // 接口类对象 System.out.println(List.class); // 数组类对象 System.out.println(String[].class); System.out.println(int[][].class); // 注解类对象 System.out.println(Override.class); // void 类对象 System.out.println(void.class); // 类对象，比较 int[] a = new int[10]; int[] b = new int[20]; System.out.println(a.getClass() == b.getClass()); // true&#125; Type 对象Type 是 Java 中所有类型共同的超级接口，其中包含 raw types（原始类型）, parameterized types（参数化类型）, array types（数组类型）, type variables（类型变量类型） and primitive types（原生基础类型）。 Type 接口的类 UML 图如下，它有 4 个子接口 GenericArrayType，ParameterizedType，TypeVariable，WildcardType 和一个实现类 Class。 Class 类，表示 raw types（原始类）和基础类型，指的是普通类、枚举、接口、注解、数组、基本类型（int，double），等等不是泛型的类型； GenericArrayType 表示的泛型数组类型，如 T[] 等等； ParameterizedType 表示的是泛型类型，指的是 List，Map&lt;K,V&gt; 等泛型类型; TypeVariable 表示的是泛型类型变量，如 List 中的泛型变量 T； WildcardType 通配符泛型也叫做泛型表达式类型，如 List&lt;? extends Number&gt;。 测试说明例子，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 测试例子输出结果如下： * ParameterizedType = java.util.Map&lt;java.lang.String, java.lang.Object&gt; actualTypeArguments = java.lang.String,java.lang.Object * ParameterizedType = java.util.List&lt;java.lang.String&gt; actualTypeArguments = java.lang.String * ParameterizedType = java.util.List&lt;? extends java.lang.Number&gt; actualTypeArguments = ? extends java.lang.Number * ParameterizedType = java.lang.Class&lt;?&gt; actualTypeArguments = ? * GenericArrayType = T[] arrayType = T * K * V */ @Test public void test02() &#123; TypeTest&lt;String&gt; typeTest = new TypeTest&lt;String&gt;(); // 通过反射的方式，获取所有生命定义的字段 Field[] declaredFields = typeTest.getClass().getDeclaredFields(); for (Field declaredField : declaredFields) &#123; // 反射获取字段的 Type 类型对象 Type type = declaredField.getGenericType(); // 判断类型 if (type instanceof ParameterizedType) &#123; ParameterizedType pt = (ParameterizedType) type; // 泛型变量的实际类型 String actualTypeArguments = Arrays.stream(pt.getActualTypeArguments()).map(item -&gt; item.getTypeName()).collect(Collectors.joining(&quot;,&quot;)); System.out.println(&quot;ParameterizedType = &quot; + pt.getTypeName() + &quot; actualTypeArguments = &quot; + actualTypeArguments); &#125; if (type instanceof WildcardType) &#123; WildcardType wt = (WildcardType) type; System.out.println(&quot;WildcardType = &quot; + wt.getTypeName()); &#125; if (type instanceof GenericArrayType) &#123; GenericArrayType gat = (GenericArrayType) type; System.out.println(&quot;GenericArrayType = &quot; + gat.getTypeName() + &quot; arrayType = &quot; + gat.getGenericComponentType().getTypeName()); &#125; &#125; // 通过 map 实例的方式只能获取泛型定义的变量，取不到实际的泛型变量类型，只有通过类成员变量然后通过反射 Field 获取 type 的方式的才能取到，如上。 Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); TypeVariable&lt;? extends Class&lt;? extends Map&gt;&gt;[] typeParameters = map.getClass().getTypeParameters(); for (TypeVariable&lt;? extends Class&lt;? extends Map&gt;&gt; typeParameter : typeParameters) &#123; // 输出 K, V System.out.println(typeParameter.getTypeName()); &#125; &#125; 获取泛型类型的实际类型泛型的本质是参数化类型，想要获取泛型参数化类型的实际类型，只有通过反射成员变量、继承、构造函数等方式获取 Type 对象强转 ParameterizedType 类型对象，或者直接通过放射获取 ParameterizedType 的方式，才能获取到泛型类型变量的实际类型。因为只有 ParameterizedType 对象的 getActualTypeArguments 方法能能够方法泛型的实际变量类型。 通过反射类成员变量的方式获取： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.lang.reflect.Field;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.lang.reflect.TypeVariable;public class GenericTest &#123; private Map&lt;String, Object&gt; memberMap = new HashMap&lt;String, Object&gt;(); public static void main(String[] args) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); // 直接通过 Map 对象的方式，只能获取 map 对象的声明的泛型变量，获取不是实际的泛型变量类型 TypeVariable&lt;? extends Class&lt;? extends Map&gt;&gt;[] typeParameters = map.getClass().getTypeParameters(); for (TypeVariable&lt;? extends Class&lt;? extends Map&gt;&gt; typeParameter : typeParameters) &#123; // 会打印 Map&lt;K, V&gt; 中的 K 和 V System.out.println(typeParameter.getTypeName()); &#125; // 间接通过类成员变量的方式，可以获取 Map对象实际的泛型变量类型 Field field = ClassAndTypeTest.class.getDeclaredField(&quot;memberMap&quot;); Type type = field.getGenericType(); ParameterizedType pt = (ParameterizedType)type; for(Type t : pt.getActualTypeArguments()) &#123; // 会打印出泛型变量的实际类型，java.lang.String 和 java.lang.Object System.out.println(t.getTypeName()); &#125; &#125;&#125;2. 通过成员方法的参数和返回类型的方式获取泛型的实际类型```javapublic class HelloWorld &#123; @Test public void test()&#123; try &#123; Method helloMethod = TypeTest.class.getDeclaredMethod(&quot;hello&quot;, List.class); System.out.println(helloMethod.getName()); // 获取 Type 对象，然后强转 ParameterizedType 对象，因为只有 ParameterizedType 类型对象，才能获取泛型变量的实际类型。 Type genericReturnType = helloMethod.getGenericReturnType(); if (genericReturnType instanceof ParameterizedType) &#123; ParameterizedType pt = (ParameterizedType)genericReturnType; System.out.println(&quot;返回的泛型类型 = &quot; + Arrays.stream(pt.getActualTypeArguments()).map(Type::getTypeName).collect(Collectors.joining())); &#125; Type[] genericParameterTypes = helloMethod.getGenericParameterTypes(); for (Type genericParameterType : genericParameterTypes) &#123; if (genericParameterType instanceof ParameterizedType) &#123; ParameterizedType pt = (ParameterizedType)genericParameterType; System.out.println(&quot;参数的泛型类型 = &quot; + Arrays.stream(pt.getActualTypeArguments()).map(Type::getTypeName).collect(Collectors.joining())); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; &#125; public List&lt;Integer&gt; hello(List&lt;String&gt; paramList)&#123; return new ArrayList&lt;Integer&gt;(); &#125;&#125; 通过继承方式获取泛型变量的实际类型 123456789101112131415161718192021public class Hello&lt;T&gt;&#123; public static void main(String[] args) &#123; Hello&lt;String&gt; hello = new Hello&lt;String&gt;(); // 直接通过 class 对象的只能超类或者接口的 Type，所以想要获取 Hello 类的泛型变量实际类型，必须通过其子类方能获取，相当包了一层，如下 World 类 Type genericSuperclass1 = hello.getClass().getGenericSuperclass(); Type[] genericInterfaces = hello.getClass().getGenericInterfaces(); World world = new World(); // 获取 type 类型对象，然后强转 ParameterizedType Type genericSuperclass = world.getClass().getGenericSuperclass(); if (genericSuperclass instanceof ParameterizedType) &#123; ParameterizedType pt = (ParameterizedType)genericSuperclass; System.out.println(&quot;获取父类的泛型类型 = &quot; + Arrays.stream(pt.getActualTypeArguments()).map(Type::getTypeName).collect(Collectors.joining())); &#125; &#125;&#125;publi class World extend Hello&lt;String&gt; &#123;&#125; 通过构造方法的方式获取泛型变量的实际类型 1234567891011121314151617181920212223242526public class Hello &#123; public Hello(List&lt;String&gt; params)&#123; &#125; public static void main(String[] args) &#123; // 方式1 Constructor&lt;?&gt;[] constructors = Param.class.getConstructors(); for (Constructor&lt;?&gt; constructor : constructors) &#123; // 构造函数能获取参数的 Type 类型，所以通过构造函数的方式获取泛型变量的实际类型 for (Type genericParameterType : constructor.getGenericParameterTypes()) &#123; ParameterizedType pt = (ParameterizedType)genericParameterType; System.out.println(Arrays.stream(pt.getActualTypeArguments()).map(Type::getTypeName).collect(Collectors.joining())); &#125; &#125; // 方式2 Constructor&lt;Param&gt; constructor = Param.class.getConstructor(List.class); Type[] genericParameterTypes = constructor.getGenericParameterTypes(); ParameterizedType pt = (ParameterizedType)genericParameterTypes[0]; System.out.println(Arrays.stream(pt.getActualTypeArguments()).map(Type::getTypeName).collect(Collectors.joining())); &#125;&#125; 常见的 TypeRefece 原理","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"Instrumentation 知识笔记","slug":"Java 知识点/Instrumentation 知识笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/Instrumentation 知识笔记/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/Instrumentation%20%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Instrumentation 介绍Instrumentation 是从 JDK5 开始提供的一个特性，可以使用 Instrumentation 构建一个独立于应用程序的代理程序(Agent)。使用 Instrumentation 可以让开发者无需对原有应用做任何修改，就可以监测和获取 JVM 运行时状态，以及可以通过 ASM 和 Javassist 字节码类型增强修改 JVM 中运行的类。 Instrumentation 使用利用 JVM 提供的 Instrumentation API 来改变 JVM 中已经加载的字节代码 创建代理(Agent)创建代理类，需要在代理类中定义两个名为 premain 和 agentmain 的方法，Instrumentation 实例以参数的形式传递到方法中。premain 和 agentmain 方法的区别如下：1、premain – 在代理类中定义 premain 方法2、agentmain – will dynamically load the agent into the JVM using the Java Attach API 123456789101112131415public class TestAgent &#123; public static void premain(String agentArgs, Instrumentation inst) &#123; LOGGER.info(&quot;[Agent] In premain method&quot;); String className = &quot;com.baeldung.instrumentation.application.MyAtm&quot;; transformClass(className,inst); &#125; public static void agentmain(String agentArgs, Instrumentation inst) &#123; LOGGER.info(&quot;[Agent] In agentmain method&quot;); String className = &quot;com.baeldung.instrumentation.application.MyAtm&quot;; transformClass(className,inst); &#125;&#125; 参考文档","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"main 方法和 classpath 说明","slug":"Java 知识点/Java main 和 classpath","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/Java main 和 classpath/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/Java%20main%20%E5%92%8C%20classpath/","excerpt":"","text":"classpath 介绍classpath 是一个环境变量，用于指定 JVM 查找类和资源的路径。JVM 启动时，会通过 ClassLoader 类加载 Java 类和资源。当 ClassLoader 类加载类或资源时，会在 classpath 中查找这些文件。注意 JVM 查找类和资源时，先会查找 java -classpath 命令指定的类路径，如果找不到会去查找 classpath 系统环境变量设置的类路径。 classpath: 和 classpath*: 介绍classpath: 和 classpath*: 用于配置文件中，表示路径或者文件的相对根路径是 classpath，此相对路径是代码编译后根包所在的目录，classpath*: 除了表示当前工程根包所在相对路径，还表示依赖的 jar 内根包的相对路径。Java 在 loadClass 类中提供了 getResource() 方法来读取 classpath 相对根路径内的资源，如 this.getClass().getClassLoader().getResource(&quot;application.yaml&quot;), 因为我们打包后的 Jar 是可以在任意目录运行的，如果我们代码直接写死资源文件的绝对路径，明显是不可以的。 在 Java Maven 项目 src\\main\\java 和 src\\main\\resources 都属于 Java 工程的源文件夹编译后对应的是 target\\classes，则 target\\classes 就是当前工程的 classpath。如下下图所示： 当在配置文件想要配置 DemoController.class 和 application.yaml 的路劲时，则可以写成 classpath:com/github/com/github/demo/controller/DemoController.class 和 classpath:application.yaml 。 main 函数说明main 函数是 Java 程序的入口函数，Java 命令启动 JVM 虚拟机时，Jvm 虚拟机会加载指定的 MainClass 并执行 Mainclass 类中的public static void main(String[] args)方法。 Java 程序编译和运行 编译 Java 命令: javac &lt;options&gt; &lt;source files&gt;，常用的 options 如下: -classpath, -cp 指定待编译类和依赖包的查找目录 -d 指定编译结果的输出目录 执行 Java 命令: java [-options] class [args...] 或者 java [-options] -jar jarfile [args...] ，args 用于指定 main 函数的参数，options 常用参数如下： -classpath，-cp 指定依赖包或者运行类的查找目录 编译没有包的 java 程序12345678public class HelloWorld&#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello World&quot;); &#125;&#125; 直接在当前路径编译和运行 12345# 编译javac HelloWorld.java# 运行，通过 classpath 参数，告诉 JVM 先查找当前位置，是否存在 HelloWorld 类，不存在，再去 classpath 系统变量设置的路径里面找，注意不需要加 .class 后缀 java -classpath . HelloWorld # -classpath . 时可以省略掉的，因为我们系统变量中的 classpath 已经配置有 . 表示的时当前目录 编译带包的 java 程序如在 D:/helloJava 目录创建以下 Java 文件 123456789package com.github;public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println(&quot;this is helloWorld Java&quot;); &#125;&#125; 进入 D:/helloJava 目录运行 javac 编译命令，注意编译带有 package 的类时，需要指定编译后的输出目录，不然编译时不会生成包路径。 1javac -d ./target HelloWorld.java 运行编译后的 HelloWorld 1234# 指定 JVM 的查找类，不然会提示找不到 HelloWorld.class 类，注意 helloWorld 不能加 .class 后缀java -classpath ./target/ com.github.HelloWorld# 或者java -classpath ./target/ com/github/HelloWorld 编译 Java 项目12345678910111213141516171819202122232425262728293031323334helloProject ├─src # 源码目录│ ├─com│ │ └─github│ │ └─HelloWorld.java│ ││ └─org│ └─github│ └─HelloResource.java│├─resource # 配置目录| └─logback.xml|├─libraries # 依赖包目录| |─logback-classic-1.2.11.jar| |─logback-core-1.2.11.jar| └─slf4j-api-1.7.36.jar|└─bin # 编译输出的目录 ├─com │ └─github │ └─HelloWorld.class │ ├─libraries │ |─logback-classic-1.2.11.jar │ |─logback-core-1.2.11.jar │ └─slf4j-api-1.7.36.jar │ └─org | └─github | └─HelloResource.class | └─logback.xml 编译 helloProject 项目命令如下： 12345678# 通过 classpath 指定依赖包，将编译后的结果输出到 bin 目录下javac -d ./bin -classpath &quot;./libraries/logback-classic-1.2.11.jar;./libraries/logback-core-1.2.11.jar;./libraries/slf4j-api-1.7.36.jar&quot; src/com/github/HelloWorld.java src/org/github/HelloResource.java# 或者javac -classpath &quot;./libraries/*&quot; -d ./target $(find src -name &quot;*.java&quot;) # resource 配置文件到 bin 目录，依赖包不需要复制，运行是通过 classpath 去指定即可。cp ./resource/logback.xml ./target 运行 helloProject 项目，通过 -classpath 参数 Jvm 查找类和依赖路径时，需要指定类包的所在目录即可，但依赖的 jar 不能指定 jar 所在的目录, 需要指定到具体的 jar 名 1234567java -classpath &quot;./bin;./libraries/logback-classic-1.2.11.jar;./libraries/logback-core-1.2.11.jar;./libraries/slf4j-api-1.7.36.jar&quot; com/github/HelloWorld# 或者java -classpath &quot;./bin;./libraries/logback-classic-1.2.11.jar;./libraries/logback-core-1.2.11.jar;./libraries/slf4j-api-1.7.36.jar&quot; com.github.HelloWorld# 或者java -classpath &quot;./bin;./libraries/*&quot; com/github/HelloWorld# 或者java -classpath &quot;./bin;./libraries/*&quot; com.github.HelloWorld 将 bin 目录中的类和资源文件，打包成 jar 的方式有两种，一种是使用 jar 命令，另外一种是通过打成 zip 压缩包，在将文件后缀改成 jar 就可以, 或者不改后缀也可以。 12# 将 bin 目录的文件打成 jar，注意要进 bin 目录运行命令，防止将 bin 目录打进 jar 中jar -cvf run-bin.jar ./* 第一种通过指定 classpath 和入口类的运行 jar 方式 12345# java 运行的 com.github.HelloWorld 类, 通过 classpath 设置改类和依赖包的查找路径 java -classpath &quot;./libraries/*;./bin/run-bin.jar&quot; com.github.HelloWorld# zip 打包的也可以运行，因为 jar 本质上也是 zip 压缩 java -classpath &quot;./libraries/*;./bin/run-bin.zip&quot; com.github.HelloWorld 第二种方式通过 -jar 参数的方式运行，如果提示找不到主类，则需要在打包的时候先创建 META-INF&#x2F;MAINFEST.MF 一起压缩打包，或者用压缩软件打开已压缩好的 jar| zip 包然后新增或修改 META-INF&#x2F;MAINFEST.MF 文件。 123java -classpath &quot;./libraries/*&quot; -jar ./bin/run-bin.jar# 或者java -classpath &quot;./libraries/*&quot; -jar ./bin/run-bin.zip META-INF&#x2F;MAINFEST.MF 文件说明，注意每一行不能超过 72 个字符，可以换行需要以空格开头，文件最后必须要有一个回车换行 123456Manifest-Version: 1.0 # 属性和值之间必须空格Created-By: 1.8.0_41 (Oracle Corporation)Main-Class: com.github.HelloWorld # 指定运行 jar 的入口类Class-Paht: ./lib/logback-classic-1.2.11.jar .lib/logback-core-1.2.11.jar ./lib/slf4j-api-1.7.36.jar # 指定 jar 包的依赖包，只能使用相对路径，并且是相对 java -jar 运行的 jar 所在路径 # 注意注意这里是最后一行，是一个回车换行","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"Javassist 知识笔记","slug":"Java 知识点/Javassist 知识笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/Javassist 知识笔记/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/Javassist%20%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/","excerpt":"","text":"概述Javassist 是一个开源的分析、编辑和创建Java字节码的类库。相对于 ASM 来说 Javassist 处理 Java 字节码相对简单。Javassist 可以在一个已经编译好的类中添加新的方法，或者是修改已有的方法，同时也可以生成一个新的类对象。 通过 Javassist 创建 Class 对象1","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"SecurityManager 笔记","slug":"Java 知识点/SecurityManager 笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/SecurityManager 笔记/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/SecurityManager%20%E7%AC%94%E8%AE%B0/","excerpt":"","text":"简介Java SecurityManager 安全管理器，配合安全策略文件使用，能够控制代码对敏感或关键资源的访问，例如文件系统，网络服务，系统属性访问等，加强代码的安全性。注意读取程序类路径中的文件是不需要进行显式授权，默认已有读取执行删除的权限。 简单使用例子： 12345678910111213141516171819202122232425262728293031323334353637import java.io.BufferedReader;import java.io.File;import java.io.FileReader;import java.util.Objects;public class SecurityManagerTest &#123; public static void main(String[] args) &#123; // 代码中启动安全管理器，或者通过指定参数启动安全管理 java -Djava.security.manager xxx.jar SecurityManager manager = new SecurityManager(); if(Objects.isNull(System.getSecurityManager())) &#123; // 开启安全管理器，安全管理器默认的安全策略配置文件是 JAVA_HOME/jre/lib/security/java.policy System.setSecurityManager(manager); &#125; try &#123; // 检查是否有访问属性权限，没有的话，抛出异常 manager.checkPropertyAccess(&quot;java.home&quot;); System.out.println(System.getProperty(&quot;java.home&quot;)); &#125;catch (SecurityException e) &#123; System.out.println(&quot;没有读取 java.home 属性的权限&quot;); &#125; try (FileReader fileReader = new FileReader(new File(&quot;D:\\\\test-security.txt&quot;)); BufferedReader reader = new BufferedReader(fileReader)) &#123; for (String text = reader.readLine(); Objects.nonNull(text); text = reader.readLine()) &#123; System.out.println(text); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上述代码设置安全管理，因为默认的 java.policy 安全策略文件未配置读取该文件的权限，则会报如下错误： 12345678java.security.AccessControlException: access denied (&quot;java.io.FilePermission&quot; &quot;D:\\test-security.txt&quot; &quot;read&quot;) at java.security.AccessControlContext.checkPermission(AccessControlContext.java:457) at java.security.AccessController.checkPermission(AccessController.java:884) at java.lang.SecurityManager.checkPermission(SecurityManager.java:549) at java.lang.SecurityManager.checkRead(SecurityManager.java:888) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:127) at java.io.FileReader.&lt;init&gt;(FileReader.java:72) at com.ils.securityManager.SecurityManagerTest.main(SecurityManagerTest.java:16) 开启安全管理方式如下： 通过编码方式1System.setSecurityManager(new SecurityManager()); 通过设置 Java 程序启动参数方式1java -Djava.security.manager xxx.jar 安全策略文件默认使用的是 JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;security&#x2F;java.policy 和哟用户目录下的 .jara.policy 文件，当然可以另外指定，支持以下两种方式指定： 通过编码方式1234// 指定类路径下的文件System.setProperty(&quot;java.security.policy&quot;, SecurityManagerTest.class.getResource(&quot;/&quot;)+&quot;testFile.policy&quot;);// 指定全路径System.setProperty(&quot;java.security.policy&quot;,&quot;D:/testFile.policy&quot;); 通过 Java 程序启动参数方式1234# 表示优先查找当前策略文件权限，如果查找不到，则去查找默认的 JAVA_HOME/jre/lib/security/java.policy 安全策略文件-Djava.security.policy=D:/testFile.policy# == 符号表示查找权限只查找当前指定策略文件-Djava.security.policy==D:/testFile.policy 上述例子，配置安全策略权限有两种如下： 在默认的安全策略文件中添加123456grant &#123; // 在 grant 语句处添加如下权限，表示所有资源的可以访问，一般不建议这么做 permission java.security.AllPermission; // 或者添加单独的文件访问权限 permission java.io.FilePermission &quot;D:\\\\test-security.txt&quot;, read;&#125; 在项目的资源根路径下下新建一个安全策略配置文件，文件名 testFile.policy，内容如下：123grant &#123; permission java.io.FilePermission &quot;D:\\\\test-security.txt&quot;, &quot;read&quot;;&#125; 然后将代码修改如下：123456789101112131415161718192021222324252627282930313233public class SecurityManagerTest &#123; public static void main(String[] args) &#123; // 代码中启动安全管理器，或者通过指定参数启动安全管理 java -Djava.security.manager -Djava.security.policy=xxx/xx/my.policy xxx.jar System.setProperty(&quot;java.security.policy&quot;, SecurityManagerTest.class.getResource(&quot;/&quot;)+&quot;testFile.policy&quot;); // 注意安全管理器会优先使用命令行或者 system.setPropety 设置的 policy 文件，如果权限不匹配在去查找默认的策略文件 SecurityManager manager = new SecurityManager(); if(Objects.isNull(System.getSecurityManager())) &#123; // 开启安全管理器，安全管理器默认的安全策略配置文件是 JAVA_HOME/jre/lib/security/java.policy System.setSecurityManager(manager); &#125; try &#123; // 检查是否有访问属性权限，没有的话，抛出异常 manager.checkPropertyAccess(&quot;java.home&quot;); System.out.println(System.getProperty(&quot;java.home&quot;)); &#125;catch (SecurityException e) &#123; System.out.println(&quot;没有读取 java.home 属性的权限&quot;); &#125; try (FileReader fileReader = new FileReader(new File(&quot;D:\\\\test-security.txt&quot;)); BufferedReader reader = new BufferedReader(fileReader)) &#123; for (String text = reader.readLine(); Objects.nonNull(text); text = reader.readLine()) &#123; System.out.println(text); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 安全管理策略文件以下是安全策略文件的简单语法说明，具体详细说明可以查看官方文档 语法格式说明1234567891011121314151617181920212223242526272829303132// 表示签名秘钥文件路径keystore &quot;http://foo.example.com/blah/.keystore&quot;;// 授权条目，其中 signedBy、principal、codeBase 语句都是可选的，它们是与的关系。grant signedBy &quot;signer_names&quot;, codeBase &quot;URL&quot;, principal principal_class_name &quot;principal_name&quot;, principal principal_class_name &quot;principal_name&quot; &#123; // 通过 signedBy 指定签名人 permission permission_class_name &quot;target_name&quot;, &quot;action&quot;, signedBy &quot;signer_names&quot;;; permission permission_class_name &quot;target_name&quot;, &quot;action&quot;; &#125;grant codeBase &quot;URL&quot; &#123; permission permission_class_name &quot;target_name&quot;, &quot;action&quot;; permission permission_class_name &quot;target_name&quot;, &quot;action&quot;; &#125;grant &#123; permission permission_class_name &quot;target_name&quot;, &quot;action&quot;; permission permission_class_name &quot;target_name&quot;, &quot;action&quot;;&#125;// 表示允许任何以 X500Principal，&quot;cn=Alice &quot; 的身份执行的代码，有权限读写 &quot;/home/Alice&quot; 资源grant principal javax.security.auth.x500.X500Principal &quot;cn=Alice&quot; &#123; permission java.io.FilePermission &quot;/home/Alice&quot;, &quot;read, write&quot;;&#125;;// 表示允许任何以 X500Principal 的任何身份执行的代码，都有权限读写 &quot;/home/Alice&quot; 资源grant principal javax.security.auth.x500.X500Principal * &#123; permission java.io.FilePermission &quot;/home/Alice&quot;, &quot;read, write&quot;;&#125;; 每一个 policy 文件可以包含多个 grant 授权条目，其中 signedBy、principal、codeBase 语句都是可选的。 signedBy 表示针对某个签名者赋予权限，签名例子如下： 1234jarsigner -verbose -keystore [私钥存放路径] -signedjar [签名后文件存放路径] [未签名的文件路径] [证书别名]jarsigner -verbose -keystore /xx/path/keystore -signedjar ./signed-xxx.jar ./xxx.jar signer_names codeBase 用于指定运行 URL 目录下的代码，才能赋予配置的 permission 权限。注意如果 URL 以 &#x2F; 结尾的匹配指定目录下的所有类文件（ 非 JAR 文件 ），以 &#x2F;* 结尾的匹配该目录下的所有文件（类文件和 JAR 文件），以 &#x2F;- 结尾的匹配该目录下的所有文件（类文件和 JAR 文件）及该目录下子目录中的所有文件，直接以目录名结尾的等同于 &#x2F; 结尾的。 principal 表示针对证书或者主体认证的 class_name&#x2F;principal_name 对，授予资源的读取权限。 例子说明1234567891011121314151617181920212223242526// 表示扩展包目录的下的代码，使用资源时，授予所有资源权限grant codeBase &quot;file:$&#123;&#123;java.ext.dirs&#125;&#125;/*&quot; &#123; // 开放所以权限 permission java.security.AllPermission;&#125;;// 表示该 URL 目录中的代码执行时，能获取所有资源的权限grant codeBase &quot;file:C:/Users/xxpath/learn-test/target/classes&quot; &#123; permission java.security.AllPermission;&#125;;grant &#123; // java.security.AllPermission 所有权限的集合 permission java.security.AllPermission; // 表示开发所有权限 // java.util.PropertyPermission 系统/环境属性权限 permission java.util.PropertyPermission &quot;java.home&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vendor&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vendor.url&quot;, &quot;read&quot;; // ... 等等其他权限&#125;; 参考链接 https://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html https://docs.oracle.com/javase/8/docs/technotes/guides/security/PolicyFiles.html","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"ByteBuddy 入门笔记","slug":"Java 知识点/byteBuddy入门笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/byteBuddy入门笔记/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/byteBuddy%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"ByteBuddy 概述ByteBuddy 是一个可以在运行时动态生成 java class 的类库。 依赖在使用 ByteBuddy 之前我们需要引入对应的 Jar 到工程中，如下 12345&lt;dependency&gt; &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt; &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt; &lt;version&gt;1.12.17&lt;/version&gt;&lt;/dependency&gt; 根据官网例子入门JVM 运行时创建 Java 类123456789101112131415161718192021222324class HellWorld&#123; @Test public void testBuddy() throws Exception &#123; ByteBuddy byteBuddy = new ByteBuddy(); // 创建一个继承 Object 的子类 Unloaded&lt;Object&gt; unloadedClass = byteBuddy.subclass(Object.class) // 使用 ElementMatchers 选择需要重写的父类方法 .method(ElementMatchers.named(&quot;toString&quot;)) // 重写父类的 toString 方法，固定返回如下值 .intercept(FixedValue.value(&quot;Hello World ByteBuddy!&quot;)) // 定义子类的名称(包含 package 路径)，如果不定义 bytebuddy 会自动生成 net.bytebuddy.renamed.xxxx 名称 .name(&quot;hello.Test&quot;) // 生成子类 .make(); // 将加载到 JVM 中, 并获取加载到 JVM 中的 子类的 Class 对象 Class&lt;? extends Object&gt; loaded = unloadedClass.load(getClass().getClassLoader()).getLoaded(); // 通过反射把子类的 Class 对象实例化 Object newInstance = loaded.newInstance(); // 打印子类，会在终端输出 Hello World ByteBuddy! System.out.println(newInstance); // 打印类型，因为定义名称，所以会输出 class hello.Test System.out.println(newInstance.getClass()); &#125;&#125; 动态类的命名说明使用 [name|with] 方法, 可以指定动态类的名称，当两者同时设置时 with 方法的优先级更高 12345678910111213141516171819class NameTest&#123; @Test public void testName() &#123; DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy() .with(new NamingStrategy.AbstractBase() &#123; @Override protected String name(TypeDescription superClass) &#123; return &quot;i.love.ByteBuddy.&quot; + superClass.getSimpleName(); &#125; &#125;) .withNamingStrategy(new NamingStrategy.SuffixingRandom(&quot;suffix&quot;)); .subclass(Object.class) .name(&quot;hello.dynamicTest&quot;) .make(); // 输出 class net.bytebuddy.dynamic.DynamicType$Default$Unloaded System.out.println(dynamicType.getClass()); &#125;&#125; 动态类重写父类方法ByteBuddy 动态生成的类, 需要重写父类方法时， 使用 method 配合 ElementMatcher 选择器去匹配父类的方法，然后通过 intercept 指定重写方法的实现，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class Foo &#123; public String bar() &#123; return null; &#125; public String foo() &#123; return null; &#125; public String foo(Object o) &#123; return null; &#125;&#125; class MethodTest &#123; @Test public void testOverride() throws Exception &#123; // 定义一个动态类继承 Foo 类 Unloaded&lt;Foo&gt; unloadedClass = new ByteBuddy().subclass(Foo.class) /** 使用 method 重写 Foo 类中的方法，使用 ElementMatchers 选择要重写那个方法，isDeclaredBy 表示把 Foo 类的全部方法都重写 **/ .method(ElementMatchers.isDeclaredBy(Foo.class)) // intercept 指定重写方法的实现，FixedValue.value 表示重写的方法全部返回 Hello Method! .intercept(FixedValue.value(&quot;Hello Method!&quot;)) .make(); // unloadedClass 加载到 JVM 中并通过反射实例化 Foo dynamicFoo = unloadedClass.load(getClass().getClassLoader()).getLoaded().newInstance(); // 输出 Hello Method! System.out.println(dynamicFoo.bar()); // 输出 Hello Method! System.out.println(dynamicFoo.foo()); // 输出 Hello Method! System.out.println(dynamicFoo.foo(&quot;&quot;)); // 输出 One! &#125; /** 多个 method 是堆栈式匹配的，新的 method 在栈顶，会有优先使用 ElementMatchers 匹配方法，匹配结束则出栈，使用下一个 method 的 ElementMatchers 进行匹配，父类的方法被前一个 method 匹配到后，后面的 metod 不再匹配，只能匹配一次。 */ @Test public void testOverride() throws Exception&#123; Unloaded&lt;Foo&gt; unloadedClass = new ByteBuddy().subclass(Foo.class) .method(ElementMatchers.isDeclaredBy(Foo.class)).intercept(FixedValue.value(&quot;One!&quot;)) .method(ElementMatchers.named(&quot;foo&quot;)).intercept(FixedValue.value(&quot;Two!&quot;)) .method(ElementMatchers.named(&quot;foo&quot;).and(ElementMatchers.takesArguments(1))) .intercept(FixedValue.value(&quot;Three!&quot;)).make(); // unloadedClass 加载到 JVM 中并通过反射实例化 Foo dynamicFoo = unloadedClass.load(getClass().getClassLoader()).getLoaded().newInstance(); // 打印重写方法返回的值 System.out.println(dynamicFoo.bar()); // 输出 One! System.out.println(dynamicFoo.foo()); // 输出 Two! System.out.println(dynamicFoo.foo(&quot;Hello Wold&quot;)); // 输出 Three! Unloaded&lt;Foo&gt; unloadedClass02 = new ByteBuddy().subclass(Foo.class) .method(ElementMatchers.named(&quot;foo&quot;)).intercept(FixedValue.value(&quot;Two!&quot;)) .method(ElementMatchers.named(&quot;foo&quot;).and(ElementMatchers.takesArguments(1))).intercept (FixedValue.value(&quot;Three!&quot;)) // 该 method 会优先匹配所有方法，所以下面的打印会全部都输出 One! .method(ElementMatchers.isDeclaredBy(Foo.class)).intercept(FixedValue.value(&quot;One!&quot;)) .make(); // unloadedClass02 加载到 JVM 中并通过反射实例化 Foo dynamicFoo02 = unloadedClass02.load(getClass().getClassLoader()).getLoaded().newInstance(); // 打印重写方法返回的值 System.out.println(dynamicFoo02.bar()); // 输出 One! System.out.println(dynamicFoo02.foo()); // 输出 One! System.out.println(dynamicFoo02.foo(&quot;Hello Wold&quot;)); // 输出 One! &#125;&#125; 代理方法的调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Source &#123; public String hello(String name) &#123; return null; &#125;&#125;public class Target &#123; public static String intercept01(String name) &#123; return &quot;Hello &quot; + name + &quot;!&quot;; &#125; public static String intercept02(int i) &#123; return Integer.toString(i); &#125; public static String intercept03(Object o) &#123; return o.toString(); &#125;&#125;public class DelegationTest &#123; /** * 方法委托调用 * * @throws Exception */ @Test public void testMethodDelegation() throws Exception &#123; // 生成动态类 Unloaded&lt;Source&gt; unloaded = new ByteBuddy() // 指定动态类的父类 .subclass(Source.class) .method(ElementMatchers.named(&quot;hello&quot;).and(ElementMatchers.returns(String.class))) /** * 拦截 target 类方法，delegation 会找到一个最匹配的方法，名称不要求一样，但是返回值类型和参数类型要求相匹配才行， * 比如 target 类中 intercept02 方法的参数 int 类型肯定是不匹配的，因为 source 类的 hello 方法参数是 String, * target 类中剩下参数是 Object 和 String 的方法，根据最优原则，会匹配到 intercept01 方法，如果 * 没有匹配到就抛出异常，注意 Delegation 委托的 target 是类不是实例对象，所以只会匹配静态方法 */ .intercept(MethodDelegation.to(Target.class )) .make(); // 将动态类加载到 JVM 并通过反射实例化 Source source = unloaded.load(getClass().getClassLoader()).getLoaded().newInstance(); String result = source.hello(&quot;World&quot;); // 输出 helloWorld System.out.println(result); &#125;&#125;","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"代理模式","slug":"Java 设计模式/代理模式","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 设计模式/代理模式/","link":"","permalink":"http://example.com/wiki/Java%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"","categories":[{"name":"Java 设计模式","slug":"Java-设计模式","permalink":"http://example.com/categories/Java-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"工厂模式","slug":"Java 设计模式/工厂模式","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 设计模式/工厂模式/","link":"","permalink":"http://example.com/wiki/Java%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"作用通过工厂模式实例化对象，可以解耦代码，面向接口编程，使用类只需要与接口耦合不需要耦合具体的实现类也不关心具体的实现类，通过工厂类来耦合实现类，工厂类拓展性高，如果想增加一个实现类，只需拓展一个工厂类即可，同时工厂类也方便实现一些增强逻辑，相当于包了一层。 遵循原则1、满足开闭原则（一个对象对扩展开放，对修改关闭），新增功能需求时，不修改原有代码，在原有的基础扩展和新增。 简单工厂模式简单工厂模式，也称为静态工厂模式。 1234","categories":[{"name":"Java 设计模式","slug":"Java-设计模式","permalink":"http://example.com/categories/Java-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"模板模式(模板方法模式)","slug":"Java 设计模式/模板模式","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 设计模式/模板模式/","link":"","permalink":"http://example.com/wiki/Java%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"作用通过抽象类定义通用或者固定的逻辑，然后其他部分逻辑以子类形式去实现，即父类中定义好一个主要的逻辑框架（方法），在框架中一个步骤就是一个抽象方法，具体的步骤交给子类来实现。 遵循原则 里氏替换原则，子类可以扩展父类的功能，但不能改变父类原有的功能(可以父类使用 final 修饰)，除添加新的方法完成新增功能外，尽量不要重写父类的方法。 依赖倒置原则，高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象，通俗的话讲就是以面向接口或抽象类的方式去编程，只需要依赖父类，不要依赖子类。 示例代码1234567891011121314151617181920212223242526// 该类还可以在套一层public abstract class BusinessTempalte&#123; public void doSomething()&#123; // 固定代码逻辑片段 // 业务逻辑代码，即细节部分代码 doBusiness() // 固定代码逻辑片段 &#125; public abstract void doBusiness();&#125;public class Business01 extends BusinessTempalte&#123; public void doBusiness()&#123; // todo &#125;&#125;public class Business02 extends BusinessTempalte&#123; public void doBusiness()&#123; // todo &#125;&#125;","categories":[{"name":"Java 设计模式","slug":"Java-设计模式","permalink":"http://example.com/categories/Java-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"Jemeter 入门笔记","slug":"Jemeter/Jemeter 入门笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Jemeter/Jemeter 入门笔记/","link":"","permalink":"http://example.com/wiki/Jemeter/Jemeter%20%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"线程组线程组，可以看作是一个虚拟的用户组(模拟的测试用户), Jmeter 创建线程组有三个选项分别为：setUp Thread Group、Thread Group、tearDown Thread Group 其中的 setUp 和 tearDown 用于处理线程的前置初始化和后置结束处理，就相当 Junit 的中的 setUp 和 tearDown 一样。 线程组的部分参数说明1、Ramp-up： 指定所有线程启动需要的总时间，是线程启动间隔相加，不如设置值为100秒有10个线程数，那个每一个线程的启动时间间隔为10秒，即每一个相对于前一个线程延时10秒启动2、循环次数：指的线程组运行的次数, 默认永远一直执行的，要指定循环的次数，不然测试线程组会一直循环运行3、调度器(Scheduler)，开始时间(Start Time)线程组执行的开始时间，结束时间(End Time)线程组执行的结束时间，持续时间(Duration)指定测试计划的持续总时间会覆盖结束时间，延迟时间(Start Delay)会覆盖开始时间。 取样器取样器可以看作是一个没有界面的浏览器，取样器只有在线程中才能添加1、取样器：用于发送 Http 、WebService、JDBC、Java 等构造的请求2、取样器的断言：断言看作是异常处理的一种高级形式，判断是否符合某个指定的值，不符合抛出异常3、取样器的监听器：用于展示结果，如查看结果树、查看每次的请求和响应4、取样器的前置处理器：发送请求前要做环境或者数据准备5、取样器的后置处理器：请求响应后可以处理响应的结果,如果返回的是 JSON 使用 $ 作为根元素取值6、取样器的配置元件：用于设置取样器的头部之类的信息，如 HTTP 设置参数或请求头 JSON 取值器参数介绍获取请求结果返回值时使用 $ 作为根元素1、names of created variables ：接收值的变量名，多个变量时用分号分隔，提取的变量可以用作请求的参数使用的格式为 ${变量名}2、json path： json path表达式，也是用分号分隔3、atch no：0随机; n取第几个匹配值；-1匹配所有，后续引用用变量名_N 取第N个值4、default values： 缺省值，匹配不到值的时候取该值 逻辑控制器逻辑控制器和取样器一样只能在线程组中添加，逻辑控制器就是条件控制器1、if 控制逻辑控制器：用于判断某个值是否为真如果为真则执行 if 逻辑控制器中的元件和取样器2、仅一次逻辑控制器：表示线程组设置的次数大于或者设置为永远时，该控制器中的取样器及其他元件都是只运行一次 全局变量1、全局变量的设置：$&#123;__setProperty(varName,varValue,)&#125;2、全局变量的引用：$&#123;__P&#123;varName&#125;&#125; Jemter 元件的执行顺序取样器和逻辑控制器是顺序执行的，其他元件会在取样器执行的特定期间执行，不由创建的顺序决定，且会继承，子的元件会覆盖父级的元件设置，并且所有的取样器都会应用父级的元件，如下面的例子： 1234567891011121314151617181920212223242526272829-逻辑控制器--后置处理器01--取样器01--取样器02--定时器01--断言01--前置处理器01--定时器02--后置处理器02运行的执行顺序如下(取样器的会共享使用同级别或者父级的定时、处理器、断言)：前置处理器01定时器01定时器02取样器01(因为取样器01的顺序第一所以先运行)后置处理器01后置处理器02断言01前置处理器01定时器01定时器02取样器02(顺序第二所以运行顺序第二)后置处理器01后置处理器02断言01 汇总报告字段说明Label：取样器名称Samples：发送的请求总数Average：平均响应时间Min：最小响应时间Max：最大响应时间Std.Dev.：所有请求响应时间的标准差Error%：出错率（出错的request数&#x2F;所有的request数）Throughput：吞吐量，每秒&#x2F;每分钟（具体看单位）处理的request数Received KB&#x2F;sec：每秒从服务器端接收到的数据量Avg.Bytes：服务端返回给request数据的平均值，可以理解为：服务端返回所有数据&#x2F;请求数","categories":[{"name":"Jemeter","slug":"Jemeter","permalink":"http://example.com/categories/Jemeter/"}],"tags":[]},{"title":"kubeadm 快速部署 kubernetes 集群测试环境","slug":"Kubernetes/kubeadm 快速部署 k8s 集群测试环境","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Kubernetes/kubeadm 快速部署 k8s 集群测试环境/","link":"","permalink":"http://example.com/wiki/Kubernetes/kubeadm%20%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%20k8s%20%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/","excerpt":"","text":"1. 安装要求部署 Kubernetes 集群机器需要满足以下几个条件： 至少2台机器 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 禁止swap分区 2. 硬件环境准备准备至少两台机器，一台 master 节点，两台 node 节点。 序号 机器 IP 操作系统 节点类型 1 192.168.204.3 CentOS8 master 2 192.168.204.4 CentOS8 node 2 192.168.204.5 CentOS8 node 2.1 云服务的安全组设置如果搭建的集群使用外网，需要在安全组中开放端口 节点 协议类型 访问方向 端口 描述 Master 服务器 TCP 入方向 6443 Kubernetes API server 的端口 Master 服务器 TCP 入方向 2379-2380 etcd server client API kube-apiserver, etcd 的端口 Master 服务器 TCP 入方向 10250 Kubelet API 的端口 Master 服务器 TCP 入方向 10259 kube-scheduler 的端口 node 服务器 TCP 入方向 10250 Kubelet API 的端口 node 服务器 TCP 入方向 30000-32767 NodePort Services 的端口 3. CenteOs 系统环境配置（ master 和 node 机器都要改）3.1 关闭防火墙 和 SELINUX(类型 Window UAC)123456# 关闭防火墙, 关闭 firewalld 只使用 iptables 防火墙systemctl stop firewalld &amp;&amp; systemctl disable firewalld# 关闭selinuxsed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config # 永久setenforce 0 # 临时关闭，机器重启后重新启动 3.2 关闭 Swap当系统使用 swap 会降低性能。所以 kubelet 要求禁用 Swap 123456# 临时关闭swapoff -a# 永久关闭，执行了命令， kubeadm init 提示没有的话，重启系统试试 systemctl rebootsed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab# 或者vim /etc/fstab 用 # 注释掉 UUID swap 分区 3.3 修改机器的主机名在一个局域网中，每台机器都有一个主机名，用于主机与主机的区分，默认的主机名，不容易记住，需要修改成方便我们识别的 123456789101112# 运行以下命令将 master 主机名改成 k8s-masterhostnamectl set-hostname k8s-master# 修改对应 node 节点的主机名hostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02# 在 hosts 中添加 ip 地址和主机名的映射关系，主机名相当于域名，hosts 是机器的本地 DNS 服务，通过主机访问网络时，会在 hosts 解析到对应的 ipcat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.204.3 k8s-master192.168.204.4 k8s-node01192.168.204.5 k8s-node02EOF 3.4 将桥接的 IPv4 流量传递到 iptables 的链1234567cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF# 立即生效sysctl --system 3.5 时间同步(可以不修改)在集群中，时间是一个很重要的概念，要保证集群机器中的时间一致，不然可能会导致集群出现问题。 1234567# 安装时间同步软件yum install ntpdate -y# 使用阿里云的时间服务器ntpdate time1.aliyun.com # 通过定时任务，定时同步时间*/1 * * * * /usr/sbin/ntpdate time2.aliyun.com &gt; /dev/null 2&gt;&amp;1 4 安装 kubeadm、kubelet 和 kubectlkubeadm 创建 Kubernetes 集群的最快捷的一种命令行工具，其常用的命令如下： kubeadm init 初始化 Kubernetes 主节点 kubeadm join 用于 node 节点加入到集群中 kubeadm upgrade 更新 Kubernetes 集群到新版本 kubeadm token 管理 k8s token 令牌 kubeadm reset 还原 kubeadm init 或者 kubeadm join 所作的操作 kubeadm version 打印出 kubeadm 版本kubectl 是操作管理 k8s 集群的命令行工具。kubelet 是容器运行时，k8s 组件 api service 接收到 kubectl 的操作请求，通过控制 kubelet 去创建和管理容器的。 4.1 添加阿里云源123456789101112131415161718# 添加 k8s 软件源cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 设置 aliyun 镜像加速库，要重启 dockercat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;], &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125;EOF 4.2 master 节点安装 kubeadm、kubelet 和 kubectlkubelet 组件用于处理 api-server 发到本节点的任务，管理 Pod 及 Pod 中的容器。每个 kubelet 进程都会在 api-server 上注册本节点自身的信息，定期向 Master 汇报节点资源的使用情况，并通过 cAdvisor 监控 容器和节点资源。 1234# 安装的时候需要指定版本，kubeadm init 初始化节点设置的版本相对应yum install -y kubeadm-1.20.15 kubectl-1.20.15 kubelet-1.20.15# 启动 kubelet 并设置开机启动systemctl start kubelet &amp;&amp; systemctl enable kubelet 4.3 初始化 master 节点123456789101112kubeadm init \\ --apiserver-advertise-address=192.168.204.3 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.20.15 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16# --apiserver-advertise-address 指定 master 节点的地址，如果是阿里云服务不能指定为外网地址会报 bind: cannot assign requested address 错误# --kubernetes-version 指定 k8s 的版本，要和 kubectl 的版本相同，使用命令 kubectl --version 可以查看 kubectl 的版本# --service-cidr 指定 service 资源的网络地址段# --pod-network-cidr 指定 Pod 内部网络地址段 4.4 k8s 客户端 kubectl 工具配置kubectl 是与 kubernetes 集群交互的一个命令行工具, kubectl 通过调用 api server 组件 Rest Api 来交互来操作集群的。Api Server 接口的认证信息和访问地址默认是存放在 &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf 的， kubectl 请求 Api Server 接口获取认证信息和访问地址，默认是从用户目录下的 .kube&#x2F;config 文件读取或者从环境变量 KUBECONFIG 指定的文件中读取，所以要作以下配置： 123456mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 或者echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profilesource ~/.bash_profile 4.5 node 节点安装 kubeadm、kubelet123yum install -y kubeadm-1.20.15 kubelet-1.20.15# 启动 kubelet 并设置开机启动systemctl start kubelet &amp;&amp; systemctl enable kubelet 4.6 Node 加入 master 所在集群需要在 master 节点中先安装网络插件，才能访问到集群 123456# master 节点获取 token, 默认token有效期为24小时 kubeadm token create --print-join-command# 在 node 指定 kubeadm join 命令即可加入集群 kubeadm join 192.168.1.1:6443 --token esce21.q6hetwm8si29qxwn \\ --discovery-token-ca-cert-hash sha256:00603a05805807501d7181c3d60b478788408cfe6cedefedb1f97569708be9c5 5. 注意 coredns 组件如果未安装网络插件的话，coredns 组件的 pod 会一直在 pending 中，直到检测有网络插件完成成功为止。 6. 部署网络插件kubernetes 需要使用第三方的网络插件来实现 kubernetes 的网络功能，第三方网络插件有多种，常用的有 flanneld、calico 和 cannel（flanneld+calico），不同的网络组件，都提供基本的网络功能，为各个 Node 节点提供 IP 网络等。k8s 的组件可以通过容器化的方式，运行在 k8s 集群中，将 calico 网络插件创建在集群中，操作如下： 12345678910# 下载网络插件的资源文件，要注意下载的版本是否支持安装的 k8s wget https://docs.projectcalico.org/v3.20/manifests/calico.yaml# 部署网络插件kubectl apply -f calico.yaml# 查看部署的网络插件，使用如下命令 kubectl get pods -n kube-system# 显示的结果如下，说明部署成功NAME READY STATUS RESTARTS AGEcalico-kube-xx-xx-xx 1/1 Running 0 72s 7. 测试kubernetes集群在 Kubernetes 集群中创建一个 pod，验证是否正常运行： 123$ kubectl create deployment nginx --image=nginx$ kubectl expose deployment nginx --port=80 --type=NodePort$ kubectl get pod,svc 访问地址：http://NodeIP:Port","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/categories/Kubernetes/"}],"tags":[]},{"title":"kubeadm安装 k8s 问题记录","slug":"Kubernetes/kubeadm安装 k8s 问题记录","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Kubernetes/kubeadm安装 k8s 问题记录/","link":"","permalink":"http://example.com/wiki/Kubernetes/kubeadm%E5%AE%89%E8%A3%85%20k8s%20%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"kubeadm init 提示 [WARNING FileExisting-tc]: tc not found in system path 的解决办法 12# 安装 iprote-tcdnf install iproute-tc 提示 [WARNING IsDockerSystemdCheck]: detected “cgroupfs” as the Docker cgroup driver 处理办法 1234# 在 /etc/docker/daemon.json 文件中加入以下内容，并重启 docker , 如果 daemon.json 文件不存在，则创建一个&#123; &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125; 组件 coredns 一直在 pending 中的，使用命令 journalctl -f -u kubelet.service 查看日志，如果有提示 Unable to update cni config: no networks found in &#x2F;etc&#x2F;cni&#x2F;net.d 则说明是网络组件（Flannel 或者 calico 等）没有安装 安装 flannel 插件是如果一直无法成功,使用 docker images 查看flannel和flannel-cni-plugin镜像是否已经下载成功","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/categories/Kubernetes/"}],"tags":[]},{"title":"ECS 云服务器挂载数据盘","slug":"Linux/ECS 云服务器挂载数据盘","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/ECS 云服务器挂载数据盘/","link":"","permalink":"http://example.com/wiki/Linux/ECS%20%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8C%82%E8%BD%BD%E6%95%B0%E6%8D%AE%E7%9B%98/","excerpt":"","text":"查看服务是否有未挂载的硬盘1234# 第一种查看方式，该命令的结果以树形显示，如果硬盘的没有 part 类型(TYPE)说明硬盘未分区，挂载点(MOUNTPOINT)是空的，说明硬盘未挂载到系统lsblk -p# 第二种查看方式fdisk -l 挂载前先分区硬盘12# 执行以下命令，为硬盘 /dev/sdb 分区fdisk /dev/sdb 输入命令后需要依次输入以下参数 输入 n 表示新增分区 输入 p 表示建立主分区 输入 1 表示只需要建立一个分区 First sector 起始扇区，因为只是建立一个分区，直接回车即可 last sector 结束扇区，因为只是建立一个分区，直接回车即可 输入 w 表示将分区信息写到硬盘并结束分区。 格式化硬盘硬盘分区后，还需要将分区格式化为 linux 支持的文件系统格式才行 12# 将 /dev/sdb 硬盘的 /dev/sdb1 分区格式化为 ext4 文件系统格式mkfs -t ext4 /dev/sdb1 将分区挂载到指定目录12# 将 /dev/sdb1 分区挂载到 /data 目录，如果 /data 目录不存在则需要先 mkdir /datamount /dev/sdb1 /data 开机自动挂载分区mount 命令挂载的分区只是临时挂载，重启机器后就会失效，故需要将挂载信息写入文件 &#x2F;etc&#x2F;fstab 中，机器重启开机时就会自动挂载分区，操作方式是在 &#x2F;etc&#x2F;fstab 文件末尾添加一条记录如下，可以执行 mount -a命令检查添加的记录是否有错,该命令表示自动挂载 /etc/fstab 的内容。 12# 设备标识 挂载点 文件系统 挂载选项 UUID=6d935c4a-a61f-4c5f-b546-e1df4cae729c / ext4 defaults 0 2 /etc/fstab 文件配置说明 第一列：分区标识，可以分区名称或者分区UUID 或者 NFS, 分区 UUID 可以通过命令 blkid 查看，如 blkid /dev/sdb1 第二列：挂载点，即分区需要挂载到的目录 第三列：指定分区的文件系统 第四列：挂载选项，默认填写 defaults 即可 第五列：表示是否转储dump，未配置则默认为 0 第六列：表示开机 fsck 文件系统检查，0：表示不检查，1：表示第一位检查，一般用于根挂载点，2：其他磁盘配置参数","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"","slug":"Linux/Linux 服务器挂载硬盘","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/Linux 服务器挂载硬盘/","link":"","permalink":"http://example.com/wiki/Linux/Linux%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98/","excerpt":"","text":"title: Linux 服务器挂载硬盘服务器硬盘1、使用命令 fdisk -l 查看服务有哪些硬盘2、使用命令 df -h 查看已挂着的命令 在硬盘上创建文件系统1234命令格式：mkfs.文件系统 硬盘，具体例子如下：mkfs.ext4 /dev/vdb 使用 blkid 命令查看硬盘 UUID参考链接1、https://www.cnblogs.com/hiit/p/12106099.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"SSH 端口转发用法说明","slug":"Linux/SSH 端口转发","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/SSH 端口转发/","link":"","permalink":"http://example.com/wiki/Linux/SSH%20%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/","excerpt":"","text":"跳板机如上图本地电脑，能直接访问服务器 A，无法访问服务器 B，本地电脑要想登录远程和操作服务器 B，则需要使用服务器A作为中间的跳板。1、通过中间跳板机登录远程服务器 1ssh -J username@192.168.1.2:22 username@192.168.1.3 -p 22 如果 ssh 的端口时默认的 22 端口可以省略掉简写成： 1ssh -J username@192.168.1.2 username@192.168.1.3 2、通过中间跳板机上传文件 12scp -P 22 -o &#x27;ProxyJump username@192.168.1.2 -p 22&#x27; uploadFile.txt username@192.168.1.2:/home/username 本地端口转发SSH 端口转发的命令格式如下： 1234567ssh -N -L [localport]:[targethost]:[targetport] [username]@[ssh-tunnel-ip] -p ssh-tunnel-port-L 表示本地运行的 ssh 命令监听到，访问本地端口 localport 的信息时，通过中间跳板机 ssh-tunnel 将信息转发到目标主机 targetprot 的目标端口 targetport 上 -N 表示 SSH 连接只进行端口转发，不登录远程 Shell-f 表示 SSH 连接成功后，该命令就后台运行-p 用于指定执行转发操作的 SSH 通道服务器(中间服务器)端口 例子1，如下图, 本地电脑能直接访问服务器 A 不直接访问服务器 B 和 C，服务器 A 能直接访问服务器 B，而不能直接访问服务器 C 本地电脑想要远程登录服务器 C，则需要使用服务器 B 作为中间服务器器，将服务器 A 本端口转发服务器 C，然后本地电脑访问服务器 A 设置的转发端口，就能访问服务器 C，则要执行如下命令： 12345# 在服务器 B 中执行命令ssh -N -L 6011:192.168.1.4:22 username@192.168.1.3 -p 22# 本地电脑执行名ssh username@192.168.1.2 -p 6011 例子2、如下图, 本地电脑只能访问到服务器 A 如果想访问 MySql、服务器 B、HTTP 服务器、Email 服务器，则必须通过服务器 A 作为中间转发通道可以实现访问。 想要访问服务器 B，要执行的命令如下： 12345# 本地电脑运行如下命令，通过中间服务器 A(192.168.1.1) 作为转发通道，将本地电脑的端口 3111 转发到服务器 B(192.168.1.3) 的22端口ssh -N -L 3111:192.168.1.3:22 username@192.168.1.1 -p 22# 本地电脑再运行命令，即可访问到服务器 B，username 服务器 B 的 ssh 用户名ssh username@127.0.0.1 -p 3111 想要访问 Myql 服务器，本地电脑也可以使用服务器 A 作为中间跳板机，端口转发，然后访问到 MySql 12345# ssh 转发命令运行后，监听本地端口 3336 如果收 3306 端连接的信息，则通过服务器 A 转发到 mysql 服务器的 3306 端口ssh -N -L 3336:192.168.1.2:3306 username@192.168.1.1 -p 22# 运行连接命令mysql -u username -h 127.0.0.1 -p 3336 想要访问 Http 服务器和访问 Email 服务也可以通过本地端口转发来实现 123456# 本地电脑先运行转发命令ssh -N L 880:192.168.1.2:80 -L 225:192.168.1.2:25 username@192.168.1.1 -p 22# 浏览器输入如下连接即可访问 Http 和 Email 服务http://127.0.0.1:880http://127.0.0.1:225 远程端口转发远程转发指的是在远程 SSH 服务器建立的转发规则，访问远程服务器会将指定端口的流量转发到本地服务，远程转发的命令如下： 123# 将访问 remotehost 的 remote-port 端口的流量转发到 target-host 的 target-port 端口ssh -R remote-port:target-host:target-port -N remotehost 如上图，内网本地电脑无法连接外网，但是服务器 A 可以访问到本地电脑，外部网络想要访问到本地电脑，则可以通过远程端口转发的形式访问，运行如下命令： 123# 运行该命令后，只要访问 192.168.1.1 的 8080 端口就会将流量转发到 127.0.0.1 的 8080 端口ssh -N -R 8080:127.0.0.1:8081 192.168.1.1 动态端口转发动态转发指的是通过 SSH 监听本地的某个端口，将监听到流量数据转发通过 SSH 通道(即中间服务器)转发出去，动态端口转发的命令格式如下： 12ssh -D local-port tunnel-host -N 参考链接：1、https://vpsmore.com/ssh-scp-over-jump-server.html2、https://www.icode9.com/content-4-940210.html3、https://www.cainiaojc.com/ssh/ssh-port-forwarding.html4、https://solitum.net/posts/an-illustrated-guide-to-ssh-tunnels/#remote-tunnels","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"dnf 软件包管理工具","slug":"Linux/dnf软件包管理工具","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/dnf软件包管理工具/","link":"","permalink":"http://example.com/wiki/Linux/dnf%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"1. dnf 简介dnf 致力于改善 yum 的瓶颈，即性能、内存占用、依赖解决、速度和许多其他方面。DNF使用RPM、libsolv和hawkey库进行包管理。 2. 安装 dnf1234# 先 epel-release 仓库，因为默认的软件库中没有 dnf yum install epel-release -y# 安装 dnf yum install dnf 3. dnf 查看软件库12345# 查看可用的软件库dnf repolist# 查看所有软件库dnf repolist all 4. dnf 查看软件包123456789# 查看所有可用和已经安装的软件包dnf list # 查看已经安装的软件包dnf list installed # 查看所有可用的软件包dnf list available 5. dnf 搜索软件包搜索软件包的命令 dnf search 软件名 查找子软件包命令 dnf provides 软件名，如： 1234# 搜索软件包, 如查找 docker 软件包dnf search docker-ce # 子软件包dnf 6. dnf 查看软件包详情查看软件包详情使用命令dnf info 软件包名，如： 123# 如查看 docker 软件包详情dnf info docker-ce 7. dnf 添加软件仓库12# 如添加 docker 的阿里云软件源dnf config-manager --add-repo=https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 8. dnf 安装软件常用可选参数 -y 安装时，遇到确认默认全部选择 yes -q 不显示安装过程 -v, –verbose 详细显示安装过程 –nobest 不尝试将软件升级到最高的版本，不指定时默认是 –best 会尝试安装最高版本 –nodocs 不要安装文档 -e, –errorlevel 安装日志显示到 error 级别 -d, –debuglevel 安装日志显示到 debug 级别 –enablerepo 指定从哪个库中安装软件123456# 如安装 docker 软件dnf install docker-ce -y --nobest# 重新安装软件包dnf reinstall docker-ce 9. 升级软件1234567# 升级所有软件到最新的版本dnf update 或者 dnf upgrade # 升级所有软件到最新的稳定版本dnf distro-sync# 升级指定的软件包，如升级 dockerdnf update update -y docker-ce 10. 回滚降级软件123# 如回滚降级 dockerdnf downgrade docker-ce 11. 卸载、删除软件包12345678# 卸载指定的软件包，如卸载 dockerdnf remove -y docker-ce 或者 dnf erase -y docker-ce# 删除无用的依赖包，有些依赖包安装的时候用到，运行的时候用不到的dnf autoremove# 清理缓存中的无用软件包dnf clean all 11. 查看 dnf 的历史运行命令12# 查看运行过的历史命令dnf history 12. dnf module 命令12345678910111213# 查看所有可用的软件包dnf module list # 查看指定可用的软件包版本dnf module list 软件名# 安装指定版本的软件包, 注意使用冒号在软件名后面指定软件版本dnf module install docker-ce:19# 降级到指定版本使用以下命令dnf module reset docker-cednf module install docker-ce","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"iptables 学习笔记","slug":"Linux/iptables 学习笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/iptables 学习笔记/","link":"","permalink":"http://example.com/wiki/Linux/iptables%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1. iptables 简介iptables 是 Linux 防火墙软件，虽然已经被 nftables 取代了，但是仍然广泛的运用着。iptables 防火墙的网络地址转换、数据包修改，以及过滤功能，是由 Linux 内核中的 netfilter 模块实现的，iptables 通过命令行去定义服务器流量的进出规则，然后由 netfilter 模块去执行。 2. iptables 过滤和转发数据包的流程流量数据流量包经过主机内核时，会经过 PREROUTING、INPUT、OUTPUT、FORWARD 和 POSTROUTING 链路节点，通过 iptable 可以在这些节点上配置过滤、转发规则，每一个节点上可以配置多个规则，多个规则串联起来形成一条链(chain)，在节点中的链规则是从上往下执行的，只要某一条规则匹配成功，就不继续往下匹配，并执行规则中配置的 ACCEPT 或者 DROP 等等动作，链中的规则，按规则作用分组，然后每一个分组可以看作一个表(table)，因此不同作用规则要定义到指定的表中，表的说明如下： raw 表：控制 nat 表中连接追踪机制的启用状况，可以控制的链路节点有 PREROUTING、OUTPUT; mangle 表：用于修改数据包中的数据，可以控制的链路节点有 PREROUTING、INPUT、OUTPUT、FORWARD 和 POSTROUTING; nat 表：用于数据包的转发，可以控制的链路节点有 PREROUTING、INPUT、OUTPUT 和 POSTROUTING; filter 表：控制数据包是否允许进出及转发，可以控制的链路有 INPUT、FORWARD 和 OUTPUT。 总上所述，iptable 中常说的4表5链，指的就是 raw、mangle、nat、filter 和 PREROUTING、INPUT、OUTPUT、FORWARD、POSTROUTING。 2.1 iptales 规则netfilter 是从上到下的一条一条的匹配 iptables 在 raw -&gt; mangle -&gt; nat -&gt; filter 表中定义的规则，只要匹配成功就会执行规则中配置的动作，注意一旦匹配成功就不会继续往下匹配了，如果是定义的规则都不配会执行默认的(policy)策略 2.2 iptables 规则定义iptables 定义规则的语法如下： 12iptables -t &lt;table&gt; &lt;command&gt; &lt;chain&gt; &lt;match-parameter&gt; -j &lt;target&gt; &lt;target-parameter&gt; table 指定规则定义在哪个表中，如 raw、mangle、nat、filter 等。 command 指定规则的添加方式，如 -A 将规则追加到表的末尾，-I 将规则插入到表的指定行中, 行号要在 chain 后面指定，-P 指定链的默认规则。 chain 指定规则要定义在哪个节点链上 parameter 指定规则的过滤或者转发的条件参数，条件参数的个数时不限制的，可以同时指定任意多个 target 指定规则匹配要跳转执行的动作，如 ACCEPT、DROP 等等 2.3 定义规则 match-parameter(匹配参数)说明在规则中的使用参数，就是规则的匹配条件，流量数据包匹配规则中的参数，则说明规则匹配成功，注意大部分参数都是可以使用 ! 符号取反的，定义规则常用的参数如下: [!]-p 指定匹配的协议，不指定默认匹配所有跟 -p all 相同，可匹配的协议有 tcp、udp、udplite、icpm、esp、ah、sctp，其中可选 ! 符号表示取反，不匹配某个协议的意思 [!]-i 指定要匹配某个网卡进来的数据包，如 -i eth1，注意只能用在 PREROUTING 链、INPUT 链、FORWARD 链上 [!]-o 根据 -i 相反要匹配数据包从哪个网卡出去的 [!]-s,–source 指定匹配数据包的来源 IP 地址, 指定多个 IP 需要用逗号隔开，或者指定一个网段如 192.10.0.0&#x2F;16 [!]-d,–destination 与 -s 相反，用于指定匹配数据包访问的目标 IP 地址, 指定多个 IP 需要用逗号隔开，或者指定一个网段如 192.10.0.0&#x2F;16 [!]–sport 指定匹配数据包的来源端口，如果要指定多个端口，可以使用冒号隔开，如 –sport 22:25, 注意如果 :22 等同于 0:22 , 25: 等同于 25:65535 [!]–dport 指定匹配数据包访问的目标端口 -c, –set-counters 用于初始化规则的 PKTS(数据包)和 bytes (字节)计数器，如：-c 0 0 将经过规则的数据包和字节计数器置为0 –icmp-type 指定 icmp 类型，常用的可选值 8 或 echo-request 表示 ping 请求、0 或 echo-reply 表示 ping 应答 -j,–jump [target] 跳转到指定的动作或者用户定义链 -g,–goto [chain] 跳转到指定的链 2.3.1 扩展的匹配参数模块 iprange 模块，用于指定连续的 ip 访问, 扩展的参数如下： -m 指定要使用的扩展模块 –src-range 指定源 ip 范围 –dst-range 指定目的 ip 范围1iptables -t filter -A INPUT -m iprange --src-range 192.168.1.1-192.168.2.5 -j DROP string 模块，用于匹配报文中是否包含对应的字符串，扩展的参数如下： –string 指定要匹配的内容 –algo 可选参数，指定使用什么算法去匹配，如 bm 1iptables -t filter -A INPUT -m string --algo bm --string &quot;abcs&quot; -j DROP time 扩展模块，根据时间段区匹配报文，扩展的参数如下： –timestart 指定时间范围的开始时间，注意不可取反 –timestop 指定时间范围的结束时间，注意不可取反 –weekdays 指定星期的天数 –monthdays 用于指定月份的天数 –datestart 指定日期范围的开始日期，注意不可取反 –datestop 指定日期范围的结束时间，注意不可取反12345# 限制 ssh 只能在以下时间段链接iptables -t filter -I OUTPUT -p tcp --dport 22 -m time --timestart 08:00:00 --timestop 12:00:00 -j REJECTiptables -t filter -I OUTPUT -p tcp --dport 22 -m time --weekdays 1,2 -j REJECTiptables -t filter -I OUTPUT -p tcp --dport 22 -m time --monthdays 10,25 -j REJECTiptables -t filter -I OUTPUT -p tcp --dport 8220 -m time --timestart 08:00:00 --timestop 12:00:00 --weekdays 1,2 -j REJECT connlimit 扩展模块，用于匹配限制链接数量，扩展的参数如下： -connlimit-above 表示限制的链接数量 -connlimit-mask 用于指定要限制的网段1iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 80 --connlimit-mask 25 -j REJECT multiport 模块，用于指定多个端口, 扩展的参数如下： –sports –dports1ptables -I INPUT -p tcp --dports 22,25,26 -j REJECT 2.4 定义规则的 target(动作)和 target-parameter(动作参数)说明 ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，客户端会提示超时。 REJECT：拒绝数据包通过，会响应一个拒绝的信息，可选参数如下： –reject-with 参数用户设定回复的报文，可选值有 icmp host unreachable(无法访问)、icmp-port-unreachable、icmp-proto-unreachable、icmp-net-prohibited(禁止)、icmp-host-prohibited，如果是 TCP 还可以设置 tcp-reset 要求对方关闭链接 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题，使用 SNAT 时不需要配置 NDAT，iptables 会自动维护 NAT 表，并将响应报文的目标地址转换回来，可选参数如下： –to-source 用于设置源地址转换后的值 MASQUERADE：是 SNAT 的一种特殊形式，MASQUERADE 会自动将源 ip 动态转换到 -o 指定网卡的ip DNAT：目标地址转换，可选的参数如下： –to-destination 用于设置目的地址转换后的值 REDIRECT：在本机做端口映射，可选参数如下： –to-ports 用于设置目标端口转换后的值。使用该参数时，必须指定 -p [tcp|udp|sctp|dccp] –random 将目的端口转换成任意端口 LOG：会将访问日志记录到 &#x2F;var&#x2F;log&#x2F;messages 文件中，只是做日记记录，所以会继续往下匹配规则，可选的参数如下： –log-level 设定 iptables 日志的等级，可选值有 debug，info，notice，warning，err，emerg。默认是 info 级别。 –log-prefix 在日志消息中添加特定的字串前缀 RETURN 如果在自定义链的规则中使用，则跳回默认链，然后往下匹配默认链的规则，如果默认链中使用，则跳转到默认策略。 2.5 定义规则例子12345678910111213141516171819202122232425# 指定链的默认规则，如果所有规则都不匹配成功，就会执行链默认(policy)$ iptables -P INPUT DROP # 默认不允许访问$ iptables -P FORWARD DROP # 默认不允许转发$ iptables -P OUTPUT ACCEPT # 默认可以出去# 指定特定的网段才能连接主机的 ssh iptables -A INPUT -s 100.128.0.0/16 -p tcp --dport 22 -j ACCEPT# 拒绝访问 80 端口，并提示无法访问iptables -A INPUT -p tcp --dport 80 -j REJECT --reject-with icmp-host-unreachable# 主机禁止 ping，在 INPUT 和 OUTPUT 链上丢弃包都可以iptables -A INPUT -p icmp --icmp-type echo-request -j REJECTiptables -A OUTPUT -p icmp --icmp-type echo-request -j DROP# 应用使用内网 ip 去访问主机，利用 iptables 将内网 ip 转成外网的 ip iptables -t nat -A OUTPUT -d 192.168.0.88 -j DNAT --to-destination 116.205.143.251# 内网主机使用一个公网地址上网转发上网iptables -t nat -I POSTROUTING -s 172.16.0.0/16 -j SNAT --to-source 100.120.20.12# 内网主机使用一个公网地址上网转发上网, MASQUERADE 根据 SNAT 的区别是自动将源 ip 转换到 -o 指定网卡的外网ipiptables -t nat -I POSTROUTING -s 172.16.0.0/16 -o eht0 -j MASQUERADE 2.6 定义链的策略12# 定义 filter 表 OUTPUT 链的默认策略是允许访问，如果 OUTPUT 所有的规则都不匹配，就会执行默认的策略ipatables -t filter -P OUTPUT ACCPT 3. 自定义链自定义链主要为方便管理规则，自定义链是默认链规则的下一级匹配链。 3.1 创建和使用自定义链 创建自定义链使用命令 iptables -t [raw|mangle|nat|filter] -N &lt;自定义链名&gt; 12# 在 filter 表中创建一条名为 SSH-FIREWALL 的链，iptables -t filter SSH-FIREWALL 自定义链关联系统的默认链，数据包匹配默认链的规则后，跳转到自定义链，并继续匹配自定义链中的规则，自定义链相当于默认链规则的下一级匹配链12# 默认 INPUT 链中的规则匹配时跳转到自定义链 SSH-FIREWALL , 然后匹配 SSH-FIREWALL 链中的规则iptables -t filter INPUT -p tcp -dport 22 -j SSH-FIREWALL 在自定义链 SSH-FIREWALL 中定义规则123456# 定义数据包来源地址是 129.12.0.0 网段的，能访问 22 端口iptables -t filter SSH-FIREWALL -s 129.12.0.0/16 -j ACCEPT# 定义数据包来源地址是 100.12.0.0 网段的禁止访问 22 端口iptables -t filter SSH-FILEWALL -s 100.12.0.0/16 -j DROP# RETURN 动作在自定义链中使用，如果规则匹配，则跳回到默认链，并且往下匹配默认链的规则iptables -t filter SSH-FILEWALL -s 100.12.0.1 -j RETURN 3.2 重新命名自定义链1iptables -t [raw|mangle|nat|filter] -E &lt;旧的自定义链名&gt; &lt;新的自定义链名&gt; 3.3 删除自定义链删除自定链时，必须要先删除自定义链中的规则和删除默认链中关联的自定义链，删除自定义链的命令如下： 1iptables -t [raw|mangle|nat|filter] -X &lt;自定义链名&gt; 4. 查看规则查看 iptables 表规则时使用如下参数： -t 指定要查看的表，不使用 -t 指定表时，默认查看的是 filter 表 -L 查看指定链的规则，如果 -L 后面不指定链，则默认查看 -t 指定表所有的规则 -S 查看指定链的规则，与 -L 的区别是 -S 显示的是规则的定义语句，如果 -S 后面不指定链，会默认查看 -t 指定表的所有链，不能和 -n 一起使用 -n 将 IP 地址和端口号将以数字格式打印，默认显示为主机名、网络名或服务 -v, –verbose 输出详细信息，列出数据包和字节计数时会在后缀加 K、M 等单位 –line-number 显示规则的序列号，删除或修改规则时会用到 -x 显示数据包和字节计数器的展开值，不加单位 K、M 等单位123456789# 查看 filter 表的所有规则iptables -t filter -nL # 查看 nat 表 OUTPUT 链的规则iptables -t nat -L OUTPUT # 查看 nat 表的所有规则，并打印行号iptables -t nat -nL --line-numbers 查询规则显示的结果说明 pkts 规则匹配到的报文的个数。 bytes 匹配到的报文包的大小总和。 target 规则执行的动作。 prot 表示规则作用的协议。 opt 表示规则对应的选项。 in 表示数据包由哪个接口(网卡)流入，定义规则的时候，可以设置。 out 表示数据包由哪个接口(网卡)流出，定义规则的时候，可以设置。 source 表示规则对应的源头地址，可以是一个IP，也可以是一个网段。 destination 表示规则对应的目标地址，可以是一个 IP，也可以是一个网段。当然，我们也可以只查看某个链的规则，并且不让IP进行反解，这样更清晰一些，比如 iptables -nvL INPUT line-numbers 显示规则在对应表中的行号，删除的时候，指定行号去删除。 policy 表示当前链的默认策略，表示所有规则都没有匹配时，默认指定的动作。 packets 表示当前链（上例为INPUT链）默认策略匹配到的包的数量，0 packets表示默认策略匹配到0个包。 bytes 表示当前链默认策略匹配到的所有包的大小总和。 5. 将所有链中的数据包和字节计数器清零12# 将所有链中的数据包和字节计数器清零iptables -t [table] [-Z | --zero ] [chain] 6. 删除规则删除整个表的规则命令 iptables -t &lt;table&gt; -F 12345# 删除整个 filter 表的规则，不用 -t 指定表就默认时操作 filter 表iptables -F # 删除 nat 表的整个规则iptables -t nat -F 删除某一条规则的命令 iptables - &lt;table&gt; -D &lt;chain&gt; &lt;line-number&gt; ，例子如下： 12345# 查看规则的 chain 和 line-numberiptables -t filter -nL# 删除规则iptables -t filter -D INPUT 5 参考连接 https://www.frozentux.net/iptables-tutorial/cn/iptables-tutorial-cn-1.1.19.html#prelude https://ipset.netfilter.org/iptables.man.html#lbAH https://ipset.netfilter.org/iptables-extensions.man.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"YUM 常用命令","slug":"Linux/yum 常用命令","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/yum 常用命令/","link":"","permalink":"http://example.com/wiki/Linux/yum%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"Linux 常用命令记录","slug":"Linux/常用命令记录","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/常用命令记录/","link":"","permalink":"http://example.com/wiki/Linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","excerpt":"","text":"1. journalctl 命令查看 Linux 系统日志journalctl 命令用于查看 Linux 系统日志，常用参数如下 参数 作用 -k 查看内核日志 -b 查看系统本次启动的日志 -u 查看某个系统服务的日志 -n 指定日志条数 -f 实时刷新日志 -p 指定日志的级别 warning、info、debug、alert、err 等等 -o 指定日志的输出格式，如 -o json 或 -o json-pretty –since 查看指定日期时间的日志 –disk-usage 查看当前日志占用磁盘的空间的总大小 –no-pager 指定是否分页 常用的例子： 12345678910111213141516171819202122# 查看整个系统服务某个时间段的日志journalctl --since=&quot;2021-09-16 14:22:02&quot; journalctl --since &quot;30 min ago&quot;journalctl --since yesterdayjournalctl --since &quot;2021-01-01&quot; --until &quot;2021-09-16 13:40&quot;journalctl --since 07:30 --until &quot;2 hour ago&quot;# 查看内核日志, 显示最新的 100 条journalctl -k -n 100 # 查看指定服务的日志，如查看 docker 服务进程日志journalctl -u docker.service# 查看指定用户的日志，如查询 UID 为 101 用户的日志journalctl UID=101 --since today# 查看某个进程的日志journalctl -PID=123#显示日志占据的硬盘空间journalctl --disk-usage 2. find 命令find 查找文件或者目录的命令，简单使用的命令格式为 find [PATH] [OPTIONS] [OPERATORS] [ACTIONS]PATH 指定需要查找的目录，如果不指定则默认查找当前目录(命令执行所在的当前目录)OPTIONS 常用命令选项，选择参数的说明，如果参数中有[+-]符号表示大于小于，如 +5M 表示大于 5 的 M 文件 -inum inode： 按 inode 号来搜索文件，命令ls -il显示结果的第一列既为 inode 号 -name filename： 按文件目录名查找，支持 *、? 、[] 通配符模糊匹配 -iname filename： 按文件目录名查找忽略大小写 -type type： 按文件类型查找，linux 下的文件类型有： b -块设备文件 c -字符设备文件 d -目录 p -管道文件 f -普通文件 l -符号链接文件 s -socket文件 -size [+-]size[unit]： 按文件大小查找，如果加[+-]符号表示查找大于小于指定size的文件，不加表示查找等于 size 大小的文件，单位支持(c：字节,w：2字节，b：512字节，k：1024字节，M：1024k，G：1024M)，默认单位是b -atime [+-]day: 按照文件访问时间搜索，时间单位默认是天 -mtime [+-]day： 按照文改时间搜索，时间单位默认是天 -mmin [+-]min: 按照文改时间搜索，时间单位默认是分钟 -ctime [+-]day: 按照文件修改时间搜索，时间单位默认是天 -uid userid: 按照用户 ID 査找所有者是指定 ID 的文件 -gid groupid: 按照用户组 ID 査找所属组是指定 ID 的文件 -user username：按照用户名査找所有者是指定用户的文件 -group groupname：按照组名査找所属组是指定用户组的文件 -nouser：査找没有所有者的文件 -perm [+-]permnumber: 按权限查找文件 -path path：查找时忽略指定的目录 [!]-newer file 查找修改时间比某个文件早的文件或者晚的文件 OPERATORS 选项操作符号 -a 或者 -and： 表示多个 OPTIONS 都要满足，find 命令默认使用该操作符 -o 或者 -or： 表示两个 OPTIONS 只要满足一个即可，支持扩展号写法如：\\( -name &quot;.txt&quot; -o -name &quot;.log&quot; \\)，使用括号时需要 \\ 表示转义 -not：表示取反逻辑的 OPTIONS 条件 ACTIONS find 命令查找返回 Ture 后要执行的动作 -printf &lt;输出格式&gt; 按执行格式输出查找结果 -exec command &#123;&#125; [+|\\;] 查找命令返回成功后要执行的命令，如 -exec ls -il &#123;&#125; + 或者 -exec ls -il &#123;&#125; \\; 注意 {} 和 + 以及 \\; 都是固定的写法，且它们需要空格隔开，{} 表示匹配到的文件或者目录，如 -exec ls -il &#123;&#125;/data \\;，+ 或者 \\; 表示 -exec 的结束符号 3. 软硬链接在 Linux 下链接文件，主要用于解决文件的共享使用问题，软链接相当于 Window 的快捷方式，硬链接相当于为当前文件名对应的文件再创建一个文件别名对应的 inode 和物理存储的文件数据都是一样的，注意目录不能创建硬链接。 12345678# 为文件 hello.txt 创建软链接文件 hello1.txtln -s hello.txt hello1.txt# 为目录 /mnt/data/docker 传教软件链接目录 /var/lib/dockerln -s /mnt/data/docker /var/lib/docker# 为文件 hello.txt 创建硬链接文件 hello2.txtln hello.txt hello2.txt","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]},{"title":"Maven 问题记录","slug":"Maven/Maven 问题记录","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Maven/Maven 问题记录/","link":"","permalink":"http://example.com/wiki/Maven/Maven%20%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"当 Maven 依赖的 Java 环境是 OpenJDK 时，安装依赖出报以下问题1java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty 第一种临时的解决方式： 1mvn -U clean compile -Dmaven.wagon.http.ssl.insecure=true -Dmaven.wagon.http.ssl.allowall=true 第二种解决方式：从 Oracle 官网下载下载以下文件jdk7：下载 javase-jce7.jar http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.htmljdk8：下载 javase-jce8.jar https://www.oracle.com/java/technologies/javase-jce8-downloads.html 然后将解压后覆盖替换 ${JAVA_HOME}&#x2F;jre&#x2F;lib&#x2F;security 目录对应文件即可 如果还有问题的话，则需要在 ${JAVA_HOME}jre&#x2F;lib&#x2F;security&#x2F;java.security 文件末尾添加以为属性 crypto.policy&#x3D;unlimited","categories":[{"name":"Maven","slug":"Maven","permalink":"http://example.com/categories/Maven/"}],"tags":[]},{"title":"MySql 常用函数","slug":"MySql/MySql 常用函数","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/MySql/MySql 常用函数/","link":"","permalink":"http://example.com/wiki/MySql/MySql%20%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/","excerpt":"","text":"1. 字符串函数 SUBSTRING_INDEX(str, delimiter, index) 使用指定分割符(delimiter)，将字符串(str)分割成数组，并返回指定索引(index)的数组值12345# 使用 ll 将字符串分割成数组，并返回数组第一个元素SELECT SUBSTRING_INDEX(&quot;Hello&quot;,&quot;ll&quot;,1) # 根据逗号将字符串分割数组，并返回数组的最后一个值SELECT SUBSTRING_INDEX(&quot;A,B,C,D&quot;,&quot;,&quot;,-1) SUBSTRING(str, pos[, length ]) 截取指定范围内的字符串，参数说明 pos 指定开始截取的位置，pos 可以取值正负，起始值是 1 或者 -1 ，负数表示从字符后面倒数，length 表示截取的长度，为空是默认截取到字符结尾12345678# 从第一个位置开始截取2个长度的子字符串，返回 HESELECT SUBSTRING(&quot;HELLO&quot;,1,2)# 从倒数第二给位置开始，截取长度为 1 的子字符串，返回 LSELECT SUBSTRING(&quot;HELLO&quot;, -2,1)# 不指定 length 默认截取到字符串结尾，返回 LLOSELECT SUBSTRING(&quot;HELLO&quot;,-3) REPLACE( str, from_str, to_str) 替换字符串12# 将逗号替换成空格SELECT REPLACE(&quot;Hello,World&quot;,&quot;,&quot;,&quot; &quot;) LEFT(str, length) 从左开始截取指定长度的子字符串12# 从左边截取长度为2的子字符串，返回 HESELECT LEFT(&quot;HELLO&quot;, 2) RIGHT(str, length) 从右边开始截取指定长度的子字符串12# 返回 LOSELECT RIGHT(&quot;HELLO&quot;, 2) TRIM([{both | leading | trailing} [remstr] form] str) 将字符串 str去除 remstr 所指定的前缀或后缀，返回结果字符串。如果没有指定标识符both、leading，或trailing，则默认采用 both，即将前后缀都删除。remstr 其实是个可选参数，如果没有指定它，则删除的是空格1234567891011# 去掉字符串前后的空格，注意部分：制表符号空白是去不掉的SELECT TRIM(&quot; HELLO &quot;)# 等价于SELECT TRIM(BOTH &#x27; &#x27; FROM &#x27; HELLO &#x27;)# 去掉指定字符前缀SELECT TRIM(LEADING &#x27;hello&#x27; FROM &#x27;helloWorld&#x27;);# 去掉指定字符后缀SELECT TRIM( TRAILING, &#x27;hello&#x27; FROM &#x27;Worldhello&#x27;);# 去掉指定字符前后缀SELECT TRIM(BOTH &#x27;Hello&#x27; FROM &#x27;HelloWorldHello&#x27;);","categories":[{"name":"MySql","slug":"MySql","permalink":"http://example.com/categories/MySql/"}],"tags":[]},{"title":"MySql 开窗函数","slug":"MySql/MySql 开窗函数","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/MySql/MySql 开窗函数/","link":"","permalink":"http://example.com/wiki/MySql/MySql%20%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0/","excerpt":"","text":"简介MySql 是从8.0版本之后开始支持开窗函数，开窗函数也叫分析函数。 窗口函数除了聚合函数可以作为开窗函数， MySql 还提供了以下开窗函数。用于解决复杂报表统计需求的功能强大的函数。 函数名 函数作用 ROW_NUMBER() 行号 RANK() 排名 DENSE_RANK() 密集排名 PRECENT_RANK() 用于计算分区或结果集中行的百分位数 CUME_DIST() 返回一组值中值的累积分布，表示值小于或等于行的值除以总行数的行数 LAG() 用于统计窗口内往上第 n 行值 LEAD() 用于统计窗口内往下第 n 行值 FIRST_VALUE() 选择窗口框架，分区或结果集的第一行 LAST_VALUE() 返回有序行集中的最后一行 NTH_VALUE(expression, N) 从有序行集中的第N行获取值 NTILE() 将排序分区中的行划分为特定数量的组，从每个组分配一个从一开始的桶号，对于每一行，NTILE()函数返回一个桶号，表示行所属的组 窗口函数语法开窗函数语法格式：func_name([&lt;column&gt;]) OVER([PARTITION BY &lt;column&gt; | window_name] [ORDER BY &lt;column&gt;] [[ROWS | RANGE] BETWEEN frame_start AND frame_end]) OVER 函数中如果 paritition_clause 或者 window_name，则开窗函数统计分析全部数据 PARTITION BY 子句：与 GROUP BY 类似，用于按照指定字段进行分组数据 ORDER BY 子句：按照指定字段排序 partition by 子句分组的数据，如果没有指定 partition by 则排序全部数据 [ROWS | RANGE] BETWEEN frame_start AND frame_end 子句：在 PARTITION 分区的基础，再划分子分区 ROWS: ROWS 划定的子分区是以当前行为基准，前后偏移行数的范围 RANGE: 根据当前行的值划分子分区，注意如果使用 expr PRECEDING&#x2F;FOLLOWING 必须要 ORDER BY 一个数字或者时间类型的字段 子分区 frame_start(起始边界行)、frame_end(结束边界行) 可选值如下： CURRENT ROW：对于 ROWS 而言，以当前行作为边界行，对于 RANGE 而言，与当前行的值相同的都作为边界行 UNBOUNDED PRECEDING：以 PARTITION 分区的第一行作为起始边界行 UNBOUNDED FOLLOWING：以 PARTITION 分区的最后一行作为终点边界行 expr PRECEDING：对于 ROWS 而言 expr 值只能为数字，边界行是当前行的前前几行，对于 RANGE 而言 expr 值可以是数字或者时间表达式，行值等于大于ORDER BY 字段当前行的值减去表达式的值所得值的即为边界行 expr FOLLOWING：FOLLOWING 根据 PRECEDING 相对的，对于 ROWS 而言边界行是当前行的后几行，对于 RANGE 而言，行值等于小于 ORDER BY 字段当前行的值加上 expr 表达式的值即为边界行 例子说明 语法例子 12345678910111213141516171819# PARTITION BY 直接写在 OVER 函数中SELECT *, ROW_NUMBER() OVER(PARTITION BY `month` ORDER BY salary) AS `rownum`FROM (SELECT &#x27;2月&#x27; AS `month`, 3000 AS salaryUNION ALL SELECT &#x27;1月&#x27; AS `month`, 4000 AS salary) t# 使用 WINDOW 命名方式定义 PARTITION BY 字句和 ORDER BY 字句SELECT `month`, `salary`, ROW_NUMBER() OVER(w1 ORDER BY salary) AS `rownum1`, ROW_NUMBER() OVER(w2 ORDER BY salary) AS `rownum2`, ROW_NUMBER() OVER w3 AS `rownum3`, ROW_NUMBER() OVER w4 AS `rownum4`FROM (SELECT &#x27;2月&#x27; AS `month`, 3000 AS salaryUNION ALL SELECT &#x27;1月&#x27; AS `month`, 4000 AS salary) t WINDOW w1 AS (), w2 AS (PARTITION BY `month`), w3 AS ( ORDER BY salary), w4 AS (PARTITION BY `month` ORDER BY salary) ROW_NUMBER、RANK、DENSE_RANK 排序区别 1234567891011121314151617SELECT salary, ROW_NUMBER() OVER(ORDER BY salary) AS `rown_umber`, RANK() OVER(ORDER BY salary ) AS `rank`, DENSE_RANK() OVER(ORDER BY salary) AS `dense_rank` FROM (SELECT 1000 AS salary UNION ALLSELECT 1000 AS salary UNION ALLSELECT 2000 AS salaryUNION ALLSELECT 3000 AS salaryUNION ALL SELECT 3000 AS salaryUNION ALL SELECT 4000 AS salary) t 结果显示如下 salary rown_umber rank dense_rank 1000 1 1 1 1000 2 1 1 2000 3 3 2 3000 4 4 3 3000 5 4 3 4000 6 6 4 range 子分区窗口使用说明 123456789101112131415161718192021222324252627/* 注意 range 是 parition by 分区下的子分区，如果没有 paritiion by 则默认是所有记录下的子分析，使用 expr following 必须要 order by 时间或者数字类型的字段 */SELECT `name`,`month`, `salary`, /* 在 month 分区下，计算子分区为(当前行month值 &lt;= month &lt;= 当前行month值 + 1)内的行 */ SUM(salary) OVER(PARTITION BY month ORDER BY month RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) orderMonth, /* 在 month 分区下，计算子分区(当前行salary的值 &lt;= salary &lt;= 当前行salary值+100 )内的行 */ SUM(salary) OVER(PARTITION BY month ORDER BY salary RANGE BETWEEN CURRENT ROW AND 100 FOLLOWING) orderSalary, /* 没有 parition by 则表示，在所有记录的分区下，计算子分区(当前行month值 &lt;= month &lt;= 当前行month值 + 1)内的行 */ SUM(salary) OVER(ORDER BY month RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)FROM (SELECT &#x27;李思&#x27; AS `name`, 300 AS salary, 1 AS `month`UNION ALL SELECT &#x27;张三&#x27; AS `name`, 300 AS salary, 1 AS `month`UNION ALLSELECT &#x27;李思&#x27; AS `name`, 300 AS salary, 2 AS `month`UNION ALL SELECT &#x27;张三&#x27; AS `name`, 350 AS salary, 2 AS `month`UNION ALL SELECT &#x27;小鱼&#x27; AS `name`, 300 AS salary, 1 AS `month`UNION ALL SELECT &#x27;小鱼&#x27; AS `name`, 400 AS salary, 2 AS `month`UNION ALLSELECT &#x27;小明&#x27; AS `name`, 300 AS salary, 1 AS `month`UNION ALL SELECT &#x27;小明&#x27; AS `name`, 450 AS salary, 2 AS `month`) t rows 子分区窗口使用说明 12345678910111213141516171819202122232425SELECT `month`, `salary`, ROW_NUMBER() OVER(), SUM(salary) OVER(ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING), /*在 month 分区下，计算的子分区的范围是(当前行的row_number &lt;= row_number &lt;= 当前行的row_number + 1)之间的行*/ SUM(salary) OVER(PARTITION BY `month` ORDER BY `month` ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING), ROW_NUMBER() OVER(PARTITION BY `month` ORDER BY `month` )FROM (SELECT &#x27;李思&#x27; AS `name`, 300 AS salary, &#x27;1月份&#x27; AS `month`UNION ALL SELECT &#x27;张三&#x27; AS `name`, 300 AS salary, &#x27;1月份&#x27; AS `month`UNION ALLSELECT &#x27;李思&#x27; AS `name`, 300 AS salary, &#x27;2月份&#x27; AS `month`UNION ALL SELECT &#x27;张三&#x27; AS `name`, 350 AS salary, &#x27;2月份&#x27; AS `month`UNION ALL SELECT &#x27;小鱼&#x27; AS `name`, 300 AS salary, &#x27;1月份&#x27; AS `month`UNION ALL SELECT &#x27;小鱼&#x27; AS `name`, 400 AS salary, &#x27;2月份&#x27; AS `month`UNION ALLSELECT &#x27;小明&#x27; AS `name`, 300 AS salary, &#x27;1月份&#x27; AS `month`UNION ALL SELECT &#x27;小明&#x27; AS `name`, 450 AS salary, &#x27;2月份&#x27; AS `month`) t 参考链接1、https://dev.mysql.com/doc/refman/8.0/en/window-functions.html","categories":[{"name":"MySql","slug":"MySql","permalink":"http://example.com/categories/MySql/"}],"tags":[]},{"title":"Mysql 部分词汇含义","slug":"MySql/Mysql 部分词汇含义","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/MySql/Mysql 部分词汇含义/","link":"","permalink":"http://example.com/wiki/MySql/Mysql%20%E9%83%A8%E5%88%86%E8%AF%8D%E6%B1%87%E5%90%AB%E4%B9%89/","excerpt":"","text":"DDL(Data Definition Languages)DDL 是数据库定义语句，用来创建数据库中的表、索引、视图、存储过程、触发器等，常用的语句关键字有：CREATE,ALTER,DROP,TRUNCATE,COMMENT,RENAME。 DML(Data Manipulation Language)DML 是数据操纵语句，用于查询、添加、更新、删除等，常用的语句关键字有：SELECT, INSERT, UPDATE, DELETE, MERGE, CALL,EXPLAIN PLAN, LOCK TABLE。 DCL(Data Control Language)DCL 是数据控制语句，用于授权&#x2F;撤销数据库及其字段的权限，常用的语句关键字有：GRANT, REVOKE。 TCL(Transaction Control Language)TCL 是事务控制语句，用于控制事务，常用的语句关键字有：COMMIT, ROLLBACK, SAVEPOINT, SET TRANSACTION。","categories":[{"name":"MySql","slug":"MySql","permalink":"http://example.com/categories/MySql/"}],"tags":[]},{"title":"Nginx 常用命令","slug":"Nginx/Nginx 常用命令","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Nginx/Nginx 常用命令/","link":"","permalink":"http://example.com/wiki/Nginx/Nginx%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"启动命令 linux 启动方式 12345# -c 指定 nginx 配置文件 nginx -c /path/conf/nginx.conf# -p 指定 nginx 所在路径前缀，启动时会根据前缀路径查找 conf 文件夹下的 nginx.conf 配置文件nginx -p /path/ window 启动方式 12# 注意需要 nginx 的安装目录去执行命令，如果配置了 nginx 的环境变量，默认读取的用户用户的下的配置，需要 conf、logs 等相关文件夹复制到用户目录才行start nginx 其他常用命令 -?,-h : 查看帮助信息 -v : 显示版本信息 -V : 显示版本信息和编译配置参数 -t : 测试配置文件是否正确 -T : 测试配置文件是否正确，同时输出所有有效配置内容 -q : 在配置测试期间禁止显示非错误消息 -s signal : 向主进程发送信号，常用的信号有 stop 快速关闭, quit 正常关闭, reopen 重新打开日志文件, reload 重新加载配置文件，启动一个加载新配置文件的 Worker Process, 正常关闭一个加载旧配置文件的 Worker Process -e filename : 指定 error 文件路径 -c filename : 指定配置文件路径 -g directives : 指定全局配置指令, 如：nginx -g “daemon off;”","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[]},{"title":"","slug":"Nginx/Tengine安装笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Nginx/Tengine安装笔记/","link":"","permalink":"http://example.com/wiki/Nginx/Tengine%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/","excerpt":"","text":"title: tengine 安装笔记编译安装 nginx 淘宝定制的 官网下载 tengine 解压文件 tar zxvf tengine-2.3.3.tar.gz cd tengine-2.3.3 ./configure make sudo make install 默认会将 tengine 安装到 &#x2F;usr&#x2F;local&#x2F;nginx 下 编译提示 error: the HTTP rewrite module requires the PCRE library 安装 yum -y install pcre-devel 编译提示error: SSL modules require the OpenSSL library安装 yum -y install openssl openssl-devel 注意使用 ./configure 生成 makefile 时，可以使用 ./configure --help 查看其有哪些参数可设置，其中部分参数例子，使用如下： 12# --prefix 参数指定安装目录，--add-module 指定要安装的第三方模块目录，使用 --without 禁用默认模块，使用 --with 启动默认的模块 ./configure --prefix=/usr/local/nginx --add-module=/home/sysadmin/ngx_log_if-master --add-module=xxxxx --without-stream_return_module 将 nginx 注册为系统服务在 &#x2F;lib&#x2F;systemd&#x2F;system&#x2F; 目录创建 nginx.service 文件，如下： 123456789101112[Unit]Description=nginx serviceAfter=network.target[Service]Type=forking# 指定启动命令ExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s stopPrivateTmp=true[Install]WantedBy=multi-user.target nginx 服务启动的相关命令： 12345678systemctl start nginx.service 启动nginx服务systemctl stop nginx.service 停止服务 systemctl restart nginx.service 重新启动服务 systemctl list-units --type=service 查看所有已启动的服务 systemctl status nginx.service 查看服务当前状态 systemctl enable nginx.service 设置开机自启动 systemctl disable nginx.service 停止开机自启动 nginx1.18 以后动态添加模块运行命令 nginx -V 查看 nginx 已经安装了哪些模块，运行命令后显示示例结果如下： 123456Tengine version: Tengine/2.3.2nginx version: nginx/1.17.3built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --add-module=/home/sysadmin/ngx_log_if-master 重新使用 .&#x2F;configure 生成新的 makefile 时，需要把旧 nginx 程序中的 configure arguments中的参数也要带上，不然已安装或者禁止的模块会丢弃。 1./configure --prefix=/usr/local/nginx --add-module=/home/sysadmin/ngx_log_if-master --add-module=新增第三方的模块 ./configure 之后，然后运行 make 编译生成新的 nginx 程序，注意make 之后，不要make install因为 make install 是覆盖安装。make 完之后新的 nginx 程序会生成在跟 configure 同级的 objs 目录中。运行 ./objs/nginx -V 如果看到编译参数已经变成新编辑的参数，说明编译成功。 将新编译生成的 nginx 覆盖原来的 nginx 即可，注意备份原来的 nginx","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[]},{"title":"location 和 rewrite 笔记","slug":"Nginx/location 指令笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Nginx/location 指令笔记/","link":"","permalink":"http://example.com/wiki/Nginx/location%20%E6%8C%87%E4%BB%A4%E7%AC%94%E8%AE%B0/","excerpt":"","text":"location 指令location 指令由 ngx_http_core_module 模块提供，官方文档说明 12345Syntax: location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name &#123; ... &#125;Default: —Context: server, location The matching is performed against a normalized URI, after decoding the text encoded in the “%XX” form,resolving references to relative path components “.” and “..”, and possible compression of two or more adjacent slashes into a single slash. 匹配是针对标准化的 URI 执行的，故在执行前，会将 URI 中以 %XX 形式编码的文本先进行解码、及解析对相对路径中 . 和 .. 组件的引用，和尽可能的去将路径中 // 压缩替换成 /。 A location can either be defined by a prefix string, or by a regular expression. Regular expressions are specified with the preceding “*” modifier (for case-insensitive matching), or the “” modifier (for case-sensitive matching). To find location matching a given request, nginx first checks locations defined using the prefix strings (prefix locations). Among them, the location with the longest matching prefix is selected and remembered. Then regular expressions are checked, in the order of their appearance in the configuration file. The search of regular expressions terminates on the first match, and the corresponding configuration is used. If no match with a regular expression is found then the configuration of the prefix location remembered earlier is used. location 的 URI 匹配规则可以使用前缀字符串定义，也可以由正则表达式定义。使用正则表达式，前缀指定 ~* 修饰符（用于不区分大小写的匹配）或 ~ 修饰符（适用于区分大小写匹配）。查找 location 匹配请求时，nginx 会优先检查匹配使用前缀字符串定义的 location，如果存在多个匹配的前缀字符串 location，则会取优先选择最长前缀字符串的 location 记录起来，然后按照正则表达式在配置文件中的出现顺序检查匹配正则表达式 location，搜索匹配到第一个正则表达式 location 时，就会终止查找匹配，并使用该正则表达作为最终的匹配结果。如果找不到匹配的正则表达式 location，则使用前面记录的的前缀字符串 location。 location blocks can be nested, with some exceptions mentioned below. location 语句块是可以嵌套的，除了下面提到的一些情况是例外的。 For case-insensitive operating systems such as macOS and Cygwin, matching with prefix strings ignores a case (0.7.7). However, comparison is limited to one-byte locales. 对于 macOS 和 Cygwin 等不区分大小写的操作系统，匹配前缀字符串 location 会忽略大小写（ 0.7.7 版本）。然而，比较仅限于一个字节的区域设置。 Regular expressions can contain captures (0.7.40) that can later be used in other directives. 正则表达式可以包含捕获(0.7.40)，稍后可以在其他指令中使用。 If the longest matching prefix location has the “^~” modifier then regular expressions are not checked. 如果匹配最长的前缀字符串 location 前缀使用 ^~ 修饰符，则不会在继续检查匹配正则表达式 location。 Also, using the “&#x3D;” modifier it is possible to define an exact match of URI and location. If an exact match is found, the search terminates. For example, if a “&#x2F;” request happens frequently, defining “location &#x3D; &#x2F;” will speed up the processing of these requests, as search terminates right after the first comparison. Such a location cannot obviously contain nested locations. 当然，使用 = 修饰符定义的前缀字符串 location，它会精准匹配 URI。如果精准匹配 location 匹配上了，就会终止后续的匹配。例如，如果一个 / 频繁的请求，使用 = 符号，定义一个 location = / 精准匹配，将加快对这些请求的处理，由于匹配上第一精准的 location 之后就在终止继续查找匹配。像这样的 location 显然是不能嵌套另一个 location 的。 In versions from 0.7.1 to 0.8.41, if a request matched the prefix location without the “&#x3D;” and “^~” modifiers, the search also terminated and regular expressions were not checked. 在 0.7.1 到 0.8.41 版本中，如果请求与前缀字符串的 location 匹配，但没有 = 和 ^~ 修饰符，也会终止检查匹配，并且不检查正则表达式。 Let’s illustrate the above by an example: 让我们通过一个例子来说明以上内容： 12345678910111213141516171819202122232425# 精准匹配，完整的匹配请求的 URIlocation = / &#123; [ configuration A ]&#125;# 普通前缀匹配location / &#123; [ configuration B ]&#125;# 普通前缀匹配location /documents/ &#123; [ configuration C ]&#125;# 普通前缀匹配，^~ 符号表示，最长普通前缀匹配到后，就不再匹配正则表达式location ^~ /images/ &#123; [ configuration D ]&#125;# 不区分大小写正则表达式匹配location ~* \\.(gif|jpg|jpeg)$ &#123; [ configuration E ]&#125;# 区分大小写正则表达式匹配location ~ \\.(css|js)$ &#123; [ configuration F ]&#125; The “&#x2F;” request will match configuration A, the “&#x2F;index.html” request will match configuration B, the “&#x2F;documents&#x2F;document.html” request will match configuration C, the “&#x2F;images&#x2F;1.gif” request will match configuration D, and the “&#x2F;documents&#x2F;1.jpg” request will match configuration E. 访问 / 请求会匹配 configuration A，访问 /index.html 请求会匹配 configuration B，访问 /documents/document.htm 会匹配 configuration C，访问 /images/1.gif 请求会匹配 configuration D，和访问 /documents/1.jpg 请求会匹配 configuration E。 The “@” prefix defines a named location. Such a location is not used for a regular request processing, but instead used for request redirection. They cannot be nested, and cannot contain nested locations. @ 符号前缀定义命名 location，这样定义的 location 不能用于常规请求处理，但是可以嵌套在其他 location 中用于请求重定向和转发请求，它们自身是不能嵌套其他 locations 的。 If a location is defined by a prefix string that ends with the slash character, and requests are processed by one of proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, or grpc_pass, then the special processing is performed. In response to a request with URI equal to this string, but without the trailing slash, a permanent redirect with the code 301 will be returned to the requested URI with the slash appended. If this is not desired, an exact match of the URI and location could be defined like this: 如果一个 location 的匹配规则使用前缀字符定义，并且结尾是 / 字符，并且请求由 proxy_pass、fastcgi_pass、uwsgi_pass、scgi_pass、memcached_pass 或 grpc_pass 其中的一个处理，则会执行响应特殊处理。 一个请求 URI 与响应（转发）的 URI 前缀路径相同，但是响应（转发）的 URI，不是以 / 结尾的，将会返回代码为 301 的永久重定向到 以 ‘&#x2F;‘ 结尾的请求 URI。如果不希望这样做，可以定精确匹配 location 来匹配 URI，如下面的例子： 12345678location /user/ &#123; proxy_pass http://user.example.com;&#125;location = /user &#123; proxy_pass http://login.example.com;&#125; 参考链接 https://nginx.org/en/docs/http/ngx_http_core_module.html#location","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[]},{"title":"ngx_http_proxy_module 模块学习笔记","slug":"Nginx/ngx_http_proxy_module模块笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Nginx/ngx_http_proxy_module模块笔记/","link":"","permalink":"http://example.com/wiki/Nginx/ngx_http_proxy_module%E6%A8%A1%E5%9D%97%E7%AC%94%E8%AE%B0/","excerpt":"","text":"介绍The ngx_http_proxy_module module allows passing requests to another server. ngx_http_proxy_module 模块允许转发请求到其他的服务器，即我们平时所说的反向代理。 proxy_pass 指令官网语法说明 123Syntax: proxy_pass URL;Default: —Context: location, if in location, limit_except 该指令用于设置请求匹配 location 后，转发的代理服务器的 protocol 和 address 以及可选 URI。protocol 可以指定使用 http 或者 https，adress 可以指定为域名或者 ip 地址和可选的端口号(没有端口则默认端口80)，使用例子如下： 123456789101112131415# protocol:address:portlocation / &#123; proxy_pass http://127.0.0.1;&#125;# protocol:address:port/urilocation / &#123; proxy_pass http://127.0.0.1:90/test;&#125;# UNIX-domain socket location / &#123; proxy_pass http://unix:/tmp/backend.socket:/uri/;&#125; 请求的转发规则如下： 如果 proxy_pass 指令带有 URI，那么当请求需要转发到服务器时，请求 URI 与 location 匹配的前缀部分字符串，将会被替换成 proxy_pass 指令中指定的 URI。故请求的最终转发地址等于：proxy_pass-host + request-uri.replace前缀(location-prefix-uri, proxy_pass-uri) 123456789101112131415161718192021222324252627282930313233# 转发的替换公式：http://127.0.0.1:8080 + request-uri.replace前缀(location-prefix-uri, proxy_pass-uri)，注意 request-uri 是包含请求参数的。# 访问 http://127.0.0.1/name/ 时，nginx 会将请求 URI = /name/ 与 location 前缀匹配字符串 /name/ 匹配的替换成 proxy_pass 的 URI = /remote/ 则转发后的地址为 http://127.0.0.1:8080/remote/# 访问 http://127.0.0.1/name/user?name=90 时，nginx 会将请求 URI 与 location 匹配的 /name/ 部分替换成 /remote/，则转发后的地址为 http://127.0.0.1:8080/remote/user?name=90location /name/ &#123; proxy_pass http://127.0.0.1:8080/remote/;&#125;# 访问 http://127.0.0.1/test 时，nginx 会将请求 URI 与 location 匹配的 /test 部分替换成 proxy_pass 的 URI(/remote), 则替换后的转发 URI = /remote# 访问 http://127.0.0.1/test/hello 时，nginx 会将请求 URI 与 location 匹配的 /test 部分替换成 proxy_pass 的 URI(/remote)，则替换后的转发 URI = /remote/hellolocation /test &#123; proxy_pass http://127.0.0.1:8080/remote;&#125;# 访问 http://127.0.0.1/hello 时，前缀不匹配该 location# 访问 http://127.0.0.1/hello/ 时，nginx 会将请求 URI(/hello/) 与 location 匹配的 /hello/ 部分替换成 proxy_pass 的 URI(/remote), 则替换后的转发 URI = /remote# 访问 http://127.0.0.1/hello/world 时，nginx 会将请求 URI(/hello/) 与 location 匹配的 /hello/ 部分替换成 proxy_pass 的 URI(/remote)，则替换后的转发 URI = /remotehellolocation /hello/ &#123; proxy_pass http://127.0.0.1:8080/remote;&#125;# 以下，是另一种表达方式# 访问 http://127.0.0.1/test/adc?param=xxx , location 匹配到请求的 URI = /test/adc 后，nginx 会将请求 URI 中与 location 匹配的前缀字符 / 去掉，变成 test/adc 后，# 再匹配拼接到 proxy_pass 的 URI 中，则转发后的地址是 http://127.0.0.1/pathtest/adc?param=xxxlocation / &#123; proxy_pass http://127.0.0.1/path; &#125;# 访问 http://127.0.0.1/get/test 时，location 匹配到请求的 URI = /get/test 后，会将请求 URI 中与 location 匹配的 /get 前缀字符串去掉，然后将剩余部分 /test，再拼接到 proxy_pass URI 中，则最终的转发地址为 http://127.0.0.1/get/path/testlocation /get &#123; proxy_pass http://127.0.0.1/get/path; &#125; 如果 proxy_pass 指令没有带有 URI，那么当请求转发到服务器时，转发后的 URI，就是请求匹配 location 的 URI。123456789location /some/path/ &#123; proxy_pass http://127.0.0.1;&#125;# 等价于location /some/path/ &#123; proxy_pass http://127.0.0.1:8080$request_uri;&#125; 访问 http://127.0.0.1/some/path 则转发后的地址为 http://127.0.0.1:8080/some/path访问 http://127.0.0.1/some/path/test 则转发后的地址为 http://127.0.0.1:8080/some/path/test访问 http://127.0.0.1/some/path?param=xxx 则转发后的地址为 http://127.0.0.1:8080/some/path?param=xxx 注意以下几种情况是 proxy_pass 指令不能携带 URI 的 如果 location 的匹配规则使用的是正则表达，proxy_pass 不能携带 URI 1234567891011# 区分大小写正则表达式匹配 URIlocation ~ /path &#123; # 不能携带 URI，否则会报错 proxy_pass http://127.0.0.1;&#125;# 不区分大小写正则表达式匹配 URIlocation ~* /case-insensitive /path/ &#123; # 不能携带 URI，否则会报错 proxy_pass http://127.0.0.1;&#125; 当在 location 中使用 rewrite 指令时，proxy_pass 指令不能携带 URI 12345location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; # rewrite 匹配不成功时，执行 proxy_pass proxy_pass http://127.0.0.1;&#125; 在具名的 location 中 proxy_pass 指令不能携带 URI 1234location @testname &#123; # 注意不能指定 URI proxy_pass http://127.0.0.1;&#125; 在 if 条件中 proxy_pass 指令不能携带 URI 12345678910111213location /test &#123; if ($host = &quot;test.adb.com&quot; )&#123; # 不能携带 URI proxy_pass http://127.0.0.1; &#125; if ($host = &quot;view.adb.com&quot; ) &#123; # 不能携带 URI proxy_pass http://127.0.0.1; &#125; # 这里可以 proxy_pass http://127.0.0.1/user;&#125; 参考链接 在线测试 nginx 链接","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[]},{"title":"ngx_http_rewrite_module 模块学习笔记","slug":"Nginx/ngx_http_rewrite_module 模块笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Nginx/ngx_http_rewrite_module 模块笔记/","link":"","permalink":"http://example.com/wiki/Nginx/ngx_http_rewrite_module%20%E6%A8%A1%E5%9D%97%E7%AC%94%E8%AE%B0/","excerpt":"","text":"介绍ngx_http_rewrite_module 主要用于改变请求的 URI，通过 PCRE 正则表达式，return 指令，以及有选择的配置条件去改变。 模块中的 break、if、return、rewrite 和 set 指令会按以下顺序执行处理： 在同一级别指令语句块中按配置文件中出现的位置，按顺序执行； 如果对一个请求 URI 使用 rewrite 重定向，限制最多只能重定向10次。 一个 URL 请求到达 nginx 时，nginx 先会顺序执行 server 指令语句块中的 ngx_http_rewrite_module 指令集合，如果执行到 break 指令会直接返回 404，执行到 return 指令也会直接返回，执行到 rewrite 如果匹配 rewrite 表达式,将会重写请求的 URI 然后使用重写后的 URI 再去匹配 location。如果 server 指令语句块中没有 ngx_http_rewrite_module 指令集合或者有匹配不到的情况下，请求的 URL 则会去匹配 location。 ngx_http_rewrite_module 模块指令日志记录，记录在 error_log 文件中的，且日志的级别需要改成 notice 级别。rewrite 指令的日志还需要开启 rewrite_log。 123rewrite_log on;error_log logs/error.log notice; break 指令break 指令的官网语法如下： 123Syntax: break;Default: —Context: server, location, if break 用于终止 ngx_http_rewrite_module 指令集合,即同一个指令块作用域内的指令集合。使用例子说明如下： 1234567891011121314151617181920212223242526272829303132333435363738http &#123; # ngx_http_rewrite_module 模块中的指令的优先级比 ngx_http_core_module 模块中的指令高。 server &#123; # 访问 127.0.0.1/b3 时，依次顺序执行 ngx_http_rewrite_module 指令，执行 break 执行后，将无法在执行后面的 rewrite ^/b3 /test/b3 指令，故会返回 404。 rewrite ^/b1 /test/b1; rewrite ^/(b2) /test/$1; # 执行到 break 指令, 将不会执行下面的 rewrite，因为 break 指令会终止 ngx_http_rewrite_module 模块中的指令执行 break; rewrite ^/b3 /test/b3; location /test/b3 &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; return 200 &quot;Hello My is test-b3&quot;; &#125; location /test &#123; # 注意 break 只能终止 ngx_http_rewrite_module 指令集合，所以执行 break 指令后, return 不会在执行，但是会执行 pass_proxy break; return 200 &quot;this test break &quot;; pass_proxy: 127.0.0.1/xxx/ &#125; location /break &#123; # 通过 break 语句，控制改走 return 还是走 pass_proxy if ( $uri == &#x27;/break/xx&#x27;) &#123; break; &#125; # 上面的 if 指令满足后，执行 break 指令，会终止 return 执行，然后运行 pass_proxy 执行，如果条件不满足，不执行 break 则会执行 return 语句直接返回，就会执行不到 pass_proxy 指令 return 200 &quot;this test break &quot;; pass_proxy: 127.0.0.1/break &#125; &#125;&#125; if 指令if 指令的官方语法如下： 123Syntax: if (condition) &#123; ... &#125;Default: —Context: server, location if 指令支持的判断条件如下： 空字符串和 0 默认 false，在1.0.1版本之前，任何以 0开头的字符串也被认为是 false 123456789set $var 0;location /test &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if ($var) &#123; return 200 &quot;this is true&quot;; &#125; return 200 &quot;this is flase&quot;;&#125; 变量和字符串比较只支持 &#x3D; 和 !&#x3D; 符号 123456789location /test &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if ($request_method = POST) &#123; return 200 &quot;this is POST method&quot;; &#125; # 变量支持在字符串中使用 return 200 &quot;unkown $request_method method&quot;;&#125; 支持变量和正则表达式匹配，~ 符号表示区分大小写匹配，~* 表示不区分大小写匹配，正则匹配支持非运算符 !~ 和 !~*，同时支持捕获组，捕获组可通过 $1..$9 变量获取值。如果正则表示式包含 &#125; 和 ; 符号，那么正则表达式必须使用引号包起来。 1234567location /test &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; return 200 &quot;id = $0&quot;; &#125; return 200 &quot;hello world&quot;;&#125; 支持使用 -f 和 !-f 符号检查文件是否存在 1234567location /exists &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if (-f C:/DevTools/nginx-1.22.1/html/index.html) &#123; return 200 &quot;file is exists&quot;; &#125; return 200 &quot;file is not exists&quot;;&#125; 支持使用 -d 和 !-d 符号检查目录是否存在 1234567location /exists &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if (-d C:/DevTools/nginx-1.22.1/html) &#123; return 200 &quot;dir is exists&quot;; &#125; return 200 &quot;dir is not exists&quot;;&#125; 支持使用 -e 和 !-e 运算符检查文件、目录或符号链接是否存在 1234567location /exists &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if (-e C:/DevTools/nginx-1.22.1/html/index.html) &#123; return 200 &quot;dir is exists&quot;; &#125; return 200 &quot;dir is not exists&quot;;&#125; 支持使用 -x 和 -x 运算符检查可执行文件 1234567location /exec &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; if (-x C:/DevTools/nginx-1.22.1/nginx.exe) &#123; return 200 &quot;file is exec&quot;; &#125; return 200 &quot;file is not exec&quot;;&#125; 不支持与或逻辑符号判断,但是可以通过变量拼接字符串的形式实现 1234567891011121314set $flag &quot;&quot;;location /test &#123; if ($request_method = POST) &#123; set $flag &quot;$flag1&quot;; &#125; if ($protocol = HTTP) &#123; set $flag &quot;$flag1&quot;; &#125; if ($flag = &quot;11&quot;) &#123; return 200 &quot;this is and &quot;; &#125; return 200 &quot;hello world&quot;&#125; rewrite 指令rewrite 指令的官方语法如下： 123Syntax: rewrite regex replacement [flag];Default: —Context: server, location, if If the specified regular expression matches a request URI, URI is changed as specified in the replacement string. The rewrite directives are executed sequentially in order of their appearance in the configuration file. It is possible to terminate further processing of the directives using flags. If a replacement string starts with “http:&#x2F;&#x2F;”, “https:&#x2F;&#x2F;”, or “$scheme”, the processing stops and the redirect is returned to a client. 如果指定的 regex 正则表达式匹配请求的 URI, URI 将会被替换成指定 replacement 字符串。重写指令按照它们在配置文件中出现的顺序依次执行。可以使用标志符来终止对指令的进一步处理。如果 repalcement 字符串以 “http:&#x2F;&#x2F;“、”https:&#x2F;&#x2F;“ 或 “$scheme” 开头，则停止处理并将重定向返回给客户。 falg 可选值说明： last：表示 regex 正则表达式匹配到 URI 后立即停止处理当前 ngx_http_rewrite_module 指令集合，并用 replactment 后的 URI 匹配查找 location break：表示 regex 正则表达式匹配到 URI 停止处理当前 ngx_http_rewrite_module 指令集合，如同处理 break 指令一样 redirect：返回一个状态是 302 的临时重定向 permanent：返回一个状态是 301 的永久重定向 永久重定向和临时重定向的区别是：浏览器会缓存永久重定向会记录，比如浏览器第一次访问 A 链接，如果返回 301 永久重定向到 B 链接，浏览器就会缓存 A 链接到 B 链接重定向记录，当浏览器再访问 A 链接时，如果缓存中有重定向记录则会直接重定向到 B 链接。如果第一次访问返回的 302 临时重定到 B 链接，浏览器每次都会重新 A 链接由 nginx 判断是不是重定向。即永久重定向会读缓存减轻服务器压力，临时重定向不会缓存，因为是临时的，临时说明随时会改变的所以不能缓存起来。 rewrite 指令在 server 指令语句块的例子说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546http&#123; # 注意，在同一指令语句块中所有的 rewrite 指令是一个集合，nginx 会按顺序匹配，并且优选高于 location，在 server 指令中使用 last 和 break 符号，其效果是一样的。 server&#123; # 没有使用 last 或者 break 标识符，如访问 127.0.0.1/test 会按 rewrite 指令的顺序去匹配 /test ，匹配到 ^/test 后，还会继续使用重写后的 URI 重写匹配，一直往下匹配到 test5，然后在使用 test5 去匹配查找 location rewrite ^/test /test1; rewrite ^/test1 /test2; rewrite ^/test2 /test3; rewrite ^/test3 /test4; rewrite ^/test4 /test5; # 如访问 127.0.0.1/last2 时，nginx 会按顺序从上面的 ^/test 开头的 rewirte 一直到 ^/last2 时匹配成功，重写 URI 为 /last3 因为 last 标识符结尾，所以直接终止匹配，然后使用 /last3 去匹配 location， # 如果能匹配查找到 location 则返回结果，否则直接返回 404 rewrite ^/last /last1 last; rewrite ^/last1 /last2 last; rewrite ^/last2 / last3 last; # 注意, 如果重写的 URI 使用的是 http 协议开头，则相当于临时重定向，会直接返回给浏览器，浏览器在重定向请求新的 URL。只有重写请求的 URI 部分，nginx 才会去重新执行后续的 rewrite 或者匹配查找 location rewrite ^/redirect http://127.0.0.1/test.com; rewrite ^/redirect/last http://127.0.0.1/test.com last; rewrite ^/redirect/break http://127.0.0.1/test.com break; # 如访问访问 127.0.0.1/hello 也是先匹配 rewrite 集合如果匹配不到，再匹配查找 location，如果都匹配不到的话，nginx 会直接返回 404 location /hello &#123; &#125; location /last3 &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; return 200 &quot;this is /last2 rewrite /last3&quot; &#125; location /test5 &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; return 200 &quot;this is /test rewrite /test5&quot; &#125; &#125;&#125; 在 location 指令中的 rewrite 指令例子： 12345678910111213141516location /break &#123; # location 中的 rewrite 使用 break 标识，如果匹配了，就会去访问 nginx 安装目录下 html 目录的 test/page 文件 rewrite ^/break /test/page break; # 如果 rewrite 不匹配，执行 return add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; return 200 &quot;can&#x27;t match rewrite, so return&quot;;&#125;location /last &#123; # location 中的 rewrite 如果使用 last 标识，根 server 指令中的效果一致 rewrite ^/break /test last; # 匹配不通过就走 return, 因为 return 的优先级比 pass_proxy 高 pass_proxy 127.0.0.1/hello; return 200 &quot;Hello this is last&quot;;&#125; 获取正则表达的值： 1234567# 访问 http://127.0.0.1/download/public/media/test.mp3location /download/ &#123; rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra break; return 403;&#125; return 指令return 的官方语法如下： 123456Syntax: return code [text];return code URL;return URL;Default: —Context: server, location, if 常用例子如下： 123456789101112131415161718192021222324# 单独返回状态码location /return0 &#123; return 404;&#125;# 返回字符串location /return1 &#123; add_header Content-Type &#x27;text/html; charset=utf-8&#x27;; return 200 &quot;request is success&quot;;&#125;# 302 重定向请求location /return2 &#123; return https://baidu.com; # 或者 return 302 https://baidu.com;&#125;# 返回内置变量location /return3 &#123; return 200 &quot;请求的 URI : $uri ，请求的IP地址：$remote_addr&quot;;&#125; set 指令set 指令用于定义变量，其官方语法如下： 123Syntax: set $variable value;Default: —Context: server, location, if 常用例子如下： 12345678910111213http &#123; set hostname xx.test.com; server &#123; location / &#123; &#125; &#125;&#125; 参考链接 https://nginx.org/en/docs/http/ngx_http_rewrite_module.html","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[]},{"title":"Drools 笔记","slug":"Java 知识点/Drools笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Java 知识点/Drools笔记/","link":"","permalink":"http://example.com/wiki/Java%20%E7%9F%A5%E8%AF%86%E7%82%B9/Drools%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、 Drools 简介Drools 是一款基于 Java 的开源规则引擎，规则引擎的核心思想是是将应用程序中的业务决策（if-else）部分分离出来，以规则脚本的形式存编写在文件中，从而达到业务规则与业务代码解耦。当业务规则的变化不需要修改代码，只需要修改业务规则即可。 二、 Drools 术语说明 Rules：表示用于定义的业务规则或 DMN 决策，所有规则必须包含触发规则的条件和规则执行的动作。 Facts： 事实对象，表示规则引擎中输入或者更改的数据对象，即规则判断条件和执行动作时，要使用的数据对象。 ：Drools 引擎中存储规则的地方。 Working memory：Drools 引擎中存储 Facts 事实对象的内存。 Agenda：注册和排序激活规则引擎匹配的规则（如果适用）以准备执行的存放位置。 三 Kie 简介Kie 的全称是 knowledge is everything，即“知识就是一切”的缩写。Kie 是 Jboss 一系列项目的总称，Kie 包含的一系列子项目如下图所示，Drools 只是 Kie 其中的一个子项目而已。 四、Kie APi 介绍4.1 KieModuleKieModule 是 Drools 规则引擎中的一个概念，KieMolde 在宏观上指的是一个标准的 Drools Java Maven 工程，包含 Facts 事实类、规则文件、流程定义、kmodule.xml 文件等其他规则引擎资源，其中 kmodule.xml 文件是必需的，并且目录固定为 resource/META-INF/kmodule.xml， 如下图所示： 同时 KieModule 也是 Drools 规则引擎中非常重要的一个接口，它定义了访问 KieModule 工程的方法，包括获取 KieBase、KieSession 和其他资源等。通过 KieModule 接口，可以方便地管理和使用 KieModule 工程下的资源，提高规则引擎的可维护性和可扩展性。KieModule接口提供了以下功能： 获取 KieBase：KieBase 是 Drools 规则引擎的核心组件之一，它表示规则的集合。KieModule 接口定义了一个 getKieBase() 方法，可以用来获取 KieBase 对象。通过 KieBase，可以加载和执行 KieModule 中定义的所有规则。 获取 KieSession：KieSession 是 Drools 规则引擎中用于执行规则的主要组件之一。KieModule 接口定义了一个getKieSession() 方法，可以用来获取 KieSession 对象。通过 KieSession，可以加载和执行 KieModule 中定义的所有规则。 获取其他资源：KieModule 可能包含其他类型的资源文件，如图像、文本文件和属性文件。KieModule 接口定义了一系列方法，可以用来获取这些资源文件。这些资源文件可以被用来支持规则的执行或提供其他功能。 版本控制：KieModule 接口支持版本控制机制，可以通过接口的方法获取 KieModule 的版本信息。这个版本信息可以用来检测 KieModule 是否有新版本，并且可以用来更新已经存在的 KieModule。 4.2 kieBaseKieBase 是规则引擎的知识库，它包含了规则、流程、函数等各种知识元素，并提供了一种高效的方式来执行规则。每个 KieBase 都与一个或多个 KieSession 相关联，其中包括 stateful 和 stateless KieSession。KieBase 还可以从多种来源创建，例如从规则文件、数据库或Java类中加载规则。 4.3 KieContainerKieContainer 是Drools 中的一个高级组件，它提供了一个应用程序的部署单元。KieContainer 包含一个或多个 KieModule，每个 KieModule 包含一个或多个 KieBase。KieContainer 的主要作用是管理应用程序中的规则库，包括从外部资源（如文件、数据库等）加载规则，并提供一种简单的方式来访问这些规则库。KieContainer 还提供了一些有用的方法，例如从 KieBase 创建 KieSession，从外部资源（如文件、数据库等）加载规则库，以及获取 KieBase 的详细信息。 4.4 KieServiceKieService 接口提供了很多方法，可以通过这些方法访问 Kie 操作和管理的 Drools 资源的接口对象。比如说可以获取 KieContainer，然后利用 KieContainer 来访问 KBase 和 KSession 等信息；可以获取 KieRepository 对象，利用 KieRepository 来管理 KieModule 等。 4.5 KieSessionKieSession 表示的是规则引擎的会话，用于执行规则，和插入事实（insert）、更新事实（update）、删除事实（delete）等，还提供了一些高级特性，如全局变量、动态规则修改、事实监听等，可以增强规则引擎的功能和灵活性。KieSession 的创建是比较消耗资源的操作，因此一般情况下应该尽可能重复利用同一个 KieSession，而不是频繁地创建和销毁。 KieSession 分为有状态和无状态两种模式，它们两种的区别如下： 有状态模式：在有状态模式下，KieSession 会维护一个工作内存（working memory），并根据规则对工作内存中的事实进行推理、更新和删除，并且每次插入、更新、删除事实后，KieSession 都会重新匹配和执行规则，有状态模式的 Session 需要直到显式地销毁，销毁调用方法 kSession.dispose()。 无状态模式：KieSession 会在执行完规则后立即销毁 Session，故每次调用 KieSession 时，它都是一个新的实例，每次调用KieSession时，需要将所有需要的事实重新插入到KieSession中。因此，无状态模式适用于单独的、短暂的推理和查询，长时间持续的会话需要用有状态的 Session，否则会会影响性能。 需要注意的是，在无状态模式下，每次都需要重新加载规则，因为无状态模式执行规则后会立即消耗。而有状态模式则只需要加载一次规则，之后在会话期间都可以使用。 五、KieModule.xml 配置说明5.1 KieBase 标签属性说明 属性名 默认值 合法的值 描述 name none any KieBase 的名称，必须指定一个名称。 includes none 逗号分隔的 KieBase 名称列表 表示引入其他的 KieBase packages all 逗号分隔的字符串列表 定义 KieBases 规则资源的路径，默认情况下将包含 resources 目录下面（子目录）的所有规则文件。也可以指定具体目录下面的规则文件，通过逗号可以包含多个目录下的文件。 default false true, false 表示当前 KieBase 是不是默认的，如果是默认的话，则在 Java 中不需要显示的根据名字指定使用哪个 KieBases equalsBehavior identity identity,equality 设置为identity 时，每次 insert 事实FactHandle faceHandle = kieSession.insert(事实) 都会返回一个新的 FactHandle，如果使用 equality 则会判断是否已经存在相同的事实对象，如果已经存在则返回已经存在的 FactHandle。 eventProcessingMode cloud cloud, stream 当以云模式编译时，KieBase将事件视为正常事实，而在流模式下允许对其进行时间推理。 declarativeAgenda disabled disabled,enabled 该属性是一个高级功能开关，打开后规则将可以控制一些规则的执行与否。 5.2 KieSession 标签属性说明 属性名 默认值 合法的值 描述 name none any 设置 KieSession 的名称，该值必须唯一，且必须设置。 type stateful stateful, stateless 定义 session 的工作状态模式 default false true, false 定义该 session 是否是默认的，非默认的，需要在 Java 代码中根据名称指定才行，注意是每个工作状态模式的 session 都可以定义一个默认值 clockType realtime realtime,pseudo 定义时钟类型，用在事件处理上面，在复合事件处理上会用到，其中realtime表示用的是系统时钟，而pseudo则是用在单元测试时模拟用的。 beliefSystem simple simple,defeasible, jtms 定义KieSession使用的 belief System的类型。 六、Drools 入门例子6.1 导入 Maven 依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie&lt;/groupId&gt; &lt;artifactId&gt;kie-api&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie&lt;/groupId&gt; &lt;artifactId&gt;kie-internal&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-core&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-templates&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-decisiontables&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.drools/drools-core-dynamic --&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-core-dynamic&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.drools&lt;/groupId&gt; &lt;artifactId&gt;drools-compiler&lt;/artifactId&gt; &lt;version&gt;7.73.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13.2&lt;/version&gt;&lt;!-- &lt;scope&gt;test&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 6.2 Drools API 开发步骤123456789101112@startuml:获取 kieServices ;:获取 KieContainer;note right: KieContainer 是线程安全的:获取 KieSession;note right: KieContainer.newStatelessKieSession() 和 KieContainer.newKieSession() 方法是线程不安全的。:Insert Facts;:触发规则 FireRules;:关闭 KieSession;@enduml 6.3 创建事实类123456789101112131415161718192021222324252627282930313233public class User &#123; private String username; private String age; private String mobile; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; public String getMobile() &#123; return mobile; &#125; public void setMobile(String mobile) &#123; this.mobile = mobile; &#125;&#125; 6.4 编写规则文件Drools 规则引擎默认递归查找当前 Maven 工程 resource 目录和 Jar 中 resource 目录的所有规则文件，加载到 Production Memory（规则库）中，Drools 是以逻辑 package 去组织规则的，跟规则文件名和存放路径无关，故可以任意命名。 12345678910111213141516171819202122// 定义规则的包名，逻辑上的包名，与规则路径无关联，包名是规则的命名空间，不同规则的文件可以使用相同的包，但是在同一个包即命名空间下，rule 的名称不能相同的package com.github.drools.rulesimport com.github.drools.model.Userrule &quot;rule1&quot; no-loop truewhen // 匹配工作内存中的 username 等于 admin 的 User 事实对象，只要存在一个就返回 true，比匹配到的时候对象赋值给 u1 u1: User(username==&quot;admin&quot;)then // 但 when 条件为真时，执行 then 语句 System.out.println(&quot;execute rule1, I am &quot; + u1.getUsername());endrule &quot;rule2&quot;when u2: User(username==&quot;dev&quot;)then System.out.println(&quot;execute rule2，I am &quot; + u2.getUsername());end 6.5 编写 kiemodule.xml 文件在 Maven 工程中创建文件 resource/META-INF/kiemodule.xml 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;kmodule xmlns=&quot;http://www.drools.org/xsd/kmodule&quot;&gt; &lt;!-- 指定规则的逻辑包，会将不同规则文件但包相同的规则都整合加到 kbase 中 --&gt; &lt;kbase packages=&quot;com.github.drools&quot;&gt; &lt;!-- 指定能操作和执行该逻辑包规则的 Session --&gt; &lt;ksession default=&quot;true&quot; name=&quot;session01&quot; type=&quot;stateful&quot;/&gt; &lt;/kbase&gt; &lt;kbase packages=&quot;com.github.drools&quot;&gt; &lt;ksession name=&quot;session02&quot; type=&quot;stateless&quot;/&gt; &lt;/kbase&gt;&lt;/kmodule&gt; 6.6 规则测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.github.drools.model.User;import org.junit.Test;import org.kie.api.KieServices;import org.kie.api.runtime.KieContainer;import org.kie.api.runtime.KieSession;import org.kie.api.runtime.StatelessKieSession;public class DroolsTest &#123; @Test public void testStateless() &#123; KieServices kieServices = KieServices.Factory.get(); KieContainer kieClasspathContainer = kieServices.getKieClasspathContainer(); // 获取默认有状态的 Session KieSession session1 = kieClasspathContainer.newKieSession(); User adminUser = new User(); adminUser.setUsername(&quot;admin&quot;); // 插入事实对象，存在规则引擎的工作内存中 session1.insert(adminUser); // 每一次 insert 都会重新从头开始匹配规则包中的所有规则，如果 insert 的是相同的 Fact 事实对象，则不会。 User devUser = new User(); devUser.setUsername(&quot;admin&quot;); session1.insert(devUser); // 执行规则 session1.fireAllRules(); // 有状态session 需要手动销毁 session1.dispose(); // 获取默认的无状态 Session StatelessKieSession session2 = kieClasspathContainer.newStatelessKieSession(); /* * 无状态 session，不会维护工作内存，每次执行规则时， * 都需要将所有需要的事实重新插入到 KieSession 中，且插入和执行规则的方法跟有状态的不相同 */ user.setUsername(&quot;dev&quot;); session2.execute(user); user.setUsername(&quot;admin&quot;); session2.execute(user); &#125;&#125; 七、语法格式规则123456789101112131415161718192021222324252627282930313233//定义规则包，注意只是逻辑上的包，实际上并不要求规则文件存放路径跟包路径一样，在不同的规则文件中包是可以相同的，包是规则的命名空间，在同一个包即一个命名空间下 rule 的名字不能重复package com.rule// 导入需要引用的 Java Class import // Optional// 函数定义，可以在 then 中执行function // Optional// 定义一个查询 Fact 过滤条件，然后在Java 程序代码中通过 ksession.getQueryResults(&quot;name&quot;) 获取 Fact 对象，name 就是 query 的名字query // Optional// 在规则中定义对象类型，即 Class、枚举类等，一般不常用，基本的 Fact 都是在程序代码中定义的declare // Optional// 定义规则的全局变量，该规则文件下的所有 rule 中都可以引用global // Optional// 定义规则的名字，在包下必须唯一rule &quot;rule name&quot; // Attributes，定义规则的属性 when // Conditions 定义规则执行的条件 then // Actions 定义规则要执行的动作endrule &quot;rule2 name&quot; when then end 7.1 function 语法12345678910function String hello(String applicantName) &#123; return &quot;Hello &quot; + applicantName + &quot;!&quot;;&#125;rule &quot;Using a function&quot; when // Empty then System.out.println( hello( &quot;James&quot; ) );end 7.2 query 语法query 用于在规则中定义 Fact 查询过滤语句，然后在 Java 代码中通过ksession.getQueryResults(&quot;name&quot;) 方式引用。 规则查询语句定义如下：1234567891011package com.rulesquery &quot;people under the age of 21&quot; $person : Person( age &lt; 21 )endrule &quot;rule name1&quot; when then end Java 代码中引用方式如下：123456789QueryResults results = ksession.getQueryResults( &quot;people under the age of 21&quot; );System.out.println( &quot;we have &quot; + results.size() + &quot; people under the age of 21&quot; );System.out.println( &quot;These people are under the age of 21:&quot; );for ( QueryResultsRow row : results ) &#123; Person person = ( Person ) row.get( &quot;person&quot; ); System.out.println( person.getName() + &quot;\\n&quot; );&#125; 7.3 declare 语句declare 语句用于在规则文件中定义类型，如下定义一个 Person 类对象： 123456789101112131415161718192021package com.rulesimport java.util.Date;// 定义一个 Person 对象declare Person name : String dateOfBirth : Date address : Addressendrule &quot;Using a declared type&quot; when // 判断规则引擎工作内存中，是否有 name == &quot;James&quot; 的 Person 对象，并将该对象，赋值给 $p $p : Person( name == &quot;James&quot; ) then Person mark = new Person(); mark.setName( &quot;Mark&quot; ); insert( mark );end 7.4 Global 语句Global 用于定义规则文件中的全局变量，在同一个规则文件中，所有的 rule 中都能引用到，使用列子如下： 先在 Java 代码中定义规则的全局变量 123List&lt;String&gt; list = new ArrayList&lt;&gt;();KieSession kieSession = kiebase.newKieSession();kieSession.setGlobal( &quot;myGlobalList&quot;, list ); 然后在规则文件中定义全局变量 12345678global java.util.List myGlobalList;rule &quot;Using a global&quot; when // Empty then myGlobalList.add( &quot;My global list&quot; );end 7.5 Rule attributes 语句规则属性，可以限制和修改规则的行为属性，具体可以查看官网 Rule attributes 介绍，Drools 支持的规则属性如下： Attribute Value salience 值为整数，用于定义规则的优先级，值的越大优先级越高 enabled 值为布尔类型 true 或者 false, 表示是否启用规则 date-effective 值为日期，用于指定规则生效时间，表示当前日期大于设置的日期后，规则才生效 例子：date-effective “4-Sep-2018” date-expires 值为日期，用于指定规则失效时间 例子：date-expires “4-Oct-2018” no-loop 值为布尔类型，防止规则重复执行，特定的环境下规则会重复执行，如在 then 中使用 insert、update 语句时，所有的规则都是会重复执行 例子：no-loop true activation-group 值为字符串，指定规则的激活分组名，同一个分组的规则只能执行一个，默认按顺序执行第一个，可以通过 salience 设置最高优先级的执行 activation-group “group name01” agenda-group 值为字符串，指定规则的议程分组名称，跟 activation-group 的区别时是，需要获取焦点后才能执行，可以执行多个，需要在 Java 代码中设置焦点或者使用 auto-focus 属性设置焦点 例子：agenda-group “GroupName” auto-focus 值为布尔类型，自动为 agenda-group 设置焦点 例子：auto-focus true timer 值为间隔的整形时间或者 corn 表达式，通过定时器指定规则的执行时间例子1：timer(10s 2s) 表示10秒后触发，然后每隔2s重新触发例子2： timer (cron:* 0&#x2F;15 * * * ? ) 表示每15分钟执行一次 calendar 通过日历来定时执行规则，可以排除节假日例子：calendars “* * 0-7,18-23 ? * *” ruleflow-group 值为字符串，用于标识规则为流程组。在规则流组中，规则只有在该组被相关的规则流激活时才能启动例子：ruleflow-group “GroupName” dialect 值为 JAVA or MVEL，用于指定当前规则使用的语言类型，默认是 JAVA例子：dialect “JAVA” 规则属性的用法如下： 123456789101112package com.rulesrule &quot;rule_name&quot; // Attribute salience 10 // 设置规则的优先级 enabled true // 表示是否启用规则 when // Conditions then // Actionsend 7.6 when 语句when 语句用于判断条件是否满足，条件满足时，就会执行 then 动作语句，注意当 when 语句的条件为空时，等于同于 eval(true) 表示条件为真，会执行 then 动作语句。when 语句官网参考 3.6.1 条件为空的规则 12345678910111213141516rule &quot;Always insert applicant&quot; when // Empty ，空条件时，规则引擎会默认添加 eval(true), 所以空条件，默认为真 then insert( new Applicant() );end// 空条件的规则，规则引擎会在内部默认将其改写如下:rule &quot;Always insert applicant&quot; when eval( true ) then insert( new Applicant() );end 3.6.2 事实对象模式约束 12345678910111213141516171819rule &quot;rule1&quot;when // 表示匹配到任意一个事实对象，就返回真 Object() then end when // 匹配到任意一个 Person 事实对象，就返回真 Person() then end when // 匹配任意一个 username = &quot;admin&quot; 的 Person 事实对象，就返回真 Person(username=&quot;admin&quot;)then end 7.7 Drools 内置方法Drools 规则语法中也提供了插入、删除、更新工作内存 Fact 事实数据的内置方法，来方便在规则中控制规则引擎的执行。通过内置方法操作 Fact 事实数据后，规则引擎会把同一个包下的相关规则重新匹配执行。 update 方法update 内置方法的作用是更新工作内存中的 Fact 事实对象，并让规则引擎重新匹配同一个包下的其他相关规则。如下例子，第一个文件的规则触发后，使用 update 内置方法后，会连锁把第二个文件的所以也触发了。 规则文件 user1.drl 1234567891011121314package com.github.drools.rulesimport com.github.drools.model.Userrule &quot;username eq admin&quot; when u1: User(username==&quot;admin&quot;) then System.out.println(&quot;用户名为 admin 触发了规则&quot;); u1.setAge(19); //update 方法更新 Fact 事实对象后，把同一个包下的除本条规则外的所有规则重新匹配执行一次。 update(u1);end 规则文件 user2.drl 1234567891011121314151617181920package com.github.drools.rulesimport com.github.drools.model.Userrule &quot;age lt 20 rule&quot; when u1: User(age &lt; 20) then System.out.println( u1.getUsername()+&quot;用户的年龄大于20岁，触发规则&quot;); u1.setAge(25); update(u1);endrule &quot;age ge 20 rule&quot; when u1: User(age &gt;= 20) then System.out.println( u1.getUsername()+&quot;用户的年龄大于20岁，触发规则&quot;);end insert 方法insert 内置方法的作用是在工作内存中插入 Fact 事实对象，并让规则引擎重新匹配执行包下所有规则， 如以下列子，在第一个规则触发后，在 insert 新的事实对象后，重新匹配规则，则第二个规则就会执行。注意要插入的是新的 Fact 事实对象实例，如果是工作内存中已存在的事实对象重复插入，不会重新匹配执行规则。 123456789101112131415161718192021222324package com.github.drools.rulesimport com.github.drools.model.Userrule &quot;rule1&quot; // 限制本条规则，只能匹配一次，不管是在 Java 中还是在规则文件只要调用 insert 事实对象，都是从头开始执行所有规则，当多次 insert 不同的事实实例对象时，如果 when 条件都满足会重复执行，故而需要该属性来限制只能执行一次。 no-loop true when u1: User(username==&quot;admin&quot;) then System.out.println(&quot;用户名为 admin 触发了规则&quot;); User user = new User(); // 如果将用名字设置为 admin 的话，该 rule1 规则会死循环执行，当出现这种情况时，需要通过规则属性 no-loop 限制规则不能重复执行。 user.setUsername(&quot;dev&quot;); // insert 事实对象后，会重新匹配执行包的所有规则（包含本条规则在内） insert(user);endrule &quot;rule2&quot; when u2: User(username==&quot;dev&quot;) then System.out.println(&quot;用户名为 dev 触发了规则&quot;); end retract 方法retract 内置方法的作用是删除工作内存中的 Fact 事实对象，并让规则引擎重新匹配执行规则。 1234567891011121314151617181920212223package com.github.drools.rulesimport com.github.drools.model.Userrule &quot;rule1&quot; // 设置规则优先级，值越大优先级越高 salience 10 when u1:User(age == 20) then System.out.println( u1.getUsername()+&quot;用户的年龄等于20岁，触发规则&quot;); // 删除 u1 事实对象，规则引擎会重新匹配规则，则 rule2 规则将不会执行。 retract(u2);end rule &quot;rule2&quot; salience 9 when u1:User(age &gt;= 20) then System.out.println( u1.getUsername()+&quot;用户的年龄大于等于20岁，触发规则&quot;);end 参考连接 https://docs.drools.org/7.73.0.Final/drools-docs/html_single/index.html#_droolslanguagereferencechapter","categories":[{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"}],"tags":[]},{"title":"K8s 入门学习笔记","slug":"Kubernetes/K8s 入门学习笔记","date":"2023-05-31T13:39:26.110Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Kubernetes/K8s 入门学习笔记/","link":"","permalink":"http://example.com/wiki/Kubernetes/K8s%20%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1. 介绍Kubernetes 的简称 K8s，Kubernetes 是 Google 开源的容器编排工具。kubernetes 的本质是一组服务器集群，集群的每个节点上运行特定的程序组件，通过组件去实现资源管理的自动化。 2. K8s 组件一个 K8s 集群主要是由控制节点（Master node）、工作节点（Work node）构成，每个节点上都会安装不同的组件, 如下图所所示(图片来源于网络)： 2.1 Master 节点Mater 节点负载整个集群的管理和和控制、以及负责集群的决策。 组件 作用 apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制 controller-manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 etcd 保存了整个集群的状态（集群中各种资源对象的信息） 2.2 Node 节点Node 真正运行工作负载的节点，通过 kube-proxy 管理应用服务的访问入口，包括集群内 pod 到 service 的访问，以及集群外访问 service。 组件 作用 Kubelet 负责维护容器的生命周期，即通过控制 docker、来创建、更新、销毁容器 Kube-Proxy 负责提供 Node 节点应用集群的服务发现和负载均衡，Internet(或者用户)访问应用前必须经过 Kube-Proxy docker 负责镜像管理以及Pod和提供容器的真正运行接口(CRI) , CRI 是一个接口，用来操作容器的接口。k8s通过CRI对容器进行操作，创建、启停容器等 2.3 kubectlkubectl 是与 kubernetes 集群交互的一个命令行工具，kubectl 通过与 kubernets api server 提供 Rest API 来操作控制 K8s 集群，类似于 docker 中的 docker 命令。kubectl 在执行命令的时候可以加上一个 -v&#x3D;9 参数（注意参数值越大日志越详细）查看执行的具体步骤： 读取 kubectl 的配置文件，判断需要与哪个 api server 交互 生成 request body 调用 API 输出结果 2.3.1 kubectl 的语法kubectl 的命令行语法格式 kubectl [command] [resource-type] [name] [flags] command 指定对资源执行的操作，如：create、apply、get、describe、delete 等 resource-type 指定要操作的资源类型，使用资源的单数或者复数、简写都可以，如 pods 或 pod 或 po, nodes 或 node 或 no, 等等 name 根据名称指定要操作的具体资源 flags 3. K8s resouce(资源)的理解K8s 组件是支持 K8s 平台运行的软件，是系统运行的进程，资源是通过组件去创建和管理的。跟 Linux 中一切皆文件, 在 K8S 中也有一切皆资源的概念。Resource 是 K8s 的一个基础概念，k8s 用 Resource 来表示集群中的各个资源。d都可以在资源文件中配置。比如 Pod、Service、Deployment、namespace 等等都属于 K8s 的资源，尽管这个资源看起来差别很大，但它们都有许多共同的属性，如 name(名称)、kind(类型)、apiVersion(api版本)、metadata(元信息等)。 3.1 查看 resource(资源)的命令1kubectl api-resource 3.2 resource(资源)文件定义k8s 资源支持定义的属性很多，定义资源文件时，未定义的属性 k8s 会设置有默认值，k8s 支持通过 YAML 和 JSON 格式文件定义资源对象，使用命令 kebectl explain [ resource | resource.attribe ] 资源能定义哪些属性，使用 YAML 定义资源的格式如下： 123456789101112131415161718192021222324# 指定资源的版本，命令 kubectl explain resource 可以查看资源使用的版本，如查看 pod 资源的版本，运行命令： kubectl explain podapiVersion: v1 # 指定资源的类型，pod、namespace, service 等等kind: pod# metadata 可以定义的资源的名称等，可以使用命令 kubectl explain resource.metadata 查看支持哪些属性的定义 metadata: # 指定资源的名称 name: test-nginx # 指定资源的命名空间，指定的话，默认是 default namespace: default # 指定资源的版本 resourceVersion: &quot;11012&quot;# 定义资源的特定属性spec: # 使用命令 kubectl explain resource. containers: # 指定容器的名称 - name: nginx-container # 指定容器运行的镜像 image: nginx ports: # hostport(主机端口) 和 containerPort(容器端口) 相当于 docker run -p 指定的端口 - containerPort: 80 hostport: 80 快速生成资源文件 123456# 不存在的资源，需要指定 --dry-run 表示不是正在的创建资源，只是试运行，为了导出资源文件 kubectl create deployment web --image=nginx-o yaml --dry-run# 或者kubectl run Pod test-nginx --image=nginx --dry-run=client -o yaml# 根据存在的资源导出资源文件kubectl get pods [pod-name] -o yaml 3.3 资源的命名空间命名空间为集群中的资源名称赋予作用域，主要作用是资源名称隔离，在命名空间中资源名称必须是唯一的，但是并不是所有的资源都使用命名空间隔离的名称，具体可以使用命令 kubectl api-resource 查看。创建命名空间使用以下命令： 123456789# 第一种方式创建命名空间，查看创建日志，在命令后面加参数 -v = 9 其中 9 表示日志的级别，一般数字越大信息越详细kubectl create [ns | namespaces] 空间名称 # 第二种方式，第一中方式其实时第二种方式的简化处理kubectl create -f /xx/xx/xx.yaml# 查看命名空间信息，可选参数 -o 指定查看信息的详细程度和输出格式kubectl get [ns | namespaces] 空间名称 -o [wide | ymal | json ] # 删除命名空间kubectl delete [ns | namespaces] 空间名称 3.4 操作 resouce(资源)的常用命令需要命名空间隔离的资源，使用 kubectl 操作时，都是需要指定命名空间的，如果不指定命名空间，则默认操作的是 default 命名空间下的资源。使用命令 kubectl api-resources 查看哪些资源是需要命名空间隔离的。 kubectl create 命令，用于创建 k8s 资源，常用可选参数： f 指定创建资源使用的资源文件或者流12# 注意需要命名空间隔离的资源，如果没有指定命名空间的会默认将资源创建在 default 命令空间中kubectl create -f resource-file.yaml 或 resource-file.josn 或 http://xxx/xx/xx.yaml kubectl apply 命令，用于更新资源，不存在则创建新的资源，常用的可选参数 -f 指定创建资源使用的资源文件或者文件流 -k 指定使用某个目录下的 kustomization.yaml 文件创建或者更新资源 –record 将当前执行的命令，记录在资源的annotation(注释)中，记录的格式为 kubernetes.io/change-cause: &lt;kubectl 执行的命令&gt; 123456# 根据指定的资源文件更新或者创建资源kubectl apply -f resource-file.yml 或 resouce-file.json 或 https://xxx/xxx/resource-file.yml# 根据资源文件的标准输入流创建或者更新资源cat resource-file.yml | kubectl apply -f - # 指定读取目录下的资源文件kubectl apply -k /home/resource-dir kubectl get 命令查看资源信息，常用参数 -A 指定查看全部命名空间的资源 -n 指定查看某个命名空间的资源，如 -n kube-system –show-lables 查看资源的 label -w, –watch&#x3D;&lt;true|false&gt; 实时显示资源信息，相当于 tail 中的 -f -o, –output 指定结果的输出格式，常用的可选值有 wide、yaml、json、name(只显示名称) 等等注意查看资源时，如果时需要命名空间隔离的资源，需要 -n 参数指定命名空间或者 -A 指定查看全部命名空间的资源，如果指定命名空间，默认查看的是 default 命名空间的资源，可以使用命令 kubectl api-resources 查看资源是否需要命名空间隔离。123456789101112# 查看 k8s 的所有 node 节点kubectl get nodes # 根据名字查看某个 node 节点kubectl get node [node-name] # 查看 pod 资源kubectl get pods # 不指定命名空间，查看的 default 命名空间的所有 pod # 查看所有命名空间下的所有 podkubectl get pods -A# 查看某个命名空间的所有 podkubectl get pods kube-system# 根据名称查看某个 pod kubectl get pod [pod-name] -o wide | yaml | josn kubectl describe 命令展示资源详情信息1234# 查看 Pod 的详情信息和 Pod 容器事件 Eventskubectl describe pod [pod-name] [-n 命名空间]# 查看 node 节点的详细信息和节点的内存和 cpu 信息，以及 Pod 限制 cpu 和内存信息kubectl describe node [node-name] kubectl label 命令，用于新增、更新、删除资源标签，资源的每个标签都是 key=value 的形式，注意在 yaml 中定义资源的标签时，使用的是key : value 形式命令的语法格式 kubectl lable &lt;resource-type : resource-file &gt; &lt;resouece-name&gt;... &lt;key=label&gt;... [--resource-version=version] 其中 … 表示可以指定多个然后用空格隔开 12345678910111213141516171819# 查看 node 节点标签kubectl get nodes --show-labels# 给名为 k8s-node01 的 node 节点打上 hello=world 标签kubectl label node k8s-node hello=world# --overwrite 表示打标签时，如果存在标签 key 相同的标签，则覆盖更新标签kubectl label node k8s-node --overwrite hello=node-world# 给所有node 节点都打上 test-k8s-node = true 标签kubectl label node --all test-k8s-node = true # 给名为 k8s-node01 和 k8s-node02 的节点都打上 hello=world 和 whoiam=node 标签kubectl label node k8s-node01 k8s-node02 hello=world whoiam=node# 删除资源的标签，使用 key和减号，如删除所有节点中标签 key 等于 hello 的标签kubectl lable node --all hello- # 查看 pods 的标签kubectl get pods --show--label# 为名 test-web 的 pod 打上 nginx-pod=true 标签kubectl lable pods test-web nginx-pod=true# 根据文件资源文件中定义的 kind、metadata.namespace、metadata.name 找到对应的 pod 打上 hello=world 标签kubectl label pod -f xxx.yaml hello=world kubectl exec 命令，在宿主机执行 Pod 中容器的命令，跟 docker exec 类似命令语法格式： kubectl exec &lt;pod-name&gt; [-n 命名空间] [ -c Pod 中容器名称 ] [ -it ] -- &lt;container-command&gt; -n 指定命名空间，不指定的话，默认是 default 命名空间下的 Pod pod-name 指定 Pod 的名称 -c 指定运行 Pod 中的哪个容器的命令，如果不指定默认随机运行一个 container-command 指定容器要运行的命令，如 bash、ls、cat、date 等等想要运行的命令 12# 进入 default 命名空间下 test-web 内的 web01 容器中kubectl exec test-web -c web01 -it -- /bin/sh 4. PodPod 是 k8s 的最小调度单位，Pod 包含一个或多个 Container(容器) ，K8s 创建 Pod 时，Pod 内容器默认使用的 Container 网络模式，所以在运行 Pod 中定义的容器之前，会先默认创建运行一个 init 容器，其他容器使用 init 容器的网络命名空间, 从而实现 Pod 内容器共享网络。即 Pod 内容器使用 localhost 就可以相互访问。注意 init 容器也是可以在资源文件中自定义，具体可以查看官方文档。kubernetes 本身的组件也可以通过容器化的方式运行在集群中，并且都存在于 kube-system 命名空间下。注意 k8s 支持通过资源文件或者运行 kubectl run 创建 Pod。 4.1 定义 Pod 资源文件使用kubectl explain pod 查看 pod 资源可以定义的属性和支持的版本 12345678910111213141516171819apiVersion: v1# 注意要大写kind: Pod metadata: name: test-webspec: # 定义 Pod 中的容器，可以多个 containers: # 指定容器的名称, 注意 docker ps 查看容器的时候，看到的名字实际为： k8s_&lt;pod容器名&gt;_&lt;pod名&gt;_&lt;命名空间&gt;_&lt;uid&gt;_&lt;Priority&gt; - name: web01 # 指定容器运行的镜像 image: nginx # 指定镜像拉取的策略，可选值分别为，Always(总是从远程仓库拉取)、IfNotPresent(本地没有镜像时，才会从远程仓库拉取)、Never(只使用本地镜像，没有就报错) 默认是 IfNotPresent imagePullPolicy: IfNotPresent ports: # 容器 expose 的端口，在集群集群内，可以使用 Pod 分配的 ip 访问 - containerPort: 80 # 宿主机的端口，相当于 docker run -p 8000:80，可以使用 Pod 所在节点的 Ip 访问 hostPort: 8000 4.2 操作 Pod 的常用命令 创建和更新 pod1234# 创建 pod，注意如果 yaml 文件或者不使用 -n 指定命名空间，则 pod 会创建在默认 default 命名空间下，是使用命令 kubectl explain pod.metadata 可以查看kubectl create pod -f xxx.yaml# 创建或者更新 pod kubectl apply pod -f xxx.yaml 删除 pod1234# 根据名称删除 pod，如果不指定命名空间，则删除 default 命名空间下的 pod kubectl delete pod [pod-name] [-n 命名空间]# 根据资源文件中的 kind、metadata.namespace、metadata.name 确定要删除的资源kubectl delete -f xxx.yaml 查看 pod第一种方式：使用 kubectl get pod [pod-name] [-o wide | yaml | json ] [-n 命名空间 | -A ]123456# 不指定命名空间，默认查看 default 命名空间下的 podskubectl get pod -o wide # 查看所有命名空间的 podskubectl get pod -A # 根据名字查看指定的 pod 不指定命名空间，默认查看 default 命名空间的 pod kubectl get pod [pod-name] 第二种方式：kubectl describe pod [po-name] [-n 命名空间 | -A]，使用第二种方式，可以查看 pod 详细信息和 events 事件1234# 查看 default 命名空间的下的所有 podkubectl describe pod # 根据名称查看 pod 信息，注意如果不指定命名空间，则默认查看 default 命名空间下的 pod kubectl describe pod [pod-name] pod 端口映射到宿主机端口命令格式 kubectl port-forward [pod-name] [hostPort:containerPort], 注意要 pod 所在的 node 节点运行才行12# 将 pod 端口映射到宿主机的端口, 注意 ip 地址要执行命令运行节点的才行kubectl port-forward test-web --address localhost,192.168.204.3 3000:80 进入 Pod 内的容器123kubectl exec test-web -n default -c web01 -it -- bash# 查看环境变量kubectl exec test-web -n default -c web01 env 查看 Pod 内的容器日志1kubectl logs test-web -n default -c web01 -f --tail=200 kubectl run 命令创建 Pod命令语法格式: kubectl run &lt;pod-name&gt; --image=image [--dry-run=server|client] 具体查看帮助文档12# 通过 --dry-run 参数，指定显示 Pod 的创建资源文件信息，不实际运行 Podkubectl run test-web --image=nginx --dry-run=client -o yaml 4.3 Pod 容器数据持久化，即容器挂载目录到宿主机，防止数据丢失第一种方式：通过 volumes 和 volumeMounts 定义挂载的目录，如下 123456789101112131415161718192021222324apiVersion: v1kind: Pod metadata: name: test-webspec: # 指定将 Pod 资源创建在标签为 hello=world 的 node 主机节点中，注意如果多个 node 节点都存在 hello=world 标签, k8s 会调度选定一个节点， # 如果固定选择某个 node 节点，需要标签唯一 nodeSelector: #注意在，在 yaml 中定义或者使用 label 时用 : 代替 = hello: world volumes: - name: nginx-data hostPath: # 定义挂载的宿主机目录 # 注意该目录是 node 节点主机的目录，Pod 创建时调度到不确定的节点，最好使用 nfs、ceph、glusterfs 文件共享存储目录, # 或者通过 nodeSelector 指定 pod 部署的节点，才能保证，Pod 删除后重新创建时，挂载目录还是固定的主机目录 path: /opt/data # 指向一个目录，不存在时自动创建 type: DirectoryOrCreate containers: - name: test-nginx # 容器名字 image: nginx # 镜像 volumeMounts: - name: nginx-data # 注意 name 要跟上面 hostPath 的名字一样，因为是根据名字取匹配的 mountPath: /usr/share/nginx/html # 指定容器的挂载目录 4.4 Pod 重启策略Pod 重启策略(RestartPolicy)，定义容器的重启规则，当 Pod 内某个容器异常退出或者探针健康检测失败时，kubelet 会根据重启策略(RestartPolicy)来进行相应的操作。Pod 的重启策略有三种分别是 Always、OnFailure、Never，默认值是 Always。 Always 当容器进程退出时，kubelet 总是会自动重启容器 OnFailure 当容器终止运行且退出码不为0时，kubelet 会自动重启容器 Never 当前容器运行状态如何，kubelet 都不会自动启动容器 12345678910111213141516apiVersion: v1kind: Pod metadata: name: test-web namespace: defaultspec: restartPolicy: OnFailure containers: - name: busybox image: busybox # 命令正常执行成功返回的 0，设置退出码为 1 测试 OnFailure 重启策略 args: - /bin/sh - c - sleep 10 &amp;&amp; exit 1 4.5 容器 Probe(探针)probe(探针) 是由 kubelet 对容器定期执行的健康诊断。 诊断的方式是 kubelet 在容器内执行代码，或者发送一个网络请求。如果没有在资源文件中定义 prode 则 kubelet 会默认所有的诊断结果都是健康的。 4.5.1 探针检测的方式 exec 在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。 gRPC 如果容器中实现 gRPC健康检查，可以使用 gRPC 执行一个远程过程调用。如果响应的状态是 SERVING，则认为诊断成功。 httpGet 对容器服务发起 HTTP GET 请求。如果响应的状态码大于等于 200 且小于 400，则任务诊断成功。 tcpSocket 对容器的指定端口执行 TCP 检查。如果端口打开，则诊断被认为成功 4.5.2 探测结果每次探测都将获得以下三种结果之一： Success（成功） 容器通过了诊断。 Failure（失败）容器未通过诊断。 Unknown（未知） 诊断失败，不会采取任何行动。 4.5.3 探针的类型k8s 提供了三种容器探针，分别如下： startupProbe 启动探针，用于诊断容器中的服务是否已经启动成功，如果探针检测返回失败结果，则 kubelet 会杀死容器，并且根据容器重启策略(RestartPolicy)决定是否重启。注意该探针如果诊断成功之前不会运行 livenessProbe 和 readinessProbe 探针，未资源文件中配置 startupProbe 探针，则 kubelet 默认是诊断成功的。 livenessProbe 存活探针，用于诊断容器是否已经挂掉了，如果探针检测返回失败结果，则 kubelet 会杀死容器，并且根据容器重启策略(RestartPolicy)决定是否重启。 readinessProbe 就绪(READY)探针，用于诊断容器中的服务是否能正常接收请求，如果探针检测返回失败结果，Endpoint 控制器将 Pod 从 Endpoint 对应的服务中移除，不会将任何请求发送该 Pod 上，直到探针检测返回成功结果为止。 livenessProbe 存活探针例子，使用 kubectl describe pod &lt;pod-name&gt;命令查看检测是否成功，如果失败会有事件提示。12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: test-webspec: containers: - name: web01 image: nginx ports: - containerPort: 80 livenessProbe: # kubectl 每3秒请求一次 /index 如果请求返回的状态码范围是 200 &lt;= statuCode &lt; 400 说检测成功 httpGet: path: /index port: 80 initialDelaySeconds: 5 # 表示容器运行5秒后，kubelet 开始检测 periodSeconds: 3 # 表示每隔 3 秒 kubelet 检测一次 successThreshold: 3 # 表示3次检测成功才算是检测成功，主要防止出现误差，默认值是 1 failureThreshold: 3 # 表示3次检测失败才算是检测失败，主要防止出现误差，默认值是 1 4.6 Pod 容器资源限制Pod 内容器运行依赖的硬件资源，最重要的指标就是 cpu 和内存，k8s 提供 requests 和 limits 两种参数类型来分配和限制容器使用的资源。它们的区别如下： requests 限制的资源只是作为 k8s 创建 Pod 时调度到指定节点的判断依据，不限制容器运行资源，只有主机节点的可分配资源大于等于 requests 限制的资源时，才允许 Pod 调度到此节点。 limits 限制 Pod 内容器能使用的最大资源，如果容器使用的内存超出设置值，则会报 OOM。如果内存和 cpu 的值都设置为 0 则 表示资源不作限制。12345678910111213...sepc: containers: - name: web01 image: nginx resource: # 使用命令 kubectl describe node [node-name] 能查看主机节点的内存和 cpu requests: memory: 200Mi cpu: 50m limits: memory: 500Mi cpu: 100m 4.7 Pod 状态和生命周期4.7.1 生命周期123456789101112131415161718gantt title Pod 生命周期 dateFormat ss axisFormat %Ss pod start : milestone, s1, 00, 0s section Init Container # 内容，颜色、标签、起始点， init Container-01 : i1, 00, 3s init Container-02 : i1, 01, 3s init Container-03 : i1, 02, 3s section Main Container post start hook: m1, 05, 2s main container: m1, 05, 6s livenessProbe: m1, 07, 2s readinessProbe: m1, 07, 2s pre stop hook: m1, 09, 2s section pod stop : milestone, crit, s1, 11, 0s Pod 资源对象从创建到结束的时间段称为 Pod 的生命周期，Pod 周期过程和钩子函数说明如下： Pod 创建过程 运行初始化容器(init container)过程 运行主容器(main container)过程 容器启动后执行的钩子函数（post start），容器终止前执行的钩子函数（ pre stop） 容器的存活性探测(liveness probe)、就绪性探测(readiness probe) Pod 终止过程 执行删除命令，k8s 给需要删除的 Pod 发出 SIGTERM 信号，Pod 状态变为 Terminating kube-proxy watch 监控到 Pod 的状态不是 READY 状态，将 Pod 从 service 的 endpoint 列表中摘除掉，新的流量不再转发到该 Pod kubelet watch 监控到 Terminating 状态，则开始销毁 Pod，如果 Pod 中的容器配置了 preStop Hook 将会执行，发送 SIGTERM 信号给容器内主进程以通知容器进程开始停止，并等待 container 中的主进程完全停止，如果在 terminationGracePeriodSeconds 内 (默认 30s) 还未完全停止，就发送 SIGKILL 信号将其强制杀死，所有容器进程终止，清理 Pod 资源，完成 Pod 删除 4.7.2 Pod 状态和容器状态 Pod 生命周期中各种状态说明 Pending（等待中） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间。 Running（运行中） Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。 Succeeded（成功） Pod 中的所有容器都已成功终止，并且不会再重启。 Failed（失败） Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。 Unknown（未知） 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。 Pod 内容器生命周期状态 Waiting （等待） 容器运行前的等待状态，如拉取容器镜像，或者向容器应用 Secret 数据等等。 Running（运行中） 表明容器正在执行状态并且没有问题发生。 Terminated（已终止） 容器已经开始执行并且或者正常结束或者因为某些原因失败。 4.8 静态 Pod静态 Pod 指的是 kubelet 自动创建的 Pod，不需要我们使用kubectl &lt;create|apply&gt;手动创建。静态 Pod 的 yaml 是存放在 /etc/kubernetes/manifests/ 中的，kubectl 会自动扫描该目录的 yaml 文件并自动创建，创建的 Pod 即为静态 Pod。如果我们想创建静态 Pod 直接将 yaml 放到该目录即可，kubectl 会自动创建。 5. ConfigMap 和 Secretk8s 提供 ConfigMap 和 Secret 两种不同类型的资源，来实现业务配置信息的统一管理。在静态 Pod 中无法使用配置资源。 ConfigMap 用于管理不敏感的配置项。ConfigMap 资源的定义如下：12345678910111213141516171819202122232425262728293031apiVersion: v1kind: ConfigMapmetadata: name: test-web-config # 不指定命名空间的话，资源默认在 default 命名空间下 namespace: default# 定义配置项，注意如果 Pod 是以挂载文件的方式引用 configMap 则 data 中的每 key-value 键值对都会单独生成一个文件，key 作为文件名，vlaue 作为文件内容 data: # 简单键值对配置项，注意值要加引号，不然会报错 redis_host: &quot;127.0.0.1&quot; redis_port: &quot;6739&quot; # 类似文件的配置项 # | 在 yaml 中表示每一行都保留换行符号 \\n game.properties: | enemy.types=aliens,monsters player.maximum-lives=5 user-interface.properties: | color.good=purple color.bad=yellow allow.textmode=true test-web.conf: | server &#123; listen 81; listen [::]:81; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; &#125; Secret 用于管理中的配置信息，如账号密码，等等敏感配置信息。Secret 资源的定义如下：1234567891011121314apiVersion: v1kind: Secretmetadata: name: test-web-secret # 不指定命名空间的话，资源默认在 default 命名空间下 namespace: default # type 指定 data 能定义哪些配置项，Opaque 表示用户可以定义的任意数据，当类型为 kubernetes.io/service-account-token 时 data 中只能配置 k8s 服务账号令牌# 具体查看： https://kubernetes.io/zh-cn/docs/concepts/configuration/secret/#secret-typestype: Opaque# 定义应用使用的配置项data: # 与configMap的区别是。配置项的值需要 base64 编码 db_username: &quot;YWRtaW4K&quot; db_password: &quot;MTIzNDU2Cg==&quot; 创建和查看 configMap 和 Secret 跟 Pod 一样操作即可123456# 创建资源kubectl create -f test-web-config.yaml# 查看资源, 不指定命名空间，默认查看的是 default 命名空间的kubectl get &lt;configmap | cm&gt; [资源名]或者kubectl describe &lt;configmap | cm&gt; [资源名] 通过内容为 key=value 格式的文件创建 configMap 资源1234567# 通过 key=value 文件创建 configMap 资源kubectl create configmap test-web-config -n default --from-env-file=configs.txt# 通过 key=value 文件创建 secret 注意文件中的 value 是需要 base64 的kubectl create configmap ggeneric test-web-config -n default --from-env-file=configs.txt# configs.txt 的文件内容格式如下hello=&quot;world&quot;lang=&quot;en&quot; Pod 内容器服务使用 ConfigMap 和 Secret 资源中的配置项，方式如下： 作为环境变量使用，注意 Pod 和 ConfigMap 必须要在同一个命名空间中使用命令 kubectl exec test-web -c web01 -- env 可以查看容器环境变量12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970apiVersion: v1kind: Podmetadata: name: test-webspec: containers: - name: web01 image: nginx # 使用 envFrom 将所有 ConfigMap 的数据定义为容器环境变量 envFrom: - configMapRef: name: test-web-config env: # 定义环境变量 db_url - name: db_url value: jdbc://mysql/xxx//xx/xx # 定义环境变量 test-env-json - name: test-env-json # | 符号，表示值可以换行和值中保留换行符号 value: | &#123; &quot;hello&quot;:90 &#125; # 定义环境变量 db_password，变量的值从 Secret 资源中获取 - name: db_password valueFrom: secretKeyRef: # Secret 的资源名 name: test-web-secret # 获取 Secret 资源中 db_password 的值 key: db_password - name: redis_port valueFrom: configMapKeyRef: name: test-web-config key: redis_port # 定义环境变量 - name: apiversion # 将 Pod 信息存到环境变量中 valueFrom: fieldRef: fieldPath: metadata.name # 环境变量中获取 Pod IP - name: pod_ip valueFrom: fieldRef: fieldPath: status.podIP volumeMounts: - name: config-file-demo mountPath: &quot;/etc/web-config&quot; readOnly: true - name: nginx-config-file mountPath: &quot;/etc/nginx/conf.d&quot; readOnly: true volumes: - name: config-file-demo configMap: name: test-web-config # 指定哪些 key 可以在容器 /etc/web-config 目录下生成文件，不指定的话，所有 Key 都会生成文件 items: - key: &quot;game.properties&quot; path: &quot;game.properties&quot; - key: &quot;user-interface.properties&quot; path: &quot;user-interface.properties&quot; - name: nginx-config-file configMap: name: test-web-config items: - key: &quot;test-web.conf&quot; path: &quot;test-web.conf&quot; 将配置资源挂载为容器文件1234567891011121314151617apiVersion: v1kind: Podmetadata: name: test-web-02 namespace: defaultspec: containers: - name: test-nginx image: nginx volumeMounts: - name: secret-config # test-web-secret 中的 data 的每一个配置项都会在容器目录 /etc/config 中生成文件，key 作为文件名，value 是文件的内容 mountPath: &quot;/etc/config&quot; volumes: - name: secret-config secret: secretName: test-web-secret 6. 工作负载(Workload)工作负载又称 Pod 控制器用于管理 Pod，比如创建 Pod 副本、扩容或者升级版本等等，确保 Pod 资源能处于预期的工作状态中，Pod 资源遇到故障时能，会根据策略自动重启或者重新新建 Pod资源，k8s 提供的工作负载资源有以下几种： ReplicaSet 自动创建指定数量的 Pod 副本，并且支持滚动式自动扩容和缩容功能 Deployment 以 ReplicaSet 为基础，进一步的封装，用于管理无状态的应用，支持副本创建伸缩的同时，支持滚动更新和回滚功能 DaemonSet 用于确集群中的每一个 Node 节点都运行特定的 Pod 副本，比如用于定义每个节点上都运行日志收集类的 Pod，因为每一个节点的日志都需要收集 Job 用于管理运行完就退出的 Pod，不需要重启或者重建的 Pod 资源 CronJob 用于运行周期性任务的 Pod，不需要后台持久性运行 StatefulSet 用于管理有状态的应用 6.1 工作负载如何控制 Pod工作负载(Workload)是通过标签去关联 Pod 的，工作负载通过属性 spec.selector.matchLabels 指定要管理的 Pod 的标签 12345flowchart TB A([&quot;工作负载(Workload)&quot;]) A -- lables: app:nginx --&gt; P1[&quot;Pod&quot;] A -- lables: app:nginx --&gt; P2[&quot;Pod&quot;] A -- lables: app:nginx --&gt; P3[&quot;Pod&quot;] 6.2 Deployment 工作负载6.2.1 创建 Deployment Deployment 的声明式文件如下： 1234567891011121314151617181920212223242526apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment namespace: default labels: app: nginxspec: # 指定 Pod 的副本个数 replicas: 3 # 根据标签选择要控制的 Pod selector: matchLabels: app: nginx # template 属性声明定义 Pod 的信息 template: metadata: # 定义 Pod 的标签 labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 声明式文件创建 Deployment 使用如下命令： 1234# 执行创建或更新资源命令时加上 --record=true 参数，k8s 会将当前执行的创建或者更新命令记录在资源的 annotations 属性中kubectl create -f nginx-deployment.yaml --record=true# 或者kubectl apply -f nginx-deployment.yaml 命令行方式创建 Deployment 的方式如下： 1kubectl create deployment nginx-depoyment --image=nginx --replicas=3 查看 Deployment 信息 1234567891011121314# 查看默认命名空间下的所有 deployment kubectl get deployments# 根据名称查看默认命名空间下的 deploymentkubectl get deployments nginx-deployment# deployment 是 replicasets 的扩展封装，在创建 Deployment 的同时创建了 ReplicaSetkubectl get replicasets -o wide# 查看 deployment 信息和事件 kubectl describe deployment nginx-deployment# 查看 Depoyment 的状态kubectl rollout status deployment nginx-deployment 删除 Deloyment 12345# 方式一，通过 yaml 文件删除kubectl delete -f nginx-deployment.yaml# 方式二，通过 deloyment 名称删除kubectl delete depolyment nginx-deloyment 重启 Deployment 1kubectl rollout restart deployment nginx-deployment 6.2.2 更新 Deployment 更新副本数量 123456789# 第一种方式，命令行通过指定 --replicas 参数，来修改kubectl scale deployment nginx-deployment --replicas=2# 第二种方式，修改 yaml 文件中的 replicas 属性，然后执行更新kubectl apply -f nginx-deloyment.yaml# 第三种方式，通过 kubectl edit 命令直接修改 replicas 属性，即可生效kubectl edit deployment nginx-deployment 注意，创建 Deployment 资源时，也会创建 replicaset ，如果想通过修改 replicaset 资源的副本数量，去改变 Deployment 创建的副本数量是行不通，如下： 12# deployment 的副本数量并不会变kubectl scale replicaset nginx-deployment-687df7cddc --replicas=2 更新镜像版本 12345678910111213# 第一种方式，直接修改 yaml 文件，然后更新kubectl apply -f nginx-deployment.yaml# 第二种方式，kubectl edit 命令直接修改kubectl edit deployment nginx-deployment# 第三种方式，使用 kubectl set image 命令kubectl set image deployment nginx-deployment nginx=nginx:1.9.1 # 将所有 nginx 镜像改成 nginx:1.9.1kubectl set image deployment nginx-deployment busybox=busybox nginx=nginx:1.9.1 # 将所有 busybox 和 nginx 镜像分别改成busybox 和 nginx:1.9.1kubectl set image deployment nginx-deployment *=nginx:1.9.1 # 将所有 deployment 中的镜像都改成 nginx:1.9.1# 第四种方式使用命令 kubectl patch 使用补丁的方式修改更新资源的字段kubectl patch deployment nginx-deployment --patch &#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;spec&quot;: &#123;&quot;containers&quot;: [&#123;&quot;name&quot;: &quot;nginx&quot;,&quot;image&quot;:&quot;nginx:1.9.1&quot;&#125;]&#125;&#125;&#125;&#125;&#x27; 暂停和恢复 Pod 资源更新 1234# 将 deployment 的状态标记为 pause 状态时，更新镜像时则会被暂停，当使用 kubectl rollout resume 命令恢复状态时，会继续执行之前暂停的更新命令kubectl rollout pause deployment nginx-deployment# 将 Deployment 从 pause 状态恢复到 kubectl rollout status 查看到的状态kubectl rollout resume deployment test-k8s-deployment 6.2.3 Deployment 查看历史和回滚Deployment 资源中 Pod 信息的更改时，才会记录历史记录，比如修改镜像的名称、版本号等都是记录为历史记录，但是 Deployment 副本的伸缩或者其他非 Pod 信息改动不会记录历史版本，只是会将版本号递增 查看历史记录1234567# 查看历史记录版本列表，其中结果列 CHANGE-CAUSE 显示的是 delopyment 资源 annotations 属性下的 kubernetes.io/change-cause 属性，如果不存在会显示为 &lt;none&gt;# annotations.kubernetes.io/change-cause 属性是执行创建或者更新资源命令添加 --record 参数，才指定增加的属性kubectl rollout history deployment test-k8s-deployment# 查看历史记录的详细信息需要指定版本，注意只有详细信息里面的属性改动时才会记录历史记录，其他的改动只会改变版本号kubectl rollout history deployment test-k8s-deployment --revision=1# 查看历史版本详情信息kubectl rollout history deployment test-k8s-deployment -oyaml 回滚12#回滚到指定历史版本kubectl rollout undo deployment nginx-deployment --to-revision=1 6.2.4 更新策略(strategy)Deployment 控制器提供了两种更新策略，分别是： Recreate 在更新新的 Pod 之前，先把旧的 Pod 全部先删除掉 RollingUpdate 滚动更新，根据指定的规则先创建新的 Pod 在删除旧的 Pods Deployment 默认使用的是 RollingUpdate 策略，它是一种平滑的滚动更新方式，可以保证服务的高可用，使RollingUpdate 策略时，需要设置 maxUnavailable 和 maxSurge 参数值，说明如下： maxUnavailable 表示在更新过程中，最多有多少个 Pod 不可用，值可以是数值或者百分比，默认值是 25%，计算结果向下取整 maxSurge 表示在更新过程中，Pod 的个数最大峰值，值可以是数值或者百分比，默认值是 25%，注意计算结果向上取整，跟 maxUnavailable 的取整结果相反 列如有 8 个 Pods 需要更新，如果 maxUnavailable 和 maxSurge 都按默认值 25 % 来计算，那么得出以下规则： 在更新过程中，Pods 的数量最大值为 10 &#x3D; (8 + 8 * 0.25maxSurge) 在更新过程中，Ready 状态 Pods 数量至少大于等于 6 &#x3D; (8 - 8*0.25maxUnavailable)使用 kubectl describe deployment nginx-deployment 命令查看 Deployment 的升级事件，如下：由可以看到滚动升级的过程如下： 启动 maxSurge 个 Pods 关闭 maxUnavailable 个 pods 启动 maxUnavailable 个 Pods 关闭 1 个 Pod 启动 1 个 Pod 关闭 1 个 Pod 启动 1 个 Pod，后面一直重复，启动一个关闭一个，直到 Pods 版本更新完成 7. ServiceService 资源是一组 Pods 的抽象服务，可以看成是一组 Pods 的负载均衡(LB)，创建 Service 资源时，K8s 会为 Serivce 资源生成一个虚拟 IP，又称ClusterIP(集群IP)。访问该 ClusterIP 时，Serivice 会负责将请求转发给对应的 Pod。 Service 主要有以下特性： Service 是通过 label 去关联对应的 Pods Servcie 只会监控 Ready 状态的 Pods 提供了负载均衡功能，能自动转发流量到不同 Pod 副本上 集群内所有的 Pods 的内部都可以通过服务名字或者服务虚拟 IP 访问，但在节点中只能虚拟 IP 访问，注意在 Pod 内部使用服务名访问时，如果是不同的命名空间下，需要在服务名后面加命名空间 7.1 Service 资源文件式声明定义12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: v1kind: Servicemetadata: name: test-k8sspec: # 根据 label 关联 Pods, 并根据 label 实时 Watch Pods 的状态 # 如果 Pod 是 Ready 状态，就将 Pod 加入 Service 的 Endpoints 中，不是就将其从 Service 的 Endpoints 中剔除 selector: app: test-k8s-pod # type 支持四种类型分别是 ClusterIP、NodePort、LoadBalancer、ExternalName type: ClusterIP ports: # 本 Service 的端口 - port: 8888 # Pod 应用的端口 targetPort: 80# 三个横线表示是将文件分成多个 yaml 文件--- apiVersion: v1kind: Servicemetadata: name: test-k8sspec: selector: app: test-k8s-pod # 表示除了可以通过使用 Service 的名称和IP 访问该 Service 负载均衡的 Pods 外 # 还可以通过通过每个节点的 IP 加 nodePort 访问 type: NodePort # ports 指定多个端口时，必须指定 name ports: # 本 Service 的端口 - port: 8888 # Pod 应用的端口 targetPort: 80 # 节点端口，如果不指定的话，创建时会默认从范围 30000 ~ 32767 中指定一个 # 集群节点的端口，注意每节点的 Kube-Proxy 组件都会监听改端口，所有每个节点的 IP 都可以访问 Service 服务 nodePort: 30458 name: test-service-001 - port: 8889 # Pod 应用的端口，如果 Pod 应用的 ports 属性定义 name 则 targetPort 的值也可以设置为 Pod 端口的 name targetPort: 81 nodePort: 30459 name: test-service-002 Service 资源的的 Type 说明如下： ClusterIP：通过集群内的 ClusterIP 暴露服务，选择该值时服务只能够在集群内部访问。注意 ClusterIP 是可以在配置文件中固定写死一个值的。 NodePort：通过集群节点 IP 和集群 ClusterIP 暴露服务。 LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的 NodePort 服务和 ClusterIP 服务上。 ExternalName：通过返回 CNAME 和对应值，可以将服务映射到 externalName 字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理。 两个注意点： 通过服务名访问服务，只能在 Pod 的容器内部使用。Pod 容器中的 /etc/resolv.conf 文件，维护有 Core-DNS 组件的 IP 地址，使用服务名访问会通过该 IP 去访问 Core-DNS 将服务名解析成服务的 ClusterIP nodePort 实际上是由节点上的 Kube-proxy 组件监听的，通过节点 IP 访问服务时，实际是访问 kube-proxy 在转发到 Service 服务 7.1.2 操作资源的常用命令12345678910111213141516# 通过资源配置文件创建资源kubectl apply -f [test-service.yaml]# 查看默认命名空间下的资源信息kubectl get service -owide# 查看服务详情和 Endpoints(Pods 的应用的访问地址)kubectl describe svc [资源名]# 查看服务资源的 endpointskubectl get endpoints# 根据资源配置文件删除资源kebectl delete -f [test-service.yaml]# 通过资源名称删除资源kubectl delete service [test-service] 8. IngressIngress 为外部访问集群提供了一个 统一入口，避免了对外暴露集群端口，可以根据域名、路径把请求转发到不同的 Service 资源。Ingress 资源主要用于定义统一的访问配置和转发规则，去适配不同的负载均衡器，目前支持负载均衡器有 nginx、Haproxy, trafik, lstios 等等。 Ingress 资源只是提供访问转发路由的配置，实际访问配置和负责转发工作的是 Ingress 控制器，也就是底层的负载均衡器，ingress 控制器通过和 k8s API 交互，动态监控 ingress 资源中配置的规则。并将其更新到 ingress 控器 Pod 内的负载均衡应用中。如使用 ningx 控制器(ingress-nginx-controller)时，nginx 控制器通过 k8s API 实时监控 ingress 资源中配置的转发规则，当监控到 ingress 中的配置规则时，会将 ingress 规则转发 nginx 配置规则，并实时写到 ingress-nginx-controller 的 Pod 里的 nginx 服务的 nginx.config 文件中和在控制器中运行nginx -s reload动态实时生效配置。外部流量访问时，访问的是 ingress-nginx 控制器中 pod 的 nginx 服务，所以部署 ingress-nginx 控制器时候要指定 Deployment 中 Pod 的网络默认为 host 或者将 Service 中的类型改成 NodePort。 注意Ingress 通过 Service 关联已经是 Ready 状态的 Pods，如下图所示： 8.2 IngressIngress 资源文件定义如下，注意 k8s 在 1.18 版本之前可以使用注解指定使用那种控制器，1.18 版本之后使用 ingressClassName 123456789101112131415161718192021222324252627282930313233apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: hello-ingress annotations: # 指定要使用的控制器类，ingress-nginx 控制器需要在 pods 容器的启动参数中设置 –-ingress-class=nginx kubernetes.io/ingress.class: nginx # 表示闭 https 连接，只使用 http 连接 nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;spec: # 如果规则不指定 host 则表示匹配所有域名 rules: - http: paths: - path: /hello # 匹配路径的规则有三个可选值，Prefix 表示按路径前缀匹配，区分大小写，Exact 表示全路径精准匹配，区分大小写，ImplementationSpecific 匹配方法取决于 IngressClass 即取决于Ingress 控制器 # 指定规则匹配后跳转到的 service 名称和端口 backend: # 支持两种写法，第一种写法 service: name: test-service port: number: 3000 # host 支持 * 通配符号 - host: ecm.jintiantong.com http: paths: path: / pathType: Prefix backend: # 第二种写法 serviceName: test-service-01 servicePort: 3000 8.1 安装 Ingress 控制器注意安装 Ingress 控制器的时候，可以更该 Pod 的配置 nodeSelector 表示需要将 Ingress 控制器的 Pod 部署在那个节点，默认是选择部署在有标签 kubernetes.io&#x2F;os&#x3D;linux 的节点 注意要将 ingress-nginx-controller 配置文件中的 Deployment 资源中将 Pods 网络默认改成 host 模式，或者 Service 资源的类型改成 NodePort, 如果 service 资源需要安装一个LB(负载均衡器，可以使用开源的 MetalLB)，通过 LB 在将流量转发到集群内部的Serive ClusterIP, 不然无法访问到 ingress 控制器里面的负载均衡器的。 注意 ingress-nginx-controller 资源安装文件中，可以 Pod 的控制器由 Deployment 改成 DaemonSet 控制，Pod 使用 host 模式时可以删除 service 资源配置不创建 Service 资源。 安装 ingress-nginx-controller 的资源文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658apiVersion: v1kind: Namespacemetadata: labels: app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx name: ingress-nginx---apiVersion: v1automountServiceAccountToken: truekind: ServiceAccountmetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx namespace: ingress-nginx---apiVersion: v1kind: ServiceAccountmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission namespace: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx namespace: ingress-nginxrules:- apiGroups: - &quot;&quot; resources: - namespaces verbs: - get- apiGroups: - &quot;&quot; resources: - configmaps - pods - secrets - endpoints verbs: - get - list - watch- apiGroups: - &quot;&quot; resources: - services verbs: - get - list - watch- apiGroups: - networking.k8s.io resources: - ingresses verbs: - get - list - watch- apiGroups: - networking.k8s.io resources: - ingresses/status verbs: - update- apiGroups: - networking.k8s.io resources: - ingressclasses verbs: - get - list - watch- apiGroups: - &quot;&quot; resourceNames: - ingress-nginx-leader resources: - configmaps verbs: - get - update- apiGroups: - &quot;&quot; resources: - configmaps verbs: - create- apiGroups: - coordination.k8s.io resourceNames: - ingress-nginx-leader resources: - leases verbs: - get - update- apiGroups: - coordination.k8s.io resources: - leases verbs: - create- apiGroups: - &quot;&quot; resources: - events verbs: - create - patch- apiGroups: - discovery.k8s.io resources: - endpointslices verbs: - list - watch - get---apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission namespace: ingress-nginxrules:- apiGroups: - &quot;&quot; resources: - secrets verbs: - get - create---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: labels: app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginxrules:- apiGroups: - &quot;&quot; resources: - configmaps - endpoints - nodes - pods - secrets - namespaces verbs: - list - watch- apiGroups: - coordination.k8s.io resources: - leases verbs: - list - watch- apiGroups: - &quot;&quot; resources: - nodes verbs: - get- apiGroups: - &quot;&quot; resources: - services verbs: - get - list - watch- apiGroups: - networking.k8s.io resources: - ingresses verbs: - get - list - watch- apiGroups: - &quot;&quot; resources: - events verbs: - create - patch- apiGroups: - networking.k8s.io resources: - ingresses/status verbs: - update- apiGroups: - networking.k8s.io resources: - ingressclasses verbs: - get - list - watch- apiGroups: - discovery.k8s.io resources: - endpointslices verbs: - list - watch - get---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admissionrules:- apiGroups: - admissionregistration.k8s.io resources: - validatingwebhookconfigurations verbs: - get - update---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx namespace: ingress-nginxroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: ingress-nginxsubjects:- kind: ServiceAccount name: ingress-nginx namespace: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission namespace: ingress-nginxroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: ingress-nginx-admissionsubjects:- kind: ServiceAccount name: ingress-nginx-admission namespace: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: labels: app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginxroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: ingress-nginxsubjects:- kind: ServiceAccount name: ingress-nginx namespace: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admissionroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: ingress-nginx-admissionsubjects:- kind: ServiceAccount name: ingress-nginx-admission namespace: ingress-nginx---apiVersion: v1data: allow-snippet-annotations: &quot;true&quot;kind: ConfigMapmetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-controller namespace: ingress-nginx---apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-controller namespace: ingress-nginxspec: externalTrafficPolicy: Local ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - appProtocol: http name: http port: 80 protocol: TCP targetPort: http - appProtocol: https name: https port: 443 protocol: TCP targetPort: https selector: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-controller-admission namespace: ingress-nginxspec: ports: - appProtocol: https name: https-webhook port: 443 targetPort: webhook selector: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx type: ClusterIP---apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-controller namespace: ingress-nginxspec: minReadySeconds: 0 revisionHistoryLimit: 10 selector: matchLabels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx template: metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx spec: containers: - args: - /nginx-ingress-controller - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller - --election-id=ingress-nginx-leader - --controller-class=k8s.io/ingress-nginx - --ingress-class=nginx - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller - --validating-webhook=:8443 - --validating-webhook-certificate=/usr/local/certificates/cert - --validating-webhook-key=/usr/local/certificates/key env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: LD_PRELOAD value: /usr/local/lib/libmimalloc.so image: registry.k8s.io/ingress-nginx/controller:v1.5.1@sha256:4ba73c697770664c1e00e9f968de14e08f606ff961c76e5d7033a4a9c593c629 imagePullPolicy: IfNotPresent lifecycle: preStop: exec: command: - /wait-shutdown livenessProbe: failureThreshold: 5 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 name: controller ports: - containerPort: 80 name: http protocol: TCP - containerPort: 443 name: https protocol: TCP - containerPort: 8443 name: webhook protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: requests: cpu: 100m memory: 90Mi securityContext: allowPrivilegeEscalation: true capabilities: add: - NET_BIND_SERVICE drop: - ALL runAsUser: 101 volumeMounts: - mountPath: /usr/local/certificates/ name: webhook-cert readOnly: true dnsPolicy: ClusterFirst nodeSelector: kubernetes.io/os: linux serviceAccountName: ingress-nginx terminationGracePeriodSeconds: 300 volumes: - name: webhook-cert secret: secretName: ingress-nginx-admission---apiVersion: batch/v1kind: Jobmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission-create namespace: ingress-nginxspec: template: metadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission-create spec: containers: - args: - create - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc - --namespace=$(POD_NAMESPACE) - --secret-name=ingress-nginx-admission env: - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f imagePullPolicy: IfNotPresent name: create securityContext: allowPrivilegeEscalation: false nodeSelector: kubernetes.io/os: linux restartPolicy: OnFailure securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 2000 serviceAccountName: ingress-nginx-admission---apiVersion: batch/v1kind: Jobmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission-patch namespace: ingress-nginxspec: template: metadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admission-patch spec: containers: - args: - patch - --webhook-name=ingress-nginx-admission - --namespace=$(POD_NAMESPACE) - --patch-mutating=false - --secret-name=ingress-nginx-admission - --patch-failure-policy=Fail env: - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f imagePullPolicy: IfNotPresent name: patch securityContext: allowPrivilegeEscalation: false nodeSelector: kubernetes.io/os: linux restartPolicy: OnFailure securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 2000 serviceAccountName: ingress-nginx-admission---apiVersion: networking.k8s.io/v1kind: IngressClassmetadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: nginxspec: controller: k8s.io/ingress-nginx---apiVersion: admissionregistration.k8s.io/v1kind: ValidatingWebhookConfigurationmetadata: labels: app.kubernetes.io/component: admission-webhook app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.5.1 name: ingress-nginx-admissionwebhooks:- admissionReviewVersions: - v1 clientConfig: service: name: ingress-nginx-controller-admission namespace: ingress-nginx path: /networking/v1/ingresses failurePolicy: Fail matchPolicy: Equivalent name: validate.nginx.ingress.kubernetes.io rules: - apiGroups: - networking.k8s.io apiVersions: - v1 operations: - CREATE - UPDATE resources: - ingresses sideEffects: None 9.0 Pods 调度调度指的是将 Pod 部署到合适的节点上，kube-scheduler 是 Kubernetes 集群的默认调度器。 9.1 kube-scheduler 调度器kube-scheduler 给一个 Pod 做调度时包含两个阶段： 过滤，过滤阶段会将所有满足 Pod 调度需求的节点选出来。 打分，打分阶段，调度器会为 Pod 从所有可调度节点中选取一个最合适的节点。 根据当前启用的打分规则，调度器会给每一个可调度节点进行打分。最后，kube-scheduler 会将 Pod 调度到得分最高的节点上。 如果存在多个得分最高的节点，kube-scheduler 会从中随机选取一个。 9.2 控制 k8s 调度一般情况下 Pods 会部署在哪些 node 上，我们并不需要去关心和控制，kube-scheduler 会自动进行合理的调度。但是有时候，我们想去控制 pods 调度部署到指定的 node 节点上时，可以通过 nodeSelector 选择或者亲和性和反亲和性的配置去控制 pods 的调度。注意 nodeselector 和亲和性都是通过标签匹配的。 9.2.1 nodeSelector 节点选择在 Pods 资源配置文件，通过 nodeSelector 选择带有指定标签的节点，k8s 会将 Pod 调度到特定节点或节点组上，nodeSelector 节点选择器是限制 k8s 调度最简单的一种方式。 9.2.1 nodeAffinity 节点亲和性nodeselector 是一种比较简单的控制 k8s 调度的方式，如果想控制粒度更细致的话，则需要用到 nodeAffinity(节点亲和性)定义策略去控制。亲和性的调度可以分成软策略和硬策略两种方式，如下： requiredDuringSchedulingIgnoredDuringExecution 硬策略，表示只会将 pods 调度到满足策略的节点上，如果没有满足策略的节点，将会一直重试匹配策略直到有满足策略的节点出现才调度部署 pods。 preferredDuringSchedulingIgnoredDuringExecution 软策略，表示会优先将 pods 调度到满足策略的节点上，如果没有满足策略的节点，k8s 也会自动调度到不满足策略的节点上。 labels 标签在 K8s 中是一个很重要的概念，k8s 资源之间的关联都是通过 label 来实现的如 Service、Deployment、Pods 之间的关联。节点亲和性控制 pods 的调度也是通过匹配 node 节点标签来实现，亲和性匹配 labels 语法支持的运算符有：In、NotIn、Exists、DoesNotExist、Gt、Lt。 nodeAffinity 节点亲和性使用例子如下： 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: test-node-affinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 支持多个匹配表达式(matchExpressions)，表达式之间属于 or 的关系 nodeSelectorTerms: # 支持匹配多个 key，多个 key 的匹配规则是 and 的关系 - matchExpressions: # 匹配标签 key 等于 topology.kubernetes.io/zone 且标签值等于 antarctica-east1 或 antarctica-west1 的节点 - key: topology.kubernetes.io/zone operator: In values: - antarctica-east1 - antarctica-west1 # 匹配标签 key 等于 node.kubernetes.io/host 且标签值等于 192.168.204.3 或 192.168.204.4 的节点 - key: node.kubernetes.io/host operator: In values: - 192.168.204.3 - 192.168.204.4 - key: node.kubernetes.io/disk operator: Exists values: - ssd preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: test-node-affinity image: nginx:latest 注意多条件匹配规则如下： 如果你同时指定了 nodeSelector 和 nodeAffinity，两者 必须都要满足， 才能将 Pod 调度到候选节点上。 如果你在与 nodeAffinity 类型关联的 nodeSelectorTerms 中指定多个条件， 只要其中一个 nodeSelectorTerms 满足（各个条件按逻辑或操作组合）的话，Pod 就可以被调度到节点上。 如果你在与 nodeSelectorTerms 中的条件相关联的单个 matchExpressions 字段中指定多个表达式， 则只有当所有表达式都满足（各表达式按逻辑与操作组合）时，Pod 才能被调度到节点上。 9.2.2 Pod 间亲和性与反亲和性Pod 间亲和性与反亲和性与 Node 节点的亲和性类似，也有两种策略类型，不同的是 requiredDuringSchedulingIgnoredDuringExecution 用来设置亲和性，preferredDuringSchedulingIgnoredDuringExecution 用来设置反亲和性。实际使用例子如下： 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: with-pod-affinityspec: affinity: # pod 亲和性 podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: # 注意匹配该标签要匹配的是 Pods 的标签 - key: security operator: In values: - S1 topologyKey: topology.kubernetes.io/zone # pod 反亲和性 podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: topology.kubernetes.io/zone containers: - name: with-pod-affinity image: nginx:latest 9.2.3 污点（taints）与容忍（tolerations）nodeSelector 或者 nodeAffinity(节点亲和性)都是想要将 Pods 调度到预期的节点上，taints(污点)则恰好与之相反，如果将一个 node 节点标记为 taints ，则 Pods 将不会调度到该 node 节点上，除非 Pods 标识为可以容忍污点。 查看节点是否有污点(taints)标签1234# 如果 node 节点 taints 属性不为 &lt;node&gt; 说明已经有污点标签kubectl describe node | grep -i taints# 或者kubectl describe node k8s-node01 | grep -i taints 将为节点打上污点1234567# 为 k8s-node01 节点打上 key1=value1 标签节点，并驱逐 k8s-node01 节点上的 Pods 到其他 node 节点上，并且新的 Pods 如果未设置污点容忍，则无法调度到此节点。 kubectl taint nodes k8s-node01 key1=value1:NoExecute# 为 k8s-node01 节点打上 key=value1 标签，不驱逐 k8s-node01 节点上的 Pods, 新的 Pods 如果未设置污点容忍，则无法调度到此节点。 kubectl taint nodes k8s-node01 key1=value1:NoSchedule# 查看 node 节点是否已经打上污点标签kubectl describe node k8s-node01 | grep -i taints 删除节点污点标签1kubectl taint nodes k8s-node01 key1=value1:NoExecute- 10. HelmHelm 是部署 Kubernetes 应用包管理工具，比如有多个应用服务，部署的时候如果不使用 Helm 则需要手动的一个个的编写 Pods, Deployment, Service 等资源文件，相当繁琐，并且版本更新的时候也繁琐。Helm 是使用 Chart 将 Pods, Deployment, Service 等资源的 yaml 文件作为一个整体管理，相当于 docker 去管理 image 一样，我们可以自己创建 Chart ，也可以从 Helm 仓库查找和使用别人配置好的 Chart。 10.1 Helm 的三个重要概念 Helm 是命令行工具 Chart 应用服务的资源的 yaml 配置文件集合 Release 是 Chart 的部署实体，运行部署使用命令helm install 10.2 安装 Helm10.2.1 离线安装包安装 下载对应系统的安装 https://github.com/helm/helm/releases 这里下载的是 linux-amd64.tar.gz 解压离线包 tar -zxvf linux-amd64.tar.gz 将解压后的 helm 可执行文件复制到 /usr/local/bin 或者 /usr/bin 目录 验证是否安装成功 helm help 10.3 Helm Chart 常用命令参考连接 https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/init-containers/ https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-pod-configmap/","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/categories/Kubernetes/"}],"tags":[]},{"title":"SSH 密码登录和密钥配置说明","slug":"Linux/SSH 密码登录和密钥配置说明","date":"2022-05-11T16:00:00.000Z","updated":"2023-05-31T13:39:26.110Z","comments":true,"path":"wiki/Linux/SSH 密码登录和密钥配置说明/","link":"","permalink":"http://example.com/wiki/Linux/SSH%20%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E5%92%8C%E5%AF%86%E9%92%A5%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/","excerpt":"","text":"账号密码登录1ssh username@host -p 22 公钥登录1、运行如下命令生成密钥，如果已有密钥则不必重新生成，默认会在用户目录，生成 .ssh 目录和 id_rsa 私钥 以及 id_rsa.pub 公钥 12345678ssh-keygen -t rsa -C &quot;xxxx@email.com&quot;-t 指定密钥类型，一般类型有 dsa和 rsa 默认是 rsa 类型，可以省略。-C 设置注释，一般填写的都是自己的邮箱-f 指定密钥文件存储文件名-P 密钥的密码，一般都是不指定密码的，-P &#x27;&#x27; 指定密码为空字符时，运行命令可以少敲两个回车 -b 指定密钥的位数，可以设置值如 1024 或 4069，未研究位数的作用 2、将公钥复制到远程服务器，复制的方式有两种 第一种方式，使用命令 ssh-copy-id 12345# 将公钥复制到程服务器 ~/.ssh/authorizeys 文件中ssh-copy-id -i ~/.ssh/id_rsp.pub username@host -p 22-i 参数指定公钥文件，不指定的话，ssh-copy-id 命令默认读取用户目录下 .ssh 文件夹中的 id_rsp.pub 文件 第二种方式，将公钥 id_rsa.pub 文件内容追加到远程服务器 ~&#x2F;.ssh&#x2F;authorizeys 文件中，如果 .ssh 目录和 authorizeys 文件不存在则需要创建后再把 id_rsa.pub 内容复制到其中。 12345678910111213上传 id_rsa.pub 文件到远程服务，可以使用 sftp 工具上传，也可以使用 scp 上传，或者其他方式上传，例子使用 scp 命令上传scp ~/.ssh/id_rsa.pub username@host:/home/username 密码登录远程服务将刚才上传的公钥内容追加到 authorizeys 文件中cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorizeys注意远程服务的 .ssh 目录权限不是 700 要修改一下chmod -R 700 ~ /.ssh 3、按上面的说明配置好后，即可直接使用命令 ssh username@host 免密登录远程服务 4、禁止密码登录，限制只能使用密钥登录，需要修改 &#x2F;etc&#x2F;ssh&#x2F;sshd_config 文件如下 12345678910# 修改登录端口 port 默认是 22, 修改端口前查看是否被占用 netstat -ano | grep 2222port 2222# 允许 root 用户通过ssh登录PermitRootLogin yes# 禁用密码登录PasswordAuthentication no# 允许使用ssh权限登录RSAAuthentication yesPubkeyAuthentication yes 注意修改配置文件要重启 sshd 才能生效，重启命令,如下 12service sshd restart 5、ssh 快捷登录说明，使用 ~&#x2F;.ssh&#x2F;config 文件实现 1234567891011Host server01HostName xx.xx.xx.xxPort 22User usernameIdentityFile /path/id_rsa # 指定登录的密钥，不指定默认使用的是 ~/.ssh/id_rsa 注意 ~ 符号表示的用户目录Host server02HostName xx.xx.xx.xxPort 22User username 以上文件配置后，直接使用 ssh server01 和 ssh server02 就能登录到服务器，注意如果没配置密钥连接方式的话，运行 ssh server01 还是会提示输入密码 服务器查看 ssh 的登录日志12tail -f -n 200 /var/log/secure","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[]}],"categories":[{"name":"NodeJs","slug":"NodeJs","permalink":"http://example.com/categories/NodeJs/"},{"name":"PowerDesigner","slug":"PowerDesigner","permalink":"http://example.com/categories/PowerDesigner/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"},{"name":"Shell","slug":"Shell","permalink":"http://example.com/categories/Shell/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/categories/SpringBoot/"},{"name":"Xml","slug":"Xml","permalink":"http://example.com/categories/Xml/"},{"name":"other","slug":"other","permalink":"http://example.com/categories/other/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Apache POI","slug":"Apache-POI","permalink":"http://example.com/categories/Apache-POI/"},{"name":"Docker","slug":"Docker","permalink":"http://example.com/categories/Docker/"},{"name":"Golang","slug":"Golang","permalink":"http://example.com/categories/Golang/"},{"name":"Java 知识点","slug":"Java-知识点","permalink":"http://example.com/categories/Java-%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"Java 设计模式","slug":"Java-设计模式","permalink":"http://example.com/categories/Java-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Jemeter","slug":"Jemeter","permalink":"http://example.com/categories/Jemeter/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://example.com/categories/Kubernetes/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"},{"name":"Maven","slug":"Maven","permalink":"http://example.com/categories/Maven/"},{"name":"MySql","slug":"MySql","permalink":"http://example.com/categories/MySql/"},{"name":"Nginx","slug":"Nginx","permalink":"http://example.com/categories/Nginx/"}],"tags":[{"name":"go","slug":"go","permalink":"http://example.com/tags/go/"}]}